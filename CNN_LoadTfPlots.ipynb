{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install snntorch\n",
    "#!pip install opencv-python\n",
    "#!pip install brevitas\n",
    "#!pip install onnx==1.8.1  \n",
    "!pip install onnxoptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### RUN\n",
    "# Create dataset using HDF5 Format\n",
    "# Errors due to dataset being not discrete. Hand pick ictal samples.\n",
    "# iNVERSE- SPIKES IN  BLACK, nO inverse - SPIKES IN WHITE\n",
    "#!pip install snntorch\n",
    "# imports\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import backprop\n",
    "from snntorch import functional as SF\n",
    "from snntorch import utils\n",
    "from snntorch import spikeplot as splt\n",
    "\n",
    "import onnx   #1.8.1   #Import ONNX before torch\n",
    "import onnxoptimizer as opt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import brevitas.nn as qnn\n",
    "import torch.onnx\n",
    "from brevitas.export import FINNManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### RUN\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader,ConcatDataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "pat_id = 'pat_442'\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        #self.imgs_path = \"./TF_images_ictal_nonictal/\"\n",
    "        #self.imgs_path = \"./TF_plot_images/pat_139/\"\n",
    "        #self.imgs_path = \"./TF_plot_images/pat_253/\"\n",
    "        self.imgs_path = './TF_plot_images_rand/' + pat_id + '/train_data/' \n",
    "        file_list = glob.glob(self.imgs_path + \"*\")\n",
    "        print(file_list)\n",
    "        self.data = []\n",
    "        for class_path in file_list:\n",
    "            class_name = class_path.split(\"/\")[-1]\n",
    "            for img_path in glob.glob(class_path + \"/*.png\"):\n",
    "                self.data.append([img_path, class_name])\n",
    "        print('self.data length',len(self.data))\n",
    "        self.class_map = {\"non_ictal\" : 0, \"ictal\": 1}\n",
    "        self.img_dim = (28, 28)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, class_name = self.data[idx]\n",
    "        img = cv2.imread(img_path)                      # Load Image \n",
    "        #print('shape for original image',img.shape)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)    # in grayscale\n",
    "        #img = img[:,:,2]                                # take red component only\n",
    "        #print('shape for image grayscale',img.shape)\n",
    "        img = img[60:60+366, 81:81+396]                 # Crop image  \n",
    "        #print('shape for image cropped',img.shape)\n",
    "        img = cv2.bitwise_not(img)                      # Negativ-positiv inversion #TODO: improve this\n",
    "        #print('shape for image bitwise not',img.shape)\n",
    "        img = cv2.resize(img, self.img_dim)             # resize\n",
    "        #print('shape for image resize',img.shape)\n",
    "        #img_tensor = torch.from_numpy(img)\n",
    "        #img_tensor = torch.unsqueeze(img_tensor, 0).float()\n",
    "        #print('shape for image before',img_tensor.shape)\n",
    "        if self.transform is not None:\n",
    "            img_tensor = self.transform(img)\n",
    "            img_tensor = img_tensor.float()\n",
    "            #print('return type of transform',img_tensor.shape, img_tensor.dtype)\n",
    "        class_id = self.class_map[class_name]\n",
    "        #if class_id == 1:\n",
    "        #    cv2.imshow('rgb image', img)\n",
    "        #    cv2.waitKey(5)\n",
    "        #print('Label is ', class_id)\n",
    "        #img_tensor = img_tensor.permute(2, 0, 1)     # for BGR image\n",
    "        class_id = torch.tensor([class_id])\n",
    "        #print('data', img_tensor.float().shape , 'targets', class_id.float().shape)\n",
    "        return img_tensor.float(), class_id.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### RUN\n",
    "# imports\n",
    "import snntorch as snn\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "from IPython.display import HTML\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "# dataloader arguments\n",
    "batch_size = 64\n",
    "#dtype = torch.float\n",
    "#device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device = 'cpu'\n",
    "\n",
    "# Define a transform\n",
    "transform = transforms.Compose([\n",
    "            #transforms.Resize((32, 32)),\n",
    "            #transforms.Grayscale(),     #Returns PIL image\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0,), (1,))  # ToTensor and Normalize work together\n",
    "        ])\n",
    "\n",
    "dataset = CustomDataset(transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### RUN\n",
    "# Making training test validation split and creating dataloader\n",
    "from sklearn.model_selection import LeavePGroupsOut  #TODO; Do LOO split for validation\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import pandas as pd\n",
    "\n",
    "def train_test_split(dataset):\n",
    "    \"\"\"Split dataset into train and test \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : ConcatDataset\n",
    "        The dataset to split.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ConcatDataset\n",
    "        The training data and the testing data.\n",
    "    \"\"\"\n",
    "    print('Total images', len(dataset))\n",
    "    train_size = int(0.99 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    print('Train and test size', train_size, test_size)\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "torch.manual_seed(87)\n",
    "np.random.seed(87)\n",
    "train_ds, test_ds = train_test_split(dataset)\n",
    "print('Number of examples in each set:')\n",
    "print(f'Training: {len(train_ds)}')\n",
    "print(f'Test: {len(test_ds)}')\n",
    "print(train_ds)\n",
    "\n",
    "#Class weights\n",
    "train_y = pd.Series([y for _,y in train_ds])\n",
    "#print('train_y train 0/1: {}/{}'.format((train_y == 0).sum(), (train_y == 1).sum()))\n",
    "\n",
    "class_sample_count = torch.tensor(\n",
    "    [(train_y == t).sum() for t in torch.unique(torch.tensor(train_y), sorted=True)])\n",
    "print('train class 0/1 weightage', class_sample_count)\n",
    "\n",
    "#WeightedSampler\n",
    "weights = 1. / class_sample_count.float()\n",
    "print('weights', weights)\n",
    "weights[1] = weights[1]/2.0\n",
    "print('weights', weights)\n",
    "samples_weights = torch.tensor([weights[t.long()] for t in torch.tensor(train_y)])\n",
    "print('sample weights', samples_weights)\n",
    "sampler = WeightedRandomSampler( weights=samples_weights, num_samples=len(train_ds), replacement=True)\n",
    "\n",
    "# Create dataloaders\n",
    "num_workers = 0  \n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=batch_size,  num_workers=num_workers, sampler=sampler) # Todo: shuffle?\n",
    "#loader_valid = DataLoader(\n",
    "#    valid_ds, batch_size=valid_batch_size, shuffle=False, num_workers=num_workers)\n",
    "valid_loader = DataLoader(\n",
    "    dataset_test, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "print(f'Training: {len(train_ds)}')\n",
    "print(f'Test: {len(dataset_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate DataLoader and check class balance for each batch\n",
    "for i, (x, y) in enumerate(train_loader):\n",
    "    print(\"batch index {}, 0/1: {}/{}\".format(\n",
    "        i, (y == 0).sum(), (y == 1).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brevitas.nn import QuantIdentity\n",
    "from brevitas.nn import QuantConv2d\n",
    "from brevitas.quant import Int8Bias\n",
    "from brevitas.nn import QuantDropout\n",
    "from brevitas.nn import QuantReLU\n",
    "from brevitas.nn import QuantSigmoid\n",
    "from brevitas.quant.scaled_int import Int8ActPerTensorFloat\n",
    "%env BREVITAS_JIT=1\n",
    "%env BREVITAS_IGNORE_MISSING_KEYS=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### RUN\n",
    "def reset_weights(m):\n",
    "    '''Try resetting model weights to avoid weight leakage. '''\n",
    "    for layer in m.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            print(f'Reset trainable parameters of layer = {layer}')\n",
    "            layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING NEURAL NETWORK with parameterization for freq = 256Hz and t= 2sec : based on Farrokh's\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class IEEGSeizureDetection_cnv(nn.Module):\n",
    "   \n",
    "    def __init__(self):\n",
    "        super(IEEGSeizureDetection_cnv, self).__init__()\n",
    "\n",
    "        weight_bit_width = 4\n",
    "        act_bit_width = 4\n",
    "        \n",
    "        #Layer1\n",
    "        self.quant_identity = QuantIdentity(return_quant_tensor=True)\n",
    "        self.conv1 = qnn.QuantConv2d(in_channels=1, out_channels= 16, kernel_size= 5,\n",
    "                                     bias=True,\n",
    "                                     #weight_bit_width=weight_bit_width,\n",
    "                                     #input_quant=Int8ActPerTensorFloat, \n",
    "                                     #weight_quant=Int8ActPerTensorFloat,\n",
    "                                     bias_quant=Int8Bias,\n",
    "                                     #output_quant=Int8ActPerTensorFloat,\n",
    "                                     return_quant_tensor=True)\n",
    "        #print(self.conv1)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        #self.dropout = QuantDropout(0.2)\n",
    "        self.relu1 = QuantReLU(return_quant_tensor=True)\n",
    "        \n",
    "        #Layer2\n",
    "        self.conv2 = qnn.QuantConv2d(in_channels=16, out_channels=64 ,kernel_size= 5,\n",
    "                                     bias=True,\n",
    "                                     #weight_bit_width=weight_bit_width,\n",
    "                                     #input_quant=Int8ActPerTensorFloat, \n",
    "                                     bias_quant=Int8Bias,\n",
    "                                     #output_quant=Int8ActPerTensorFloat,\n",
    "                                     return_quant_tensor=True)\n",
    "        #print(self.conv2)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(64)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.relu2 = QuantReLU(return_quant_tensor=True)\n",
    "        \n",
    "        #Layer3\n",
    "        self.conv3 = qnn.QuantConv2d(in_channels=64, out_channels=64 , kernel_size=1,\n",
    "                                     bias=True,\n",
    "                                     #weight_bit_width=weight_bit_width,\n",
    "                                     #input_quant=Int8ActPerTensorFloat, \n",
    "                                     bias_quant=Int8Bias,\n",
    "                                     #output_quant=Int8ActPerTensorFloat,\n",
    "                                     return_quant_tensor=True)\n",
    "        #print(self.conv3)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
    "        #self.maxpool3 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.relu3 = QuantReLU(return_quant_tensor=True)\n",
    "        '''\n",
    "        #Layer4\n",
    "        self.conv4 = qnn.QuantConv2d(in_channels=10, out_channels=10 , kernel_size=(1,5),\n",
    "                                     bias=True,\n",
    "                                     #weight_bit_width=weight_bit_width,\n",
    "                                     #input_quant=Int8ActPerTensorFloat, \n",
    "                                     bias_quant=Int8Bias,\n",
    "                                     #output_quant=Int8ActPerTensorFloat,\n",
    "                                     return_quant_tensor=True)\n",
    "        #print(self.conv4)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(10)\n",
    "        self.relu4 = QuantReLU(return_quant_tensor=True)\n",
    "        '''\n",
    "        #Layer5\n",
    "        self.fc1 = qnn.QuantLinear(in_features=64*4*4, out_features= 128, \n",
    "                                   bias=True,   \n",
    "                                   #weight_bit_width=weight_bit_width,\n",
    "                                   #output_quant=Int8ActPerTensorFloat,\n",
    "                                   bias_quant=Int8Bias,\n",
    "                                   return_quant_tensor=True)\n",
    "        #print(self.fc1)\n",
    "        self.relu5 = QuantReLU(return_quant_tensor=True)\n",
    "        \n",
    "        #Layer6\n",
    "        self.fc2 = qnn.QuantLinear(in_features=128, out_features=1, \n",
    "                                   bias=True,  \n",
    "                                   #weight_bit_width=weight_bit_width,\n",
    "                                   #output_quant=Int8ActPerTensorFloat,\n",
    "                                   bias_quant=Int8Bias,\n",
    "                                   return_quant_tensor=True)\n",
    "        #print(self.fc2)\n",
    "        #self.relu5 = QuantReLU(return_quant_tensor=True)\n",
    "        #self.relu6 = QuantSigmoid(return_quant_tensor=True)\n",
    "        '''\n",
    "        #Layer7\n",
    "        self.fc3 = qnn.QuantLinear(in_features=5, \n",
    "                                   #out_features=1, \n",
    "                                   #input_quant=Int8ActPerTensorFloat, \n",
    "                                   out_features=2,\n",
    "                                   bias=True, \n",
    "                                   #weight_bit_width=weight_bit_width,\n",
    "                                   #output_quant=Int8ActPerTensorFloat,\n",
    "                                   bias_quant=Int8Bias,\n",
    "                                   return_quant_tensor=True)'''\n",
    "        #print(self.fc3)\n",
    "        #self.sigmoid = QuantSigmoid(return_quant_tensor=True)\n",
    "        #self.sigmoid = nn.Sigmoid()\n",
    "        #'''\n",
    "        # Non Quantized\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass.\n",
    "        \n",
    "        Parameters\n",
    "        ---------\n",
    "        x: torch.Tensor\n",
    "            Batch of EEG windows of shape (batch_size, n_channels, n_times).\n",
    "        \"\"\"\n",
    "        \n",
    "        x = self.quant_identity(x)  # UNCOMMENT FOR QUANTIZATION \n",
    "        #print(f\"Input has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.conv1(x)\n",
    "        #print(f\"CONV1:\\n {x} \\n\")\n",
    "        #print(f\"CONV1 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.batchnorm1(x)\n",
    "        #print(f\"BN1 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.relu1(x)\n",
    "        #print(f\"R1 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.maxpool1(x)\n",
    "        #print(f\"MP1 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        #x = self.dropout(x)\n",
    "        #print(f\"DR1 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.conv2(x)\n",
    "        #print(f\"CONV2:\\n {x} \\n\")\n",
    "        #print(f\"CONV2 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.batchnorm2(x)\n",
    "        #print(f\"BN2 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.relu2(x)\n",
    "        #print(f\"R2 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.conv3(x)\n",
    "        #print(f\"CONV2:\\n {x} \\n\")\n",
    "        #print(f\"CONV2 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.batchnorm3(x)\n",
    "        #print(f\"BN2 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.relu3(x)\n",
    "        #print(f\"MP2 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        #x = self.dropout(x)\n",
    "        #print(f\"DR2 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.relu5(self.fc1(x.flatten(start_dim=1)))\n",
    "        #print(f\"FC1:\\n {x} \\n\")\n",
    "        #print(f\"FC1 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        #x = self.relu6(self.fc2(x))\n",
    "        x = self.fc2(x)\n",
    "        #print(f\"FC2:\\n {x} \\n\")\n",
    "        #print(f\"FC2 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        #x = self.sigmoid(self.fc3(x))\n",
    "        #x = self.fc3(x)\n",
    "        #print(f\"FC3:\\n {x} \\n\")\n",
    "        #print(f\"FC3 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IEEGSeizureDetection(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        input_size = 784\n",
    "        self.quant_inp = qnn.QuantIdentity(bit_width=4, return_quant_tensor=True)\n",
    "        self.fc1 = qnn.QuantLinear(input_size, 512, weight_bit_width=3, bias=True,bias_quant=Int8Bias,return_quant_tensor=True)\n",
    "        self.relu1 = qnn.QuantReLU(bit_width=4, return_quant_tensor=True)\n",
    "        self.fc2 = qnn.QuantLinear(512, 256, weight_bit_width=3, bias=True,bias_quant=Int8Bias,return_quant_tensor=True)\n",
    "        self.relu2 = qnn.QuantReLU(bit_width=4, return_quant_tensor=True)\n",
    "        self.fc3 = qnn.QuantLinear(256, 128, weight_bit_width=3, bias=True,bias_quant=Int8Bias,return_quant_tensor=True)\n",
    "        self.relu3 = qnn.QuantReLU(bit_width=4, return_quant_tensor=True)\n",
    "        self.fc4 = qnn.QuantLinear(128, 64, weight_bit_width=3, bias=True,bias_quant=Int8Bias,return_quant_tensor=True)\n",
    "        self.relu4 = qnn.QuantReLU(bit_width=4, return_quant_tensor=True)\n",
    "        self.fc5 = qnn.QuantLinear(64,1, weight_bit_width=3, bias=False)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        #return_quant_tensor = True to propogate QuantTensor across\n",
    "        #Quant_relu is stateful, so instantiate all of them separately\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.quant_inp(x)\n",
    "        x = self.dropout(self.relu1(self.fc1(x)))\n",
    "        x = self.dropout(self.relu2(self.fc2(x)))\n",
    "        x = self.dropout(self.relu3(self.fc3(x)))\n",
    "        x = self.dropout(self.relu4(self.fc4(x)))\n",
    "        x = self.fc5(x)\n",
    "        #x = nn.Sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### RUN\n",
    "# CSNN\n",
    "# neuron and simulation parameters\n",
    "spike_grad = surrogate.fast_sigmoid(slope=25)\n",
    "beta = 0.8\n",
    "num_steps = 50\n",
    "print(batch_size)\n",
    "'''\n",
    "# Define Network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers\n",
    "        self.conv1 = nn.Conv2d(1, 12, 5)\n",
    "        self.lif1 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
    "        self.conv2 = nn.Conv2d(12, 64, 5)\n",
    "        self.lif2 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
    "        self.fc1 = nn.Linear(64*4*4, 2)\n",
    "        self.lif3 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Initialize hidden states and outputs at t=0\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky() \n",
    "        mem3 = self.lif3.init_leaky()\n",
    "\n",
    "        # Record the final layer\n",
    "        spk3_rec = []\n",
    "        mem3_rec = []\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            cur1 = F.max_pool2d(self.conv1(x), 2)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = F.max_pool2d(self.conv2(spk1), 2)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            cur3 = self.fc1(spk2.view(batch_size, -1))\n",
    "            spk3, mem3 = self.lif3(cur3, mem3)\n",
    "\n",
    "            spk3_rec.append(spk3)\n",
    "            mem3_rec.append(mem3)\n",
    "\n",
    "        return torch.stack(spk3_rec), torch.stack(mem3_rec)\n",
    "\n",
    "#  Initialize Network \n",
    "net = Net().to(device)\n",
    "'''\n",
    "num_bits = 4\n",
    "net = nn.Sequential(\n",
    "                    qnn.QuantConv2d(1, 16, 5, bias=False, return_quant_tensor=True), #try 16\n",
    "                    #nn.Conv2d(1, 16, 5),\n",
    "                    nn.BatchNorm2d(16),\n",
    "                    nn.MaxPool2d(2),\n",
    "                    #nn.ReLU(),\n",
    "                    qnn.QuantReLU(return_quant_tensor=True),\n",
    "                    #snn.Leaky(beta=beta, threshold=1.0, spike_grad=spike_grad, init_hidden=True),\n",
    "                    qnn.QuantConv2d(16, 64, 5, bias=False,  return_quant_tensor=True),\n",
    "                    #nn.Conv2d(16, 64, 5),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                    nn.MaxPool2d(2),\n",
    "                    #nn.ReLU(),\n",
    "                    qnn.QuantReLU(return_quant_tensor=True),\n",
    "                    #snn.Leaky(beta=beta, threshold=1.0, spike_grad=spike_grad, init_hidden=True),\n",
    "                    nn.Flatten(),\n",
    "                    qnn.QuantLinear(64 * 4 * 4, 128, bias=False, return_quant_tensor=True),\n",
    "                    #nn.Linear(64*4*4, 128),\n",
    "                    #nn.ReLU(),\n",
    "                    qnn.QuantReLU(return_quant_tensor=True),\n",
    "                    #snn.Leaky(beta=beta, threshold=1.0, spike_grad=spike_grad, init_hidden=True),\n",
    "                    qnn.QuantLinear(128, 1, bias=False),\n",
    "                    #nn.Linear(128, 1),\n",
    "                    nn.Sigmoid(),\n",
    "                    #qnn.QuantSigmoid(return_quant_tensor=True)\n",
    "                    #snn.Leaky(beta=beta, threshold=1.0, spike_grad=spike_grad, init_hidden=True, output=True)\n",
    "                    ).to(device)\n",
    "net.apply(reset_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IEEGSeizureDetection_cnv()\n",
    "print(f'Using device \\'{device}\\'.')\n",
    "model = model.to(device)\n",
    "model.apply(reset_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def get_accuracy(y_true, y_prob):\n",
    "    print('True',y_true,'Pred',y_prob)\n",
    "    assert(len(y_true) == len(y_prob))\n",
    "    threshold = [0.5] * len(y_true)\n",
    "    accuracy = accuracy_score(y_true, y_prob > threshold)\n",
    "    return accuracy\n",
    "def get_accuracy_(y_true, y_prob):\n",
    "    #assert y_true.ndim == 1 and y_true.size() == y_prob.size()\n",
    "    y_prob = [t > 0.5 for t in y_prob]\n",
    "    print('True',y_true,'Pred',y_prob, len(y_true), len(y_prob))\n",
    "    accuracy = accuracy_score(y_true, y_prob)\n",
    "    return accuracy\n",
    "    #return (y_true == y_prob).sum().item() / y_true.size(0)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= 3.0e-3, betas=(0.9, 0.999))\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, \n",
    "                                                        T_max=4690, \n",
    "                                                        eta_min=0, \n",
    "                                                       last_epoch=-1)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCELoss()\n",
    "num_epochs = 100\n",
    "m = nn.Sigmoid()\n",
    "\n",
    "# keeping-track-of-losses \n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "y_prob_all, y_true_all, y_pred_all = list(), list(), list()\n",
    "y_prob_all_test, y_true_all_test, y_pred_all_test = list(), list(), list()\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    \n",
    "    # keep-track-of-training-and-validation-loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    # training-the-model\n",
    "    model.train()\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        # move-tensors-to-GPU \n",
    "        data = data.to(device)\n",
    "        #print('data', data.shape)\n",
    "        target = target.to(device)\n",
    "        #print('target', target.shape)\n",
    "        \n",
    "        # clear-the-gradients-of-all-optimized-variables\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward-pass: compute-predicted-outputs-by-passing-inputs-to-the-model\n",
    "        output = model(data)\n",
    "        output_s = m(output)\n",
    "        #print('output', output.shape)\n",
    "\n",
    "        #print(pred)\n",
    "        # calculate-the-batch-loss\n",
    "        loss = criterion(output_s, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        predicted = output_s > 0.5\n",
    "        #print('Predicted', predicted, predicted.shape)\n",
    "        total_train += target.size(0)\n",
    "        correct_train += (predicted == target).sum().item()\n",
    "        y_prob_all.append(torch.squeeze(output_s).detach().cpu().numpy())\n",
    "        y_true_all.append(torch.squeeze(target).cpu().numpy())\n",
    "        y_pred_all.append(torch.squeeze(predicted).cpu().numpy().astype(float) )\n",
    "        #y_pred_all.append((out_sigmoid.cpu().numpy() > 0.5))\n",
    "        # update-training-loss\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "    \n",
    "    y_prob = np.concatenate(y_prob_all)\n",
    "    y_true = np.concatenate(y_true_all)\n",
    "    y_pred = np.concatenate(y_pred_all)\n",
    "    print('what true',y_true.shape, y_true, 'pred', y_pred.shape, y_pred)\n",
    "    acc_train = accuracy_score(y_true, y_pred)\n",
    "    #acc = np.mean(y_true == y_pred)  \n",
    "    perf_train = 100 * correct_train / total_train\n",
    "    print('Training accuracy', acc_train)\n",
    "    \n",
    "    # validate-the-model\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in valid_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            output_s = m(output)\n",
    "            loss = criterion(output_s, target)\n",
    "        \n",
    "            predicted = output_s > 0.5\n",
    "            total_test += target.size(0)\n",
    "            correct_test += (predicted == target).sum().item()\n",
    "            y_prob_all_test.append(output_s.cpu().numpy())\n",
    "            y_true_all_test.append(target.cpu().numpy())\n",
    "            y_pred_all_test.append(predicted.cpu().numpy())\n",
    "            # update-average-validation-loss\n",
    "            valid_loss += loss.item() * data.size(0)\n",
    "    \n",
    "    y_prob_test = np.concatenate(y_prob_all_test)\n",
    "    y_true_test = np.concatenate(y_true_all_test)\n",
    "    y_pred_test = np.concatenate(y_pred_all_test)\n",
    "    acc_test = accuracy_score(y_true_test, y_pred_test)\n",
    "    #perf_test = get_accuracy_(y_true_all_test, y_prob_all_test)\n",
    "    perf_test = 100 * correct_test / total_test\n",
    "    print('Test accuracy', acc_test)\n",
    "    \n",
    "    # calculate-average-losses\n",
    "    train_loss = train_loss/len(train_loader.sampler)\n",
    "    valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    # print-training/validation-statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\t Train_perf: {:.6f}\\t Test_perf: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss, perf_train, perf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './saved_models/cnn_tf_model_442_cnv2D.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test-the-model\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "model.eval()  # it-disables-dropout\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_pred_all_eval, y_true_all_eval, y_score_all_eval = list(), list(), list()\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        print('Labels', labels, labels.shape)\n",
    "        outputs = model(images)\n",
    "        output_s = m(outputs)\n",
    "        #print('Output', outputs, outputs.shape)\n",
    "        #_, predicted = torch.max(outputs.data, 1)\n",
    "        predicted = output_s > 0.5\n",
    "        print('PRedicted', predicted, predicted.shape)\n",
    "        print('check shape', images.shape, labels.shape, outputs.shape, output_s.shape)\n",
    "        #print('Predicted', predicted, predicted.shape)\n",
    "        #total += labels.size(0)\n",
    "        #correct += (predicted == labels).sum().item() \n",
    "        y_pred_all_eval.append(predicted.cpu().numpy())\n",
    "        y_true_all_eval.append(labels.cpu().numpy())\n",
    "        \n",
    "    y_pred = np.concatenate(y_pred_all_eval)\n",
    "    y_true = np.concatenate(y_true_all_eval)\n",
    "    #y_score = np.concatenate(y_score_all)\n",
    "    \n",
    "    #f1_score_eval = f1_score(torch.squeeze(labels).numpy(), torch.squeeze(predicted).numpy())\n",
    "    f1_score_eval = f1_score(y_true,y_pred)\n",
    "    confusion_matrice = confusion_matrix(y_true,y_pred)\n",
    "    accuracy_eval = accuracy_score(y_true,y_pred)\n",
    "    print('f1_score', f1_score_eval, 'Accuracy', accuracy_eval, 'Confusion matrix', confusion_matrice)\n",
    "    #print('Test Accuracy of the model: {} %'.format(100 * correct / total))\n",
    "# Save \n",
    "#torch.save(net.state_dict(), './saved_models/cnn_tf_model_442.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(valid_losses, label='Validation loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckp(checkpoint_fpath):\n",
    "    \n",
    "    # load check point on CPU\n",
    "    device = torch.device('cpu')\n",
    "    model = IEEGSeizureDetection_cnv()\n",
    "    model.load_state_dict(torch.load(checkpoint_fpath, map_location=device))\n",
    "    print(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckp_path ='./saved_models/cnn_tf_model_442_cnv2D.pth'\n",
    "#print(model)\n",
    "fc = load_ckp(ckp_path)\n",
    "fc = fc\n",
    "fc.eval()\n",
    "print(next(fc.parameters()).device)\n",
    "print(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to ONNX : GPU-trained model to be loaded using the CPU.\n",
    "from brevitas.export import FINNManager\n",
    "from brevitas.export.onnx.generic.manager import BrevitasONNXManager\n",
    "import netron\n",
    "\n",
    "FINNManager.export(fc, input_shape=(1, 1, 28, 28), export_path='./saved_models/ONNX_CNN_TF_442_cnv2D.onnx')\n",
    "#netron.start('./saved_models/ONNX_CNN_TF_442.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### RUN\n",
    "#optimizer = torch.optim.Adam(net.parameters(), lr=1e-2, betas=(0.9, 0.999))\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr= 3.0e-3, betas=(0.9, 0.999))\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, \n",
    "                                                        T_max=4690, \n",
    "                                                        eta_min=0, \n",
    "                                                        last_epoch=-1)\n",
    "\n",
    "num_epochs = 50\n",
    "loss_hist = []\n",
    "acc_hist = []\n",
    "correct = 0\n",
    "total = 0\n",
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, targets) in enumerate(iter(train_loader)):\n",
    "        data = data.to(device)\n",
    "        #print('Before',data)\n",
    "        targets = targets.to(device)\n",
    "        data = spikegen.rate(data, num_steps=num_steps)\n",
    "        #print('After:', data)\n",
    "\n",
    "        net.train()\n",
    "        spk_rec = forward_pass(net, data)\n",
    "        loss_val = loss_fn(spk_rec, torch.squeeze(targets,1).type(torch.LongTensor))\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Store loss history for future plotting\n",
    "        loss_hist.append(loss_val.item())\n",
    " \n",
    "        print(f\"Epoch {epoch}, Iteration {i} \\nTrain Loss: {loss_val.item():.2f}\")\n",
    "        _, idx = spk_rec.sum(dim=0).max(1)\n",
    "        print('target', torch.squeeze(targets,1), 'prediction', idx)\n",
    "        target_for_comp =  torch.squeeze(targets,1)\n",
    "        accuracy = np.mean((target_for_comp == idx).detach().cpu().numpy())\n",
    "        temp = (target_for_comp == idx).detach().cpu().numpy()\n",
    "        print('Mean accuracy from sum', np.mean((target_for_comp == idx).detach().cpu().numpy()))\n",
    "         #64*64\n",
    "        #acc = SF.accuracy_rate(spk_rec, targets) \n",
    "        acc_hist.append(accuracy)\n",
    "        print(f\"Accuracy: {accuracy* 100:.2f}%\\n\")\n",
    "        total += target_for_comp.size(0)\n",
    "        correct += accuracy * target_for_comp.size(0)\n",
    "        print('targets.size(0)', target_for_comp.size(0))\n",
    "        print('Total and correct', total,correct)\n",
    "        print('Calculated accuracy for an iteration is',100 * correct / total)\n",
    "        \n",
    "        # This will end training after 50 iterations by default\n",
    "        #if i == num_iters:\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), './saved_models/inference' + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_inf = nn.Sequential(#qnn.QuantConv2d(1, 16, 5, bias=False, return_quant_tensor=True), #try 16\n",
    "                    nn.Conv2d(1, 16, 5),\n",
    "                    nn.BatchNorm2d(16),\n",
    "                    nn.MaxPool2d(2),\n",
    "                    snn.Leaky(beta=beta, threshold=1.0, spike_grad=None, init_hidden=True),\n",
    "                    #qnn.QuantConv2d(16, 64, 5, bias=False,  return_quant_tensor=True),\n",
    "                    nn.Conv2d(16, 64, 5),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                    nn.MaxPool2d(2),\n",
    "                    snn.Leaky(beta=beta, threshold=1.0, spike_grad=None, init_hidden=True),\n",
    "                    nn.Flatten(),\n",
    "                    #qnn.QuantLinear(64 * 4 * 4, 128, bias=False, return_quant_tensor=True),\n",
    "                    nn.Linear(64*4*4, 128),\n",
    "                    snn.Leaky(beta=beta, threshold=1.0, spike_grad=None, init_hidden=True),\n",
    "                    #qnn.QuantLinear(128, 2, bias=False),\n",
    "                    nn.Linear(128, 2),\n",
    "                    snn.Leaky(beta=beta, threshold=1.0, spike_grad=None, init_hidden=True, output=True)\n",
    "                    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckp(checkpoint_fpath):\n",
    "    \n",
    "    # load check point on CPU\n",
    "    device = torch.device('cpu')\n",
    "    model = net_inf\n",
    "    model.load_state_dict(torch.load(checkpoint_fpath, map_location=device))\n",
    "    print(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckp_path ='./saved_models/inference' + '.pth'\n",
    "#print(model)\n",
    "fc = load_ckp(ckp_path)\n",
    "fc = fc\n",
    "fc.eval()\n",
    "print(next(fc.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Export to ONNX : GPU-trained model to be loaded using the CPU.\n",
    "from brevitas.export import FINNManager\n",
    "from brevitas.export.onnx.generic.manager import BrevitasONNXManager\n",
    "\n",
    "FINNManager.export(fc, input_shape=(1, 1, 28, 28), export_path='./saved_models/ONNX_inference.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netron\n",
    "netron.start('./saved_models/ONNX_inference.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Export to ONNX\n",
    "FINNManager.export(net, input_shape=(1, 1, 28, 28), export_path='./saved_models/ONNX_' + pat_id + '.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.custom_op.base import CustomOp\n",
    "dir(CustomOp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print model parameters\n",
    "#for name, param in net.named_parameters():\n",
    "#    if param.requires_grad:\n",
    "#        print(name, param.data)\n",
    "\n",
    "# Calculate model size\n",
    "param_size = 0\n",
    "for param in net.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "buffer_size = 0\n",
    "for buffer in net.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "print('model size: {:.3f}MB'.format(size_all_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in net.state_dict():\n",
    "    print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "def batch_accuracy(train_loader, net, num_steps):\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        acc = 0\n",
    "        net.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        train_loader = iter(train_loader)\n",
    "        for data, targets in train_loader:\n",
    "            data = data.to(device)\n",
    "            data = spikegen.rate(data, num_steps=num_steps)\n",
    "            targets = targets.to(device)\n",
    "            target_for_comp =  torch.squeeze(targets,1)\n",
    "            #spk_rec, _ = forward_pass(net, num_steps, data)\n",
    "            spk_rec = forward_pass(net, data)\n",
    "            \n",
    "            _, idx = spk_rec.sum(dim=0).max(1)\n",
    "            \n",
    "            #acc += SF.accuracy_rate(spk_rec, targets) * spk_rec.size(1)\n",
    "            #total += spk_rec.size(1)\n",
    "            accuracy = np.mean((target_for_comp == idx).detach().cpu().numpy())\n",
    "            #print(f\"Accuracy: {accuracy* 100:.2f}%\\n\")\n",
    "            total += target_for_comp.size(0)\n",
    "            correct += accuracy * target_for_comp.size(0)\n",
    "            print('targets.size(0)', target_for_comp.size(0))\n",
    "            print('Total and correct', total,correct)\n",
    "            print('Calculated ACCURACY for an iteration is',100 * correct / total)\n",
    "            f1_eval = f1_score(target_for_comp, idx, average='weighted')\n",
    "            print('y_true',target_for_comp,'y_pred',idx)\n",
    "            #print('Test: Accuracy', acc/total)\n",
    "            print('F1_SCORE:',f1_eval)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = batch_accuracy(test_loader, net, num_steps)\n",
    "\n",
    "print(f\"The total accuracy on the test set is: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN\n",
    "# Plot Loss\n",
    "acc_hist_epoch = []\n",
    "acc_hist_epoch = acc_hist[::50]\n",
    "fig = plt.figure(facecolor=\"w\")\n",
    "plt.plot(acc_hist_epoch)\n",
    "plt.title(\"Train Set Accuracy\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "#For more channels, patients, data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Experiments:\n",
    "    1. Test the data trained on another patient (Train on 139 and test on all of 253)\n",
    "    2. Channel information\n",
    "    3. Quantisation - check\n",
    "    4. Visualize Graph ,summary, Layerwise\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### RUN\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader,ConcatDataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "class CustomDataset_reload(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        #self.imgs_path = \"./TF_images_ictal_nonictal/\"\n",
    "        #self.imgs_path = \"./TF_plot_images/pat_139/\"\n",
    "        self.imgs_path = \"./TF_plot_images_rand/\" + pat_id + \"/test_data/\"\n",
    "        file_list = glob.glob(self.imgs_path + \"*\")\n",
    "        print(file_list)\n",
    "        self.data = []\n",
    "        for class_path in file_list:\n",
    "            class_name = class_path.split(\"/\")[-1]\n",
    "            for img_path in glob.glob(class_path + \"/*.png\"):\n",
    "                self.data.append([img_path, class_name])\n",
    "        print('self.data length',len(self.data))\n",
    "        self.class_map = {\"non_ictal\" : 0, \"ictal\": 1}\n",
    "        self.img_dim = (28, 28)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, class_name = self.data[idx]\n",
    "        #print('img_path', img_path.shape, img_path.type)\n",
    "        #make it into a function\n",
    "        '''\n",
    "        header = ['File Name', 'Pat_ID', 'channel', 'Seizure number','Epoch','Label','Prediction']\n",
    "        file = open(\"Eval_plot_data.csv\", \"w\")\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(header)\n",
    "        #./TF_plot_images/pat_442/test_data/ictal/EEG_inv_442_HRA4_sNo_17_226_1.png\n",
    "        pat_id = str(img_path)[-25:-23]\n",
    "        channel = str(img_path)[-21:-18]\n",
    "        seizure_n = str(img_path)[-12:-11]\n",
    "        sample = str(img_path)[-9:-7]\n",
    "        label_ = str(img_path)[-5]\n",
    "        for w in range(0,len(self.data)):\n",
    "            writer.writerow([str(img_path), pat_id,channel, seizure_n, sample, label_ ])\n",
    "        file.close()\n",
    "        print('Write to csv', img_path, class_name)\n",
    "        '''\n",
    "        \n",
    "        img = cv2.imread(img_path)                      # Load Image \n",
    "        #print('shape for original image',img.shape)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)    # in grayscale\n",
    "        #img = img[:,:,2]                                # take red component only\n",
    "        #print('shape for image grayscale',img.shape)\n",
    "        img = img[60:60+366, 81:81+396]                 # Crop image  \n",
    "        #print('shape for image cropped',img.shape)\n",
    "        img = cv2.bitwise_not(img)                      # Negativ-positiv inversion #TODO: improve this\n",
    "        #print('shape for image bitwise not',img.shape)\n",
    "        img = cv2.resize(img, self.img_dim)             # resize\n",
    "        #print('shape for image resize',img.shape)\n",
    "        #img_tensor = torch.from_numpy(img)\n",
    "        #img_tensor = torch.unsqueeze(img_tensor, 0).float()\n",
    "        #print('shape for image before',img_tensor.shape)\n",
    "        if self.transform is not None:\n",
    "            img_tensor = self.transform(img)\n",
    "            img_tensor = img_tensor.float()\n",
    "            #print('return type of transform',img_tensor.shape, img_tensor.dtype)\n",
    "        class_id = self.class_map[class_name]\n",
    "        #if class_id == 1:\n",
    "        #    cv2.imshow('rgb image', img)\n",
    "        #    cv2.waitKey(5)\n",
    "        #print('Label is ', class_id)\n",
    "        #img_tensor = img_tensor.permute(2, 0, 1)     # for BGR image\n",
    "        class_id = torch.tensor([class_id])\n",
    "        #print('data', img_tensor.float().shape , 'targets', class_id.float().shape)\n",
    "        return img_tensor.float(), class_id.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(conf_mat):\n",
    "    classes_mapping = {0: 'non-ictal', 1: 'ictal'} \n",
    "    ticks = list(classes_mapping.keys())\n",
    "    tick_labels = classes_mapping.values()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    im = ax.imshow(conf_mat, cmap='Reds')\n",
    "    ax.set_yticks(ticks)\n",
    "    ax.set_yticklabels(tick_labels)\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_xticklabels(tick_labels)\n",
    "    ax.set_ylabel('True label')\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    ax.set_title('Confusion matrix')\n",
    "\n",
    "    for i in range(len(ticks)):\n",
    "        for j in range(len(ticks)):\n",
    "            text = ax.text(\n",
    "                j, i, conf_mat[i, j], ha='center', va='center', color='k')\n",
    "\n",
    "    fig.colorbar(im, ax=ax, fraction=0.05, label='# examples')\n",
    "    fig.tight_layout()\n",
    "    #fig.savefig('./save_plot/confusion_matrix_'+i+'.png')\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "np.set_printoptions(threshold=40)\n",
    "\n",
    "def batch_accuracy_eval(train_loader, net, num_steps):\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        acc = 0\n",
    "        net.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        y_pred_all, y_true_all, f1_all = list(), list(), list()\n",
    "        train_loader = iter(train_loader)\n",
    "        for data, targets in train_loader:\n",
    "            data = data.to(device)\n",
    "            data = spikegen.rate(data, num_steps=num_steps)\n",
    "            targets = targets.to(device)\n",
    "            target_for_comp =  torch.squeeze(targets,1)\n",
    "            #spk_rec, _ = forward_pass(net, num_steps, data)\n",
    "            spk_rec = forward_pass(net, data)\n",
    "            \n",
    "            _, idx = spk_rec.sum(dim=0).max(1)\n",
    "            \n",
    "            #acc += SF.accuracy_rate(spk_rec, targets) * spk_rec.size(1)\n",
    "            #total += spk_rec.size(1)\n",
    "            accuracy = np.mean((target_for_comp == idx).detach().cpu().numpy())\n",
    "            #print(f\"Accuracy: {accuracy* 100:.2f}%\\n\")\n",
    "            total += target_for_comp.size(0)\n",
    "            correct += accuracy * target_for_comp.size(0)\n",
    "            print('targets.size(0)', target_for_comp.size(0))\n",
    "            print('Total and correct', total,correct)\n",
    "            print('Calculated ACCURACY for an iteration is',100 * correct / total)\n",
    "            f1_eval = f1_score(target_for_comp, idx, average='binary')\n",
    "            print('y_true',target_for_comp,'y_pred',idx)\n",
    "            \n",
    "            y_pred_all.append(idx)\n",
    "            y_true_all.append(target_for_comp)\n",
    "            #f1_all.append(f1_eval)\n",
    "            #print('Test: Accuracy', acc/total)\n",
    "            print('F1_SCORE:',f1_eval)\n",
    "    \n",
    "    y_pred = np.concatenate(y_pred_all)\n",
    "    y_true = np.concatenate(y_true_all)\n",
    "    print('y_true', y_true, 'y_pred', y_pred)\n",
    "    f1_comp = f1_score(y_true, y_pred)\n",
    "    print('Check dimensions', y_pred.shape, y_true.shape)\n",
    "    print('Total f1 score',f1_comp)\n",
    "    \n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "    tn, false_positives, fn, tp = conf_mat.ravel()\n",
    "    print('conf_mat', conf_mat)\n",
    "    \n",
    "    plot_confusion_matrix(conf_mat)\n",
    "    \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pat_253 dataset\n",
    "batch_size = 64\n",
    "device = 'cpu'\n",
    "num_workers = 0 \n",
    "num_steps = 50\n",
    "\n",
    "transform = transforms.Compose([\n",
    "            #transforms.Resize((32, 32)),\n",
    "            #transforms.Grayscale(),     #Returns PIL image\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0,), (1,))  # ToTensor and Normalize work together\n",
    "        ])\n",
    "\n",
    "dataset_test = CustomDataset_reload(transform = transform)\n",
    "test_loader = DataLoader(dataset_test, batch_size= dataset_test.__len__(), shuffle=False, num_workers=num_workers)\n",
    "print('Total samples', len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model for patient 139\n",
    "torch.save(net.state_dict(), './saved_models/TF_ ' + pat_id + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(test_loader_253):\n",
    "    print(\"batch index {}, 0/1: {}/{}\".format(\n",
    "        i, (y == 0).sum(), (y == 1).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test on entire dataset of pat_253\n",
    "beta = 0.8\n",
    "num_steps=50\n",
    "spike_grad = surrogate.fast_sigmoid(slope=25)\n",
    "num_bits = 4\n",
    "'''\n",
    "net_253 = nn.Sequential(nn.Conv2d(1, 12, 5),\n",
    "                    nn.BatchNorm2d(12),\n",
    "                    nn.MaxPool2d(2),\n",
    "                    snn.Leaky(beta=beta, threshold=1.0, spike_grad=spike_grad, init_hidden=True),\n",
    "                    nn.Conv2d(12, 64, 5),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                    nn.MaxPool2d(2),\n",
    "                    snn.Leaky(beta=beta, threshold=1.0, spike_grad=spike_grad, init_hidden=True),\n",
    "                    nn.Flatten(),\n",
    "                    nn.Linear(64*4*4, 128),\n",
    "                    snn.Leaky(beta=beta, threshold=1.0, spike_grad=spike_grad, init_hidden=True),\n",
    "                    nn.Linear(128, 2),\n",
    "                    snn.Leaky(beta=beta, threshold=1.0, spike_grad=spike_grad, init_hidden=True, output=True)\n",
    "                    ).to(device)'''\n",
    "\n",
    "net_253 = nn.Sequential(#qnn.QuantConv2d(1, 16, 5, bias=False, weight_bit_width= num_bits,return_quant_tensor=True), #try 16\n",
    "                    nn.Conv2d(1, 16, 5),\n",
    "                    nn.BatchNorm2d(16),\n",
    "                    nn.MaxPool2d(2),\n",
    "                    snn.Leaky(beta=beta, threshold=1.0, spike_grad=spike_grad, init_hidden=True),\n",
    "                    #qnn.QuantConv2d(16, 64, 5, bias=False, weight_bit_width=num_bits, return_quant_tensor=True),\n",
    "                    nn.Conv2d(16, 64, 5),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                    nn.MaxPool2d(2),\n",
    "                    snn.Leaky(beta=beta, threshold=1.0, spike_grad=spike_grad, init_hidden=True),\n",
    "                    nn.Flatten(),\n",
    "                    #qnn.QuantLinear(64 * 4 * 4, 128, bias=False, weight_bit_width=num_bits, return_quant_tensor=True),\n",
    "                    nn.Linear(64*4*4, 128),\n",
    "                    snn.Leaky(beta=beta, threshold=1.0, spike_grad=spike_grad, init_hidden=True),\n",
    "                    #qnn.QuantLinear(128, 2, bias=False, weight_bit_width=num_bits),\n",
    "                    nn.Linear(128, 2),\n",
    "                    snn.Leaky(beta=beta, threshold=1.0, spike_grad=spike_grad, init_hidden=True, output=True)\n",
    "                    ).to(device)\n",
    "\n",
    "net_253.apply(reset_weights)\n",
    "\n",
    "net_253.load_state_dict(torch.load('./saved_models/TF_ ' + pat_id + '.pth'))\n",
    "#model.eval()\n",
    "test_acc_253 = batch_accuracy_eval(test_loader_253, net_253, num_steps)\n",
    "\n",
    "print(f\"The total accuracy on the test set is: {test_acc_253 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print model parameters\n",
    "net_253.load_state_dict(torch.load('./saved_models/TF_ ' + pat_id + '_16.pth'))\n",
    "for name, param in net_253.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data, param.data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate model size , check data type of weights\n",
    "model = net_253\n",
    "param_size = 0\n",
    "for param in model.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "buffer_size = 0\n",
    "for buffer in model.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "print('model size: {:.3f}MB'.format(size_all_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
