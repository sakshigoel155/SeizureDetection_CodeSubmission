{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "#import tensorflow as tf\n",
    "#tf.config.list_physical_devices(\"GPU\")\n",
    "print(torch.__version__) \n",
    "#print(tf.__version__)\n",
    "print(torch.cuda.get_arch_list())\n",
    "print(torch.version.cuda) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path = './patient_info_txt/data_files_'\n",
    "csv_file_path = './patient_info_txt/Invasive_data_'\n",
    "patient_id = [115,139,253,264,442,583,620,635,862,958,1146]\n",
    "p_id = 1\n",
    "interval = 2\n",
    "test_list = [80] #7[12,14] #8[106,109] #9[80,81]\n",
    "soz_channel_list = {                      #seizure\n",
    "    115 : [\"HR3\",\"HR4\",\"HR5\",\"HR6\"],      #26\n",
    "    139 : [\"HL2\",\"HL4\",\"HL3\",\"TBA1\"],     #6   1\n",
    "    253 : [\"HRB2\",\"HRC2\",\"HRB3\",\"HRC3\"],  #7   y\n",
    "    264 : [\"BLA1\",\"BLC1\",\"BRA1\",\"TRA3\"],  #8   y\n",
    "    442 : [\"HRA4\",\"TBA1\",\"HRA5\",\"TBA2\"],  #22  y\n",
    "    583 : [\"TLB1\",\"TLA1\",\"HL1\",\"TBA1\"],   #23  \n",
    "    620 : [\"TLA1\",\"TLB2\",\"TLB3\",\"TLA2\"],  #7\n",
    "    635 : [\"HL1\",\"HL9\",\"HRA1\",\"HRA2\"],    #21  y\n",
    "    862 : [\"IHB2\",\"IHB3\",\"IHB1\",\"GC7\"],   #9   y\n",
    "    958 : [\"GE3\",\"GH6\",\"OPL5\",\"TBB2\"],    #16  \n",
    "    1146 : [\"ICL1\",\"SCL7\",\"SCL8\",\"SCR5\"], #26\n",
    "}\n",
    "print(soz_channel_list[patient_id[p_id]], [patient_id[p_id]], test_list)\n",
    "patient_channels = soz_channel_list[patient_id[p_id]]\n",
    "#patient_channels = patient_channel[:1]     # for conv1D\n",
    "#print(patient_channels, patient_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import mne\n",
    "from mne.time_frequency import psd_welch\n",
    "import csv\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "datetimeFormat = '%Y-%m-%d %H:%M:%S.%f'\n",
    "import re\n",
    "#import imblearn\n",
    "\n",
    "from numpy.fft import fft, fftfreq\n",
    "from scipy import signal\n",
    "from mne.time_frequency import tfr_morlet\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "%matplotlib notebook\n",
    "mne.set_log_level('ERROR') \n",
    "\n",
    "#NEW!!! (Imports for Quantization)  brevitas-0.7.1\n",
    "import onnx   # Import onnx before torch\n",
    "import onnxoptimizer as opt\n",
    "import torch.onnx\n",
    "import torch\n",
    "import torchvision\n",
    "import brevitas.nn as qnn\n",
    "\n",
    "\n",
    "#path_to_data = './patient_info_txt/data_files_442.txt'\n",
    "#path_to_csv = './patient_info_txt/Invasive_data_442.csv'\n",
    "\n",
    "path_to_data = data_file_path + str(patient_id[p_id]) + '.txt'\n",
    "path_to_csv = csv_file_path + str(patient_id[p_id]) + '.csv'\n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "def square_data(inputs):\n",
    "    data_df = pd.Series(inputs)\n",
    "    data_df_sq = data_df.pow(2)\n",
    "    data_df_np = data_df_sq.to_numpy()\n",
    "    return data_df_np\n",
    "\n",
    "def normalize_data(inputs):\n",
    "    data_df_HRC1 = pd.Series(inputs)\n",
    "    data_df_std_dev = data_df_HRC1.rolling(time_steps).std() # 30 seconds\n",
    "    data_df_norm = data_df_HRC1.divide(data_df_std_dev)  \n",
    "    data_df_norm[:time_steps-1].update(data_df_HRC1[:time_steps-1]) # if NaN, norm = original value\n",
    "    data_df_HRC1_np = data_df_norm.to_numpy()\n",
    "    return data_df_HRC1_np\n",
    "\n",
    "def diff_data(inputs):  #TODO : Do this before rereferencing\n",
    "    data_df = pd.Series(inputs)\n",
    "    data_df_diff= data_df.diff()\n",
    "    data_df_np = data_df_diff.to_numpy()\n",
    "    return data_df_np\n",
    "\n",
    "def dur(num):\n",
    "    if num/60 > 1:\n",
    "        return 60.0\n",
    "    else:\n",
    "        return float(num)\n",
    "\n",
    "#Reref    \n",
    "#HRA = ['HRA1','HRA2','HRA3','HRA4','HRA5']\n",
    "#HRB = ['HRB1','HRB2','HRB3','HRB4','HRB5','HRC1','HRC2','HRC3','HRC4','HRC5']\n",
    "#HRC = ['HRB1','HRB2','HRB3','HRB4','HRB5','HRC1','HRC2','HRC3','HRC4','HRC5']\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA-enabled GPU found. Training should be faster.')\n",
    "else:\n",
    "    print('No GPU found. Training will be slow')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#device = 'cpu'\n",
    "my_database ={'Patient 1':{'PatientID': 0, 'FileID': [], 'Frequency': 512, 'Duration': 0}}\n",
    "\n",
    "print('HERE WE GO!!!!!!!!!!!!!!')\n",
    "with open(path_to_data) as file:\n",
    "    lines = file.readlines()\n",
    "    lines_iter = iter(lines)\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "    #print('lines', lines, len(lines))\n",
    "            \n",
    "def load_raw_dataset(line, my_database):\n",
    "    \"\"\"Load a recording from the iEEG dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_fname : str\n",
    "        Path to the .data file containing the raw data.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    mne.io.Raw :\n",
    "        Raw object containing the EEG. \n",
    "    \"\"\"\n",
    "    #for line in range(0,len(lines)):\n",
    "    print(line, type(line))\n",
    "    #if not line.startswith(\"#\"):\n",
    "    entry = 'EEG_inv_' + str(line)[-18:-15] + '_' + str(line)[-9:-5]\n",
    "    print('Value for entry',entry)\n",
    "    my_database['Patient 1']['PatientID'] = str(line)[-18:-15]\n",
    "    my_database['Patient 1']['FileID'] = str(line)[-9:-5]\n",
    "    print(my_database)\n",
    "    data_raw =  mne.io.read_raw_nicolet(str(line), 'eeg', preload=True)\n",
    "    \n",
    "    subj_num, rec_num = int(str(line)[-18:-15]), int(str(line)[-9:-5])\n",
    "    print('subj_num',subj_num ,'rec_num',rec_num)\n",
    "    data_raw.info['subject_info'] = {'id': subj_num, 'rec_id': rec_num}\n",
    "    return data_raw\n",
    "\n",
    "# Check \n",
    "#load_raw_dataset(lines,my_database)\n",
    "# Load recordings\n",
    "data_raws = [load_raw_dataset(line, my_database) for line in lines]\n",
    "print('Database entries',len(data_raws) , type(data_raws) )\n",
    "\n",
    "#for idx in range(0,len(data_raws)):\n",
    "#    print(data_raws[idx].info)\n",
    "#    print(data_raws[idx].plot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raws = []\n",
    "cnt = 0\n",
    "for line in lines:\n",
    "    data_raw = load_raw_dataset(line, my_database)\n",
    "    data_raws.append(data_raw)\n",
    "    cnt +=1\n",
    "    if cnt == 16:\n",
    "        break\n",
    "#print('Database entries',len(data_raws) , type(data_raws) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.__version__) # 1.4.1\n",
    "print(np.__version__) #1.21.2\n",
    "print(matplotlib.__version__) #3.5.1\n",
    "print(sklearn.__version__) #1.0.2\n",
    "print(mne.__version__) #0.24.1\n",
    "print(onnx.__version__) #1.10.2 , onnxoptimizer-0.2.7,  netron-5.7.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set reference channel for all data points for all channels individually\n",
    "def set_reference(data_raw, p_id):\n",
    "    data_array = []\n",
    "    sfreq = data_raw.info['sfreq']\n",
    "    print('sfreq', sfreq)\n",
    "    print('4 electrodes for the patient',soz_channel_list[patient_id[p_id]][:1])\n",
    "    patient_channels = soz_channel_list[patient_id[p_id]]  # conv1D\n",
    "    print('patient channels',patient_channels)\n",
    "    all_channels = data_raw.ch_names\n",
    "    #print('all channels',all_channels)\n",
    "    for item in patient_channels:\n",
    "        #print('For channel', item)\n",
    "        ch_group = \" \".join(re.findall(\"[a-zA-Z]+\", item))\n",
    "        ch_group = str(ch_group)\n",
    "        ch_group = [x for x in all_channels if re.search(ch_group, x)]\n",
    "        #print('Electrode group', str(ch_group))\n",
    "        data_ch_dict = data_raw.copy()\n",
    "        data_ch_dict = data_ch_dict.pick_channels(ch_names= ch_group, ordered=False)\n",
    "        data_ch_dict.set_eeg_reference(ref_channels= ch_group)\n",
    "        data_ch_dict = data_ch_dict.pick_channels(ch_names= [item], ordered=False)\n",
    "        df_channel = data_ch_dict.to_data_frame()\n",
    "        #print('Each channel', df_channel)\n",
    "        #print('Info', data_ch_dict.info)\n",
    "        df_channel_array = np.array(df_channel[item])\n",
    "        #print(df_channel_array, df_channel_array.shape)\n",
    "        data_array.append(df_channel_array)\n",
    "        \n",
    "    reref_data = np.array(data_array)\n",
    "    print('reref data', reref_data, reref_data.shape)\n",
    "    info = mne.create_info(ch_names= patient_channels, sfreq=sfreq, ch_types = ['eeg']* 4) #conv1D\n",
    "    print('Assert',len(reref_data), len(info['ch_names']), patient_channels)\n",
    "    simulated_raw = mne.io.RawArray(reref_data, info)\n",
    "    #print(simulated_raw.info)\n",
    "    return simulated_raw \n",
    "\n",
    "reref_raws = []\n",
    "for idx in range(0,len(data_raws)):\n",
    "    #print('BEFORE RE-REFERENCING',data_raws[idx].info)\n",
    "    #data_raws[idx].plot()\n",
    "    reref_raws.append(set_reference(data_raws[idx],p_id))\n",
    "    #reref_raws[idx] = set_reference(data_raws[idx],2)\n",
    "    #print('AFTER RE-REFERENCING',reref_raws[idx].info)\n",
    "    #reref_raws[idx].plot()\n",
    "    #break\n",
    "\n",
    "print(reref_raws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_clinical_file = './patient_info_txt/subclinical/subclinical_data_' + str(patient_id[p_id]) + '.csv'\n",
    "print(sub_clinical_file)\n",
    "def remove_sub_clinical_s(sub_clinical_file , raw, csv_row):\n",
    "    onset_sub_list = []\n",
    "    dur_sub_list = []\n",
    "    desc_list = []\n",
    "    \n",
    "    #Selectively read csv file\n",
    "    df_subclinical = pd.read_csv(sub_clinical_file, usecols=['meas_date','onset', 'offset','Seizure','File'])\n",
    "    \n",
    "    #Generate information on number of seizures in a file\n",
    "    df_file = df_subclinical.loc[df_subclinical['File'] == csv_row]\n",
    "    all_meas_data = df_file.iloc[0,0]\n",
    "    all_onset = df_file['onset'].tolist()\n",
    "    all_offset = df_file['offset'].tolist()\n",
    "    print('all_meas_data',all_meas_data, 'all_onset',all_onset, len(all_onset),'all_offset',all_offset, len(all_offset))\n",
    "\n",
    "    if (df_file.iloc[0,3] !=0 ):\n",
    "        assert(df_file.iloc[0,3] == len(all_onset) )\n",
    "        assert(len(all_offset) == len(all_onset) )\n",
    "        for i in range(0,len(all_offset)):\n",
    "            onset_sub = datetime.datetime.strptime(all_onset[i], datetimeFormat)- datetime.datetime.strptime(all_meas_data, datetimeFormat)\n",
    "            dur_sub = datetime.datetime.strptime(all_offset[i], datetimeFormat)- datetime.datetime.strptime(all_onset[i], datetimeFormat)\n",
    "            desc = 'BAD_scs_' + str(i+1)\n",
    "            onset_sub_list.append(onset_sub.seconds)\n",
    "            dur_sub_list.append(dur_sub.seconds)\n",
    "            desc_list.append(desc)\n",
    "        print('There is a subclinical seizure in ', csv_row,'th file:', onset_sub_list, dur_sub_list, desc_list)\n",
    "        sub_clinical_annot = mne.Annotations(onset= onset_sub_list,\n",
    "                                              duration= dur_sub_list,\n",
    "                                              description= desc_list)\n",
    "        raw_n = raw.copy().set_annotations(sub_clinical_annot)\n",
    "        #raw_n.plot()\n",
    "        print('double check annotation',sub_clinical_annot)\n",
    "        #print(raw_n.info)\n",
    "    else:\n",
    "        print('There is NO subclinical seizure in ', csv_row,'th file.')\n",
    "        raw_n = raw\n",
    "        #raw_n.plot()\n",
    "        #print(raw_n.info)\n",
    "    return raw_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_(t_sample, meas_data):\n",
    "    #time = float(datetime.datetime.strptime(t_sample, datetimeFormat))\n",
    "    time = float((datetime.datetime.strptime(t_sample, datetimeFormat)- \n",
    "                 datetime.datetime.strptime(meas_data, datetimeFormat)).seconds)\n",
    "    return time\n",
    "\n",
    "def process_file(data_raw, csv_row, interval ):\n",
    "    df = pd.read_csv(path_to_csv, usecols=['meas_date','onset', 'offset','onset_sample','offset_sample', 'channels'])\n",
    "    cnt_data =0\n",
    "    cnt_data_ch = 0\n",
    "    columns_ = []\n",
    "    meas_date = []\n",
    "    seizure_count = []\n",
    "    data_ch_dict = [None] * len(data_raw)\n",
    "    data_epoch = [None] * len(data_raw)\n",
    "    #print('len of data_raw', len(data_raw))\n",
    "    \n",
    "    #Generate information on number of seizures in a file\n",
    "    all_meas_data = df.iloc[:,0]\n",
    "    all_onset = df.iloc[:,1]\n",
    "    all_offset = df.iloc[:,2]\n",
    "    all_onset_sample = df.iloc[:,3]\n",
    "    all_offset_sample = df.iloc[:,4]\n",
    "    meas_date = all_meas_data.tolist()\n",
    "    onset_date = all_onset.tolist()\n",
    "    offset_date = all_offset.tolist()\n",
    "    onset_sample_date = all_onset_sample.tolist()\n",
    "    offset_sample_date = all_offset_sample.tolist()\n",
    "    for i in range(0,len(meas_date)):\n",
    "        if i==0:\n",
    "            seiz = 1 ; cnt =1\n",
    "        else:\n",
    "            if (meas_date[i-1] == meas_date[i]):\n",
    "                cnt +=1 ; seiz = cnt\n",
    "            else:\n",
    "                seiz = 1 ; cnt =1\n",
    "        seizure_count.append(seiz)\n",
    "    #print('Seizure count list',seizure_count, len(seizure_count), csv_row)\n",
    "    \n",
    "    num_of_seizure_in_file = [1] * len(seizure_count)\n",
    "    for i in range(0,len(seizure_count)): \n",
    "        if seizure_count[i] == 2:\n",
    "            num_of_seizure_in_file[i] = 2\n",
    "            num_of_seizure_in_file[i-1] = 2\n",
    "        if seizure_count[i] == 3:\n",
    "            num_of_seizure_in_file[i] = 3\n",
    "            num_of_seizure_in_file[i-1] = 3\n",
    "            num_of_seizure_in_file[i-2] = 3\n",
    "    #print('num of seizures from a file',num_of_seizure_in_file)\n",
    "    \n",
    "    #print(\"seizure starts after:\",tdiff_on, \"seizure lasts for\",tdur_seiz,\"stops after\",tdiff_off)\n",
    "    #print('Seizure onset',onset,'Seizure offset',offset )\n",
    "    #print(print(\"seizure starts after:\",tdiff_on.seconds, \"seizure lasts for\",tdur_seiz.seconds,\"stops after\",tdiff_off.seconds))\n",
    "\n",
    "    '''\n",
    "    for arr in range(len(channel)):\n",
    "        for lis in range(len(channel[arr])):\n",
    "            channel[arr][lis].replace('\\'','')\n",
    "            channel[arr][lis].replace(']','')\n",
    "            channel[arr][lis].replace('[','')\n",
    "            channel[arr][lis].replace(' ','')\n",
    "    #print(\"Shape and type of tdiff_on:\",type(tdiff_on),tdiff_on, 'channel',channel)\n",
    "    \n",
    "    if channel.find(',') != -1:\n",
    "        channel = list(channel.split(\",\"))\n",
    "        #rint('HEY FOUND A ,', channel,len(channel), type(channel))\n",
    "    else:\n",
    "        channel = list(channel.split(\",\"))\n",
    "        #print('HEY DID NOT FIND ,', channel, len(channel), type(channel))\n",
    "    '''\n",
    "    cnt_data += 1\n",
    "    \n",
    "    #Signal prepreocessing\n",
    "    #print('measurement data',meas_data, meas_data_next)\n",
    "    \n",
    "    #ch_name = entry \n",
    "    #ref_ch = HRB\n",
    "    #ref_ch = data_raw.ch_names\n",
    "\n",
    "    data_ch_dict = data_raw.copy()\n",
    "    #print('Before re-referencing',data_ch_dict.info)\n",
    "    #data_ch_dict.plot()\n",
    "    #data_ch_dict = data_ch_dict.pick_channels(ch_names= ref_ch, ordered=False)\n",
    "    #data_ch_dict.set_eeg_reference(ref_channels=ref_ch) #TODO add rereferencing\n",
    "    #print('After re-referencing',data_ch_dict.info)\n",
    "    #data_ch_dict.plot()\n",
    "    \n",
    "    #Annotate subclinical seizures\n",
    "    #print('BEFORE SCS', data_ch_dict.info)\n",
    "    data_ch_dict = remove_sub_clinical_s(sub_clinical_file ,data_ch_dict, csv_row)\n",
    "    #print('AFTER SCS', data_ch_dict.info)\n",
    "    \n",
    "    #Resampling and anti-aliasing low pass filter\n",
    "    data_ch_dict.load_data().filter(l_freq=None, h_freq=90, method='fir',picks=patient_channels)\n",
    "    #print('AFTER ANTI ALISAING FILTER')\n",
    "    #data_ch_dict.plot_psd(picks=patient_channels)\n",
    "    if data_ch_dict.info['sfreq'] != 256.0:\n",
    "        data_ch_dict = data_ch_dict.resample(256)\n",
    "    #data_ch_dict.plot()\n",
    "    \n",
    "    #print('After resampling',data_ch_dict.info)\n",
    "    data_ch_dict.load_data().filter(l_freq=0.2, h_freq=48, method='fir',picks=patient_channels)\n",
    "    #print('After filtering',data_ch_dict.info)\n",
    "    #print('AFTER BPF')\n",
    "    #data_ch_dict.plot_psd(picks=patient_channels)\n",
    "    \n",
    "    do_normalization = False\n",
    "    calculate_dt= False\n",
    "    #time_steps = (10*60)/2\n",
    "    time_steps = 10\n",
    "    \n",
    "    #Calculate time difference     #before re-referencing TODO\n",
    "    if calculate_dt == True:\n",
    "        #print('First derivative', channel)\n",
    "        data_ch_dict.apply_function(diff_data, picks=channel)\n",
    "        #print('After first derivative',data_ch_dict.info)\n",
    "        #data_ch_dict.plot()\n",
    "    else:\n",
    "        data_ch_dict = data_ch_dict\n",
    "        #print('First derivative not taken')\n",
    "    \n",
    "    # TODO ; Temporary use HRB2 and HRC2\n",
    "    #channel_temp = ['HRB2','HRC2', 'HRB3','HRC3']\n",
    "    #channel_temp = ['HRB2','HRC2']\n",
    "    #channel_temp = ['TLB1', 'TLA1', 'HL1', 'TBA1']\n",
    "    #channel_temp = ['HRA4', 'TBA1', 'HRA5', 'TBA2']\n",
    "    #data_ch_dict.pick_channels(ch_names = channel_temp, ordered = False)\n",
    "    #print(data_ch_dict.info)\n",
    "    \n",
    "    #seizure starts after: 17 seizure lasts for 55 stops after 73\n",
    "    #print(print(\"seizure starts after:\",tdiff_on.seconds, \"seizure lasts for\",tdur_seiz.seconds,\"stops after\",tdiff_off.seconds))\n",
    "    #print(print(\"seizure starts after:\",tdiff_on.microseconds, \"seizure lasts for\",tdur_seiz.microseconds,\"stops after\",tdiff_off.microseconds))\n",
    "    #seizure starts after: 0:00:17.558594 seizure lasts for 0:00:55.945312 stops after 0:01:13.503906\n",
    "\n",
    "    #Generate labels\n",
    "    for col in range(0,len(df.columns)):\n",
    "        data = df.iloc[csv_row,col]\n",
    "        columns_.append(data)\n",
    "    \n",
    "    meas_data = columns_[0]\n",
    "    onset = columns_[1]\n",
    "    offset = columns_[2]\n",
    "    onset_sample = columns_[3]\n",
    "    offset_sample = columns_[4]\n",
    "    channel = columns_[5]\n",
    "\n",
    "    tdur_seiz = datetime.datetime.strptime(offset, datetimeFormat)- datetime.datetime.strptime(onset, datetimeFormat)\n",
    "    tdiff_on = datetime.datetime.strptime(onset, datetimeFormat)- datetime.datetime.strptime(meas_data, datetimeFormat)\n",
    "    tdiff_off = datetime.datetime.strptime(offset, datetimeFormat)- datetime.datetime.strptime(meas_data, datetimeFormat)\n",
    "    \n",
    "    '''\n",
    "    if (csv_row == len(seizure_count)-1):\n",
    "        print('This file has ',seizure_count[csv_row],'seizures')\n",
    "        \n",
    "    elif(csv_row == len(seizure_count)-2):\n",
    "        if(seizure_count[csv_row] == 1 and seizure_count[csv_row+1] == 2 ):\n",
    "            print('This file has 2 seizures')\n",
    "        elif(seizure_count[csv_row] == 2 and seizure_count[csv_row+1] == 3 ):\n",
    "            print('This file has 3 seizures')\n",
    "        else:\n",
    "            print('This file has 1 seizure')\n",
    "        \n",
    "    elif ((seizure_count[csv_row] == 1) and (seizure_count[csv_row+1] ==1)):\n",
    "        print('This file has only one seizure')\n",
    "    \n",
    "    elif(((seizure_count[csv_row] == 1) and (seizure_count[csv_row+1] ==2) and (seizure_count[csv_row+2] ==1)) or ((seizure_count[csv_row] ==2) and (seizure_count[csv_row+1] ==1))):\n",
    "        print('This file has 2 seizures')\n",
    "    \n",
    "    elif(((seizure_count[csv_row] == 1) and (seizure_count[csv_row+1] ==2) and (seizure_count[csv_row+2] ==3)) or ((seizure_count[csv_row] == 2) and (seizure_count[csv_row+1] ==3)) or (seizure_count[csv_row] == 3)):\n",
    "        print('This file has 3 seizures')'''\n",
    "    \n",
    "    #Extract 5s epochs : Create epochs and labels\n",
    "    interval = interval  #TODO 2 sec\n",
    "    time_window = interval * data_ch_dict.info['sfreq'] # 5*512\n",
    "    #print('time window', time_window)\n",
    "    \n",
    "    #Split\n",
    "    if (num_of_seizure_in_file[csv_row] == 1):\n",
    "        data_ch_dict = data_ch_dict.copy()\n",
    "        print('data_ch_dict_1',data_ch_dict)\n",
    "        df = data_ch_dict.to_data_frame(scalings=dict(eeg=1))\n",
    "        df['time_s'] = df['time'] / 1000.0\n",
    "        df['target'] = 0\n",
    "        df['target'] = np.where(((df.time_s >= float(tdiff_on.seconds)) & (df.time_s <= float(tdiff_off.seconds))),1 ,df.target)        \n",
    "        seizure_length = float(tdiff_off.seconds) - float(tdiff_on.seconds)\n",
    "        print('Length of seizure is', seizure_length, 'seconds' )\n",
    "        \n",
    "    elif (num_of_seizure_in_file[csv_row] == 2):\n",
    "        if (seizure_count[csv_row] ==1):\n",
    "            split_1 = dt_(offset_date[csv_row],meas_date[csv_row])  +((dt_(onset_date[csv_row+1],meas_date[csv_row]) - dt_(offset_date[csv_row],meas_date[csv_row]))/2 )\n",
    "            data_ch_dict_2_1 = data_ch_dict.copy().crop(tmin = 0, tmax = split_1)\n",
    "            data_ch_dict = data_ch_dict_2_1.copy()\n",
    "            print('data_ch_dict_2_1',data_ch_dict)\n",
    "            df = data_ch_dict.to_data_frame(scalings=dict(eeg=1))\n",
    "            df['time_s'] = df['time'] / 1000.0\n",
    "            df['target'] = 0\n",
    "            df['target'] = np.where(((df.time_s >=float(tdiff_on.seconds)) & (df.time_s <= float(tdiff_off.seconds))),1,df.target)\n",
    "            print('2_1', split_1,float(tdiff_on.seconds), float(tdiff_off.seconds))\n",
    "            seizure_length = float(tdiff_off.seconds) - float(tdiff_on.seconds)\n",
    "            print('Length of seizure is', seizure_length, 'seconds' )\n",
    "            \n",
    "        if (seizure_count[csv_row] ==2):\n",
    "            split_1 = dt_(offset_date[csv_row-1],meas_date[csv_row])  +((dt_(onset_date[csv_row],meas_date[csv_row]) - dt_(offset_date[csv_row-1],meas_date[csv_row]))/2 )\n",
    "            start = (dt_(onset_date[csv_row],meas_date[csv_row]) - dt_(offset_date[csv_row-1],meas_date[csv_row]))/2\n",
    "            end = start + (dt_(offset_date[csv_row],meas_date[csv_row]) - dt_(onset_date[csv_row],meas_date[csv_row]))\n",
    "            data_ch_dict_2_2 = data_ch_dict.copy().crop(tmin= split_1)\n",
    "            data_ch_dict = data_ch_dict_2_2.copy()\n",
    "            print('data_ch_dict_2_2',data_ch_dict)\n",
    "            df = data_ch_dict.to_data_frame(scalings=dict(eeg=1))\n",
    "            df['time_s'] = df['time'] / 1000.0\n",
    "            df['target'] = 0\n",
    "            df['target'] = np.where(((df.time_s >= start) & (df.time_s <= end)),1,df.target)\n",
    "            print('2_2', split_1, start, end)\n",
    "            seizure_length = end - start\n",
    "            print('Length of seizure is', seizure_length, 'seconds' )\n",
    "            \n",
    "    elif (num_of_seizure_in_file[csv_row] == 3):\n",
    "        if ( seizure_count[csv_row] ==1):\n",
    "            split_2 = dt_(offset_date[csv_row],meas_date[csv_row])  +((dt_(onset_date[csv_row+1],meas_date[csv_row]) - dt_(offset_date[csv_row],meas_date[csv_row]))/2 )\n",
    "            data_ch_dict_3_1 = data_ch_dict.copy().crop(tmin=0 ,tmax= split_2)\n",
    "            data_ch_dict = data_ch_dict_3_1.copy()\n",
    "            print('data_ch_dict_3_1',data_ch_dict)\n",
    "            df = data_ch_dict.to_data_frame(scalings=dict(eeg=1))\n",
    "            df['time_s'] = df['time'] / 1000.0\n",
    "            df['target'] = 0\n",
    "            df['target'] = np.where(((df.time_s >= float(tdiff_on.seconds)) & (df.time_s <= float(tdiff_off.seconds))),1,df.target)\n",
    "            print('3_1', split_2, float(tdiff_on.seconds), float(tdiff_off.seconds))\n",
    "            seizure_length = float(tdiff_off.seconds) - float(tdiff_on.seconds)\n",
    "            print('Length of seizure is', seizure_length, 'seconds' )\n",
    "            \n",
    "        if ( seizure_count[csv_row] ==2):\n",
    "            split_2 = dt_(offset_date[csv_row-1],meas_date[csv_row])  +((dt_(onset_date[csv_row],meas_date[csv_row]) - dt_(offset_date[csv_row-1],meas_date[csv_row]))/2 )\n",
    "            split_3 = dt_(offset_date[csv_row],meas_date[csv_row])  +((dt_(onset_date[csv_row+1],meas_date[csv_row]) - dt_(offset_date[csv_row],meas_date[csv_row]))/2 )\n",
    "            start = (dt_(onset_date[csv_row],meas_date[csv_row]) - dt_(offset_date[csv_row-1],meas_date[csv_row]))/2\n",
    "            end = start + (dt_(offset_date[csv_row],meas_date[csv_row]) - dt_(onset_date[csv_row],meas_date[csv_row])) \n",
    "            data_ch_dict_3_2 = data_ch_dict.copy().crop(tmin=split_2 ,tmax=split_3)\n",
    "            data_ch_dict = data_ch_dict_3_2.copy()\n",
    "            print('data_ch_dict_3_2',data_ch_dict)\n",
    "            df = data_ch_dict.to_data_frame(scalings=dict(eeg=1))\n",
    "            df['time_s'] = df['time'] / 1000.0\n",
    "            df['target'] = 0\n",
    "            df['target'] = np.where(((df.time_s >= start) & (df.time_s <= end)),1,df.target)\n",
    "            print('3_2', split_2, split_3, start, end)\n",
    "            seizure_length = end - start\n",
    "            print('Length of seizure is', seizure_length, 'seconds' )\n",
    "            \n",
    "        if ( seizure_count[csv_row]==3):\n",
    "            split_3 = dt_(offset_date[csv_row-1],meas_date[csv_row])  +((dt_(onset_date[csv_row],meas_date[csv_row]) - dt_(offset_date[csv_row-1],meas_date[csv_row]))/2 )\n",
    "            start = (dt_(onset_date[csv_row],meas_date[csv_row]) - dt_(offset_date[csv_row-1],meas_date[csv_row]))/2\n",
    "            end = start + (dt_(offset_date[csv_row],meas_date[csv_row]) - dt_(onset_date[csv_row],meas_date[csv_row]))\n",
    "            data_ch_dict_3_3 = data_ch_dict.copy().crop(tmin=split_3 )\n",
    "            data_ch_dict = data_ch_dict_3_3.copy()\n",
    "            print('data_ch_dict_3_3',data_ch_dict)\n",
    "            df = data_ch_dict.to_data_frame(scalings=dict(eeg=1))\n",
    "            df['time_s'] = df['time'] / 1000.0\n",
    "            df['target'] = 0\n",
    "            df['target'] = np.where(((df.time_s >= start) & (df.time_s <= end)),1,df.target)\n",
    "            print('3_3', split_3, start, end)\n",
    "            seizure_length = end - start\n",
    "            print('Length of seizure is', seizure_length, 'seconds' )\n",
    "    \n",
    "     # Store data, time and label as dataframe\n",
    "    #df = data_ch_dict.to_data_frame()\n",
    "    #print(df)\n",
    "    #df['time_s'] = df['time'] / 1000.0\n",
    "    #df['target'] = 0\n",
    "    #df['target'] = np.where(((df.time_s >= float(tdiff_on.seconds)) & (df.time_s <= float(tdiff_off.seconds))),1,df.target)\n",
    "    #print(df) \n",
    "    \n",
    "    '''\n",
    "    #Crop the data to include less non-ictal activity : Temporary logic\n",
    "    def define_df(data_ch_dict, idx):\n",
    "        df1 = data_ch_dict.to_data_frame()\n",
    "        df1['time_s'] = df1['time'] / 1000.0\n",
    "        df1['target'] = 0\n",
    "        df1['target'] = np.where(( (df1.time_s+ idx >= float(tdiff_on.seconds)) & (df1.time_s + idx <= float(tdiff_off.seconds))),1,df1.target)\n",
    "        return df1\n",
    "    if (tdiff_on.seconds < 1200):\n",
    "        data_ch_dict_n = data_ch_dict.copy().crop(tmin=0,tmax=1200) #0,1200\n",
    "        print('Seizure occurs in first half')\n",
    "        df_subset = define_df(data_ch_dict_n, 0)\n",
    "    elif (tdiff_on.seconds > 2400):\n",
    "        data_ch_dict_n = data_ch_dict.copy().crop(tmin=2400, tmax =3599) # 2400,3600\n",
    "        print('Seizure occurs in end')\n",
    "        df_subset = define_df(data_ch_dict_n, 2400)\n",
    "    else:\n",
    "        data_ch_dict_n = data_ch_dict.copy().crop(tmin=1200,tmax=2400) # 1200,2400\n",
    "        print('Seizure occurs in mid ')\n",
    "        df_subset = define_df(data_ch_dict_n, 1200)\n",
    "       #'''    \n",
    "    data_epoch_rej = mne.make_fixed_length_epochs(data_ch_dict, duration= interval, reject_by_annotation =True, preload=True,id= csv_row) \n",
    "    data_epoch = mne.make_fixed_length_epochs(data_ch_dict, duration= interval, reject_by_annotation =False, preload=True,id= csv_row) \n",
    "    print('Fixed Length Epochs',csv_row,data_epoch, len(data_epoch), type(data_epoch) )\n",
    "    \n",
    "    #stronger_reject_criteria = dict(eeg=1000e-6)        #10microV\n",
    "    #data_epoch.drop_bad(reject=stronger_reject_criteria)\n",
    "    #print('DROP BAD',csv_row,data_epoch, len(data_epoch), type(data_epoch) )\n",
    "    #print('dropped',data_epoch_rej.drop_log, len(data_epoch_rej.drop_log), type(data_epoch_rej.drop_log))\n",
    "\n",
    "    #df['bad_epoch'] = data_epoch.drop_log\n",
    "    #print('not dropped',data_epoch_comp.drop_log)\n",
    "    #print('Epochs return value',data_epoch.get_data(), np.shape(data_epoch.get_data()), type(data_epoch.get_data()) )\n",
    "    \n",
    "    data_labels = [None] * len(data_epoch)\n",
    "    time_labels = [None] * len(data_epoch)\n",
    "    bad_epochs_labels = [None] * len(data_epoch)\n",
    "    #print('Number of total samples in 1 file',len(data_epoch) )\n",
    "    for seg in range(0,len(data_epoch)):\n",
    "        df_start = int(seg*time_window)\n",
    "        df_end = int((seg+1)*time_window)\n",
    "        #print('Check labels',df_start, df_end)\n",
    "        #count_labels = df_subset.loc[df_start:df_end,'target'].sum()\n",
    "        count_labels = df.loc[df_start:df_end,'target'].sum()\n",
    "        #print('Count labels', count_labels)\n",
    "        if count_labels > time_window/2: #Update this threshold as needed TODO\n",
    "            #print('SEIZURE DETECTED', csv_row, ':', count_labels,'seg', seg, 'start',df_start,'end',df_end)\n",
    "            label = 1\n",
    "        else:\n",
    "            #print('NO SEIZURE DETECTED FOR', csv_row,':',count_labels,'seg', seg, 'start',df_start,'end',df_end)\n",
    "            label = 0\n",
    "        data_labels[seg] = label\n",
    "        count_labels = 0\n",
    "        time_labels[seg] = df.iloc[df_start:df_end,0]\n",
    "        bad_epochs_labels[seg] = data_epoch_rej.drop_log[seg]\n",
    "    #print( np.shape(np.array(time_labels)),type(np.array(time_labels)) )   #RETURN\n",
    "    #print('time_labels',time_labels)\n",
    "    #print('Label generated for',csv_row,':',bad_epochs_labels)\n",
    "    print('All dataloader', len(data_epoch.get_data()), len(data_labels), len(time_labels), len(bad_epochs_labels))\n",
    "    #Generate time_labels\n",
    "    \n",
    "    #Send filtered data\n",
    "    print('Total epochs', len(data_epoch), 'Epochs after rejection',len(data_epoch_rej))\n",
    "    cnt_epoch = 0\n",
    "    output_data = [None] * len(data_epoch_rej)\n",
    "    output_label = [None] * len(data_epoch_rej)\n",
    "    output_time_labels = [None] * len(data_epoch_rej)\n",
    "    for seg in range(0,len(data_epoch)):\n",
    "        if bad_epochs_labels[seg] == ():\n",
    "            output_data[cnt_epoch] = data_epoch[seg].get_data()*1000\n",
    "            output_label[cnt_epoch] = data_labels[seg]\n",
    "            output_time_labels[cnt_epoch] = time_labels[seg]\n",
    "            cnt_epoch +=1\n",
    "            #print('this is correct',bad_epochs_labels[seg] )\n",
    "        else:\n",
    "            print('This epoch is bad', bad_epochs_labels[seg])\n",
    "    print('cnt_epoch', cnt_epoch, len(output_data),len(output_label), len(output_time_labels))\n",
    "    #print( type(output_data),type(output_label), type(output_time_labels))\n",
    "    #print('New data shape',np.squeeze(np.array(output_data)).shape , np.array(output_label).shape, np.array(output_time_labels).shape)\n",
    "    #print('Old data shape',data_epoch.get_data().shape, np.array(output_label).shape, np.array(output_time_labels).shape)\n",
    "    \n",
    "    #create new dataframe\n",
    "    #df_scar = pd.DataFrame(np.array(output_time_labels))\n",
    "    #print(df_scar)\n",
    "    \n",
    "    # Non trimme\n",
    "    #print(df)\n",
    "    #df_scar.to_csv('./check_vals' + str(csv_row) + '.csv')\n",
    "    '''\n",
    "    t1 = df.time_s\n",
    "    t2 = df.time_s\n",
    "\n",
    "    plt.figure()\n",
    "    plt.subplot(511)\n",
    "    plt.plot(t1, df.iloc[:,1])\n",
    "    plt.subplot(512)\n",
    "    plt.plot(t1, df.iloc[:,2])\n",
    "    plt.subplot(513)\n",
    "    plt.plot(t1, df.iloc[:,3])\n",
    "    plt.subplot(514)\n",
    "    plt.plot(t1, df.iloc[:,4])\n",
    "    #plt.plot(t1, df.TLB1)\n",
    "\n",
    "    plt.subplot(515)\n",
    "    plt.plot(t2, df.target)\n",
    "    plt.show()#'''\n",
    "    '''\n",
    "    #print(df_subset)  # Trimmed\n",
    "    t1 = df_subset.time_s\n",
    "    t2 = df_subset.time_s\n",
    "\n",
    "    plt.figure()\n",
    "    plt.subplot(211)\n",
    "    plt.plot(t1, df_subset.HRB2)\n",
    "    #plt.plot(t1, df_subset.TLB1)\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.plot(t2, df_subset.target)\n",
    "    plt.show()#'''\n",
    "    return np.squeeze(np.array(output_data)) , np.array(output_label), np.array(output_time_labels), seizure_length\n",
    "    #return data_epoch.get_data()*1000 , np.array(data_labels), np.array(time_labels), seizure_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "for csv_row,data_raw in enumerate(reref_raws):\n",
    "    r_data_1, r_label_1, r_time_label_1, len_seizure1 = process_file(data_raw, csv_row, interval)\n",
    "    #print(r_data, r_label, r_time_label, r_data.shape, r_label.shape, r_time_label.shape)\n",
    "    break\n",
    "'''\n",
    "output = open('./pkl_files/pat_253_0.pkl', 'wb')\n",
    "print('dtype before', r_data.dtype)\n",
    "pickle.dump([r_data, r_label, r_time_label], output)\n",
    "output.close()\n",
    "\n",
    "# read python dict back from the file\n",
    "pkl_file = open('./pkl_files/pat_253_0.pkl', 'rb')\n",
    "mydata, my_label, my_time_label = pickle.load(pkl_file)\n",
    "print('dtype after', mydata.dtype)\n",
    "pkl_file.close()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mydata.shape, my_label.shape, my_time_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, ConcatDataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "class EpochsDataset(Dataset):\n",
    "    \"\"\"Class to expose an MNE Epochs object as PyTorch dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    epochs_data : np.ndarray\n",
    "        The epochs data, shape (n_epochs, n_channels, n_times).\n",
    "    epochs_labels : np.ndarray\n",
    "        The epochs labels, shape (n_epochs,)\n",
    "    epochs_time_labels : np.ndarray\n",
    "        The time labels, shape (n_epochs,n_times)\n",
    "    subj_num: None | int\n",
    "        Subject number.\n",
    "    rec_num: None | int\n",
    "        Recording number.\n",
    "    transform : callable | None\n",
    "        The function to eventually apply to each epoch\n",
    "        for preprocessing (e.g. scaling). Defaults to None.\n",
    "    \"\"\"\n",
    "    def __init__(self, epochs_data, epochs_labels, epochs_time_labels,subj_num=None, rec_num=None,transform=None):\n",
    "        assert len(epochs_data) == len(epochs_labels)\n",
    "        self.epochs_data = epochs_data\n",
    "        self.epochs_labels = epochs_labels\n",
    "        self.epochs_time_labels = epochs_time_labels\n",
    "        self.subj_num = subj_num\n",
    "        self.rec_num = rec_num\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.epochs_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X, y = self.epochs_data[idx], self.epochs_labels[idx]\n",
    "        time_label = self.epochs_time_labels[idx]\n",
    "        #print('check getitem',X.shape,y.shape)\n",
    "        if self.transform is not None:\n",
    "            X = self.transform(X)\n",
    "        X = torch.as_tensor(X[None, ...])\n",
    "        return X, y, time_label\n",
    "\n",
    "#transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "def scale(X):    #Zscore normalization also try?\n",
    "    \"\"\"Standard scaling of data along the last dimention.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape (n_channels, n_times)\n",
    "        The input signals.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    X_t : array, shape (n_channels, n_times)\n",
    "        The scaled signals.\n",
    "    \"\"\"\n",
    "    #print('Input',X)\n",
    "    X -= np.mean(X, axis=1, keepdims=True)\n",
    "    #print('Mean',np.mean(X, axis=1, keepdims=True))\n",
    "    #print('Std Dev',np.std(X, axis=1, keepdims=True))\n",
    "    #print('Return', X / np.std(X, axis=1, keepdims=True))\n",
    "    return X / np.std(X, axis=1, keepdims=True)\n",
    "\n",
    "#TODO: ''######## IMPORTANT #########''torch.utils.data. needed? and if it is actually normalized \n",
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0,), (1,))  \n",
    "        ])\n",
    "\n",
    "# To remove seizures less than 10s\n",
    "all_datasets = []\n",
    "cnt_discarded_seizures = 0\n",
    "tmp_cnt = 0\n",
    "\n",
    "for csv_row,data_raw in enumerate(reref_raws):\n",
    "    r_data, r_label, r_time_label, len_seizure = process_file(data_raw, csv_row, interval)\n",
    "    if len_seizure >= 10.1:\n",
    "        valid_dataset = EpochsDataset(r_data, r_label, r_time_label, subj_num=data_raws[csv_row].info['subject_info']['id'], \n",
    "                              rec_num=data_raws[csv_row].info['subject_info']['rec_id'], transform=scale)\n",
    "        tmp_cnt += 1\n",
    "        all_datasets.append(valid_dataset) \n",
    "    else:\n",
    "        cnt_discarded_seizures +=1\n",
    "        print('The length of the seizure is',len_seizure,'s. Hence, discarded!')\n",
    "\n",
    "print('Number of selected datasets are:',len(all_datasets),'. Number of seizures less than 10s:',cnt_discarded_seizures)\n",
    "# Does not remove seizures less than 10s \n",
    "'''all_datasets = [EpochsDataset(*process_file(data_raw, csv_row, interval), subj_num=data_raws[csv_row].info['subject_info']['id'], \n",
    "                              rec_num=data_raws[csv_row].info['subject_info']['rec_id'], transform=scale) \n",
    "                for csv_row,data_raw in enumerate(reref_raws)]  ''' #replaced from data_raws\n",
    "\n",
    "# Concatenate into a single dataset\n",
    "dataset = ConcatDataset(all_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.datasets[0].epochs_data.shape, dataset.datasets[0].epochs_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "  \"\"\"\n",
    "    Resetting model weights to avoid weight leakage.\n",
    "  \"\"\"\n",
    "  for layer in m.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            #print(f'Reset trainable parameters of layer = {layer}')\n",
    "            layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        input_size = 784\n",
    "        self.quant_inp = qnn.QuantIdentity(bit_width=4, return_quant_tensor=True)\n",
    "        self.fc1 = qnn.QuantLinear(input_size, 512, weight_bit_width=3, bias=True,bias_quant=BiasQuant,return_quant_tensor=True)\n",
    "        self.relu1 = qnn.QuantReLU(bit_width=4, return_quant_tensor=True)\n",
    "        self.fc2 = qnn.QuantLinear(512, 256, weight_bit_width=3, bias=True,bias_quant=BiasQuant,return_quant_tensor=True)\n",
    "        self.relu2 = qnn.QuantReLU(bit_width=4, return_quant_tensor=True)\n",
    "        self.fc3 = qnn.QuantLinear(256, 128, weight_bit_width=3, bias=True,bias_quant=BiasQuant,return_quant_tensor=True)\n",
    "        self.relu3 = qnn.QuantReLU(bit_width=4, return_quant_tensor=True)\n",
    "        self.fc4 = qnn.QuantLinear(128, 64, weight_bit_width=3, bias=True,bias_quant=BiasQuant,return_quant_tensor=True)\n",
    "        self.relu4 = qnn.QuantReLU(bit_width=4, return_quant_tensor=True)\n",
    "        self.fc5 = qnn.QuantLinear(64,10, weight_bit_width=3, bias=False)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        #return_quant_tensor = True to propogate QuantTensor across\n",
    "        #Quant_relu is stateful, so instantiate all of them separately\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.quant_inp(x)\n",
    "        x = self.dropout(self.relu1(self.fc1(x)))\n",
    "        x = self.dropout(self.relu2(self.fc2(x)))\n",
    "        x = self.dropout(self.relu3(self.fc3(x)))\n",
    "        x = self.dropout(self.relu4(self.fc4(x)))\n",
    "        x = F.log_softmax(self.fc5(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brevitas.nn import QuantIdentity\n",
    "from brevitas.nn import QuantConv2d\n",
    "from brevitas.quant import Int8Bias\n",
    "from brevitas.nn import QuantDropout\n",
    "from brevitas.nn import QuantReLU\n",
    "from brevitas.nn import QuantSigmoid\n",
    "from brevitas.quant.scaled_int import Int8ActPerTensorFloat\n",
    "%env BREVITAS_JIT=1\n",
    "%env BREVITAS_IGNORE_MISSING_KEYS=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv1D\n",
    "# CREATING NEURAL NETWORK with parameterization for freq = 256Hz and t= 2sec : based on Farrokh's\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class IEEGSeizureDetection_2sec(nn.Module):\n",
    "   \n",
    "    def __init__(self, n_channels, sfreq, n_conv_chs=15, time_conv_size_s=0.5,\n",
    "                 max_pool_size_s=0.03125, n_classes=2, input_size_s=5, dropout=0.25):\n",
    "        super(IEEGSeizureDetection_2sec, self).__init__()\n",
    "\n",
    "        time_conv_size = int(time_conv_size_s * sfreq) #256\n",
    "        max_pool_size = int(max_pool_size_s * sfreq)   #16\n",
    "        input_size = int(input_size_s * sfreq)         #2560\n",
    "        pad_size = time_conv_size // 2                 #128\n",
    "        self.n_channels = 4                            #2\n",
    "        len_last_layer = self._len_last_layer(n_channels, input_size, max_pool_size, n_conv_chs) #300\n",
    "        beta = 0.89\n",
    "        print('Check parameters',time_conv_size,max_pool_size,input_size,pad_size,self.n_channels, len_last_layer)\n",
    "\n",
    "        #Quantized Aware Training\n",
    "        #8-bit signed integer with a per-tensor floating-point scale factor (ONNX standard)\n",
    "        '''\n",
    "        weight_bit_width = 4\n",
    "        act_bit_width = 4\n",
    "        #Layer1\n",
    "        self.quant_identity = QuantIdentity(return_quant_tensor=True)\n",
    "        self.conv1 = qnn.QuantConv1d(in_channels=4, out_channels= 20,kernel_size= 17,\n",
    "                                     bias=True,\n",
    "                                     #weight_bit_width=weight_bit_width,\n",
    "                                     #input_quant=Int8ActPerTensorFloat, \n",
    "                                     #weight_quant=Int8ActPerTensorFloat,\n",
    "                                     bias_quant=Int8Bias,\n",
    "                                     #output_quant=Int8ActPerTensorFloat,\n",
    "                                     return_quant_tensor=True)\n",
    "        #print(self.conv1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(20)\n",
    "        self.maxpool1 = nn.MaxPool1d(kernel_size=4)\n",
    "        self.dropout = QuantDropout(0.2)\n",
    "        self.relu1 = QuantReLU(return_quant_tensor=True)\n",
    "        \n",
    "        #Layer2\n",
    "        self.conv2 = qnn.QuantConv1d(in_channels=20, out_channels=10 ,kernel_size= 5,\n",
    "                                     bias=True,\n",
    "                                     #weight_bit_width=weight_bit_width,\n",
    "                                     #input_quant=Int8ActPerTensorFloat, \n",
    "                                     bias_quant=Int8Bias,\n",
    "                                     #output_quant=Int8ActPerTensorFloat,\n",
    "                                     return_quant_tensor=True)\n",
    "        #print(self.conv2)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(10)\n",
    "        self.maxpool2 = nn.MaxPool1d(kernel_size=4)\n",
    "        self.relu2 = QuantReLU(return_quant_tensor=True)\n",
    "        \n",
    "        #Layer3\n",
    "        self.conv3 = qnn.QuantConv1d(in_channels=10, out_channels=10 , kernel_size=5,\n",
    "                                     bias=True,\n",
    "                                     #weight_bit_width=weight_bit_width,\n",
    "                                     #input_quant=Int8ActPerTensorFloat, \n",
    "                                     bias_quant=Int8Bias,\n",
    "                                     #output_quant=Int8ActPerTensorFloat,\n",
    "                                     return_quant_tensor=True)\n",
    "        #print(self.conv3)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(10)\n",
    "        self.maxpool3 = nn.MaxPool1d(kernel_size=2)\n",
    "        self.relu3 = QuantReLU(return_quant_tensor=True)\n",
    "        \n",
    "        #Layer4\n",
    "        self.conv4 = qnn.QuantConv1d(in_channels=10, out_channels=10 , kernel_size=5,\n",
    "                                     bias=True,\n",
    "                                     #weight_bit_width=weight_bit_width,\n",
    "                                     #input_quant=Int8ActPerTensorFloat, \n",
    "                                     bias_quant=Int8Bias,\n",
    "                                     #output_quant=Int8ActPerTensorFloat,\n",
    "                                     return_quant_tensor=True)\n",
    "        #print(self.conv4)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(10)\n",
    "        self.relu4 = QuantReLU(return_quant_tensor=True)\n",
    "        \n",
    "        #Layer5\n",
    "        self.fc1 = qnn.QuantLinear(in_features=10*1*9, out_features= 5, \n",
    "                                   bias=True,   \n",
    "                                   #weight_bit_width=weight_bit_width,\n",
    "                                   #output_quant=Int8ActPerTensorFloat,\n",
    "                                   bias_quant=Int8Bias,\n",
    "                                   return_quant_tensor=True)\n",
    "        #print(self.fc1)\n",
    "        self.relu5 = QuantReLU(return_quant_tensor=True)\n",
    "        \n",
    "        #Layer6\n",
    "        self.fc2 = qnn.QuantLinear(in_features=5, out_features=5, \n",
    "                                   bias=True,  \n",
    "                                   #weight_bit_width=weight_bit_width,\n",
    "                                   #output_quant=Int8ActPerTensorFloat,\n",
    "                                   bias_quant=Int8Bias,\n",
    "                                   return_quant_tensor=True)\n",
    "        #print(self.fc2)\n",
    "        self.relu6 = QuantReLU(return_quant_tensor=True)\n",
    "        \n",
    "        #Layer7\n",
    "        self.fc3 = qnn.QuantLinear(in_features=5, \n",
    "                                   #out_features=1, \n",
    "                                   #input_quant=Int8ActPerTensorFloat, \n",
    "                                   out_features=2,\n",
    "                                   bias=True, \n",
    "                                   #weight_bit_width=weight_bit_width,\n",
    "                                   #output_quant=Int8ActPerTensorFloat,\n",
    "                                   bias_quant=Int8Bias,\n",
    "                                   return_quant_tensor=True)\n",
    "        #print(self.fc3)\n",
    "        #self.sigmoid = QuantSigmoid(return_quant_tensor=True)\n",
    "        #self.sigmoid = nn.Sigmoid()\n",
    "        #'''\n",
    "        # Non Quantized\n",
    "        #'''\n",
    "        self.conv1 = nn.Conv1d(in_channels=4, out_channels= 20,kernel_size= 17 )\n",
    "        self.batchnorm1 = nn.BatchNorm1d(20)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool1d(kernel_size=n_channels)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=20, out_channels=10 ,kernel_size= 5)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(10)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool1d(kernel_size=n_channels)\n",
    "        self.conv3 = nn.Conv1d(in_channels=10, out_channels=10 , kernel_size=5)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(10)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool1d(kernel_size=2)\n",
    "        self.conv4 = nn.Conv1d(in_channels=10, out_channels=10 , kernel_size=5)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(10)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(in_features=10*1*9, out_features= 5, bias=True)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(in_features=5, out_features=5, bias=True)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(in_features=5, out_features=2, bias=True)\n",
    "        #self.sigmoid = nn.Sigmoid()#'''\n",
    "\n",
    "    @staticmethod\n",
    "    def _len_last_layer(n_channels, input_size, max_pool_size, n_conv_chs):\n",
    "        return n_channels * (input_size // (max_pool_size ** 2)) * n_conv_chs\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass.\n",
    "        \n",
    "        Parameters\n",
    "        ---------\n",
    "        x: torch.Tensor\n",
    "            Batch of EEG windows of shape (batch_size, n_channels, n_times).\n",
    "        \"\"\"\n",
    "        #print('in', x.shape)\n",
    "        #x = self.quant_identity(x)  # UNCOMMENT FOR QUANTIZATION \n",
    "        #print(f\"Input has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        #print('conv1', x.shape)\n",
    "        x = self.conv1(x)\n",
    "        #print(f\"CONV1:\\n {x} \\n\")\n",
    "        #print(f\"CONV1 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        #print('bn', x.shape)\n",
    "        x = self.batchnorm1(x)\n",
    "        #print(f\"BN1 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        #print('relu', x.shape)\n",
    "        x = self.relu1(x)\n",
    "        #print(f\"R1 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        #print('maxpool', x.shape)\n",
    "        x = self.maxpool1(x)\n",
    "        #print(f\"MP1 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        #print('dropout', x.shape)\n",
    "        x = self.dropout(x)\n",
    "        #print(f\"DR1 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        #print('conv2 shape', x.shape)\n",
    "        x = self.conv2(x)\n",
    "        #print(f\"CONV2:\\n {x} \\n\")\n",
    "        #print(f\"CONV2 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.batchnorm2(x)\n",
    "        #print(f\"BN2 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.relu2(x)\n",
    "        #print(f\"R2 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.maxpool2(x)\n",
    "        #print(f\"MP2 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.dropout(x)\n",
    "        #print(f\"DR2 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.conv3(x)\n",
    "        #print(f\"CONV3:\\n {x} \\n\")\n",
    "        #print(f\"CONV3 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.batchnorm3(x)\n",
    "        #print(f\"BN3 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.relu3(x)\n",
    "        #print(f\"R3 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.maxpool3(x)\n",
    "        #print(f\"MP3 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.dropout(x)\n",
    "        #print(f\"DR3 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.conv4(x)\n",
    "        #print(f\"CONV4:\\n {x} \\n\")\n",
    "        #print(f\"CONV4 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.batchnorm4(x)\n",
    "        #print(f\"BN4 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.relu4(x)\n",
    "        #print(f\"R4 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu5(self.fc1(x.flatten(start_dim=1)))\n",
    "        #print(f\"FC1:\\n {x} \\n\")\n",
    "        #print(f\"FC1 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.relu6(self.fc2(x))\n",
    "        #print(f\"FC2:\\n {x} \\n\")\n",
    "        #print(f\"FC2 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        #x = self.sigmoid(self.fc3(x))\n",
    "        x = self.fc3(x)\n",
    "        #print(f\"FC3:\\n {x} \\n\")\n",
    "        #print(f\"FC3 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv1D HPO Params sigmoid\n",
    "# CREATING NEURAL NETWORK with parameterization for freq = 256Hz and t= 2sec : based on Farrokh's\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class IEEGSeizureDetection_2sec(nn.Module):\n",
    "   \n",
    "    def __init__(self, n_channels, sfreq, n_conv_chs=15, time_conv_size_s=0.5,\n",
    "                 max_pool_size_s=0.03125, n_classes=2, input_size_s=5, dropout=0.25):\n",
    "        super(IEEGSeizureDetection_2sec, self).__init__()\n",
    "\n",
    "        time_conv_size = int(time_conv_size_s * sfreq) #256\n",
    "        max_pool_size = int(max_pool_size_s * sfreq)   #16\n",
    "        input_size = int(input_size_s * sfreq)         #2560\n",
    "        pad_size = time_conv_size // 2                 #128\n",
    "        self.n_channels = 4                            #2\n",
    "        len_last_layer = self._len_last_layer(n_channels, input_size, max_pool_size, n_conv_chs) #300\n",
    "        beta = 0.89\n",
    "        print('Check parameters',time_conv_size,max_pool_size,input_size,pad_size,self.n_channels, len_last_layer)\n",
    "\n",
    "        #Quantized Aware Training\n",
    "        #8-bit signed integer with a per-tensor floating-point scale factor (ONNX standard)\n",
    "        '''\n",
    "        weight_bit_width = 4\n",
    "        act_bit_width = 4\n",
    "        #Layer1\n",
    "        self.quant_identity = QuantIdentity(return_quant_tensor=True)\n",
    "        self.conv1 = qnn.QuantConv1d(in_channels=4, out_channels= 20,kernel_size= 17,\n",
    "                                     bias=True,\n",
    "                                     #weight_bit_width=weight_bit_width,\n",
    "                                     #input_quant=Int8ActPerTensorFloat, \n",
    "                                     #weight_quant=Int8ActPerTensorFloat,\n",
    "                                     bias_quant=Int8Bias,\n",
    "                                     #output_quant=Int8ActPerTensorFloat,\n",
    "                                     return_quant_tensor=True)\n",
    "        #print(self.conv1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(20)\n",
    "        self.maxpool1 = nn.MaxPool1d(kernel_size=4)\n",
    "        self.dropout = QuantDropout(0.2)\n",
    "        self.relu1 = QuantReLU(return_quant_tensor=True)\n",
    "        \n",
    "        #Layer2\n",
    "        self.conv2 = qnn.QuantConv1d(in_channels=20, out_channels=10 ,kernel_size= 5,\n",
    "                                     bias=True,\n",
    "                                     #weight_bit_width=weight_bit_width,\n",
    "                                     #input_quant=Int8ActPerTensorFloat, \n",
    "                                     bias_quant=Int8Bias,\n",
    "                                     #output_quant=Int8ActPerTensorFloat,\n",
    "                                     return_quant_tensor=True)\n",
    "        #print(self.conv2)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(10)\n",
    "        self.maxpool2 = nn.MaxPool1d(kernel_size=4)\n",
    "        self.relu2 = QuantReLU(return_quant_tensor=True)\n",
    "        \n",
    "        #Layer3\n",
    "        self.conv3 = qnn.QuantConv1d(in_channels=10, out_channels=10 , kernel_size=5,\n",
    "                                     bias=True,\n",
    "                                     #weight_bit_width=weight_bit_width,\n",
    "                                     #input_quant=Int8ActPerTensorFloat, \n",
    "                                     bias_quant=Int8Bias,\n",
    "                                     #output_quant=Int8ActPerTensorFloat,\n",
    "                                     return_quant_tensor=True)\n",
    "        #print(self.conv3)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(10)\n",
    "        self.maxpool3 = nn.MaxPool1d(kernel_size=2)\n",
    "        self.relu3 = QuantReLU(return_quant_tensor=True)\n",
    "        \n",
    "        #Layer4\n",
    "        self.conv4 = qnn.QuantConv1d(in_channels=10, out_channels=10 , kernel_size=5,\n",
    "                                     bias=True,\n",
    "                                     #weight_bit_width=weight_bit_width,\n",
    "                                     #input_quant=Int8ActPerTensorFloat, \n",
    "                                     bias_quant=Int8Bias,\n",
    "                                     #output_quant=Int8ActPerTensorFloat,\n",
    "                                     return_quant_tensor=True)\n",
    "        #print(self.conv4)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(10)\n",
    "        self.relu4 = QuantReLU(return_quant_tensor=True)\n",
    "        \n",
    "        #Layer5\n",
    "        self.fc1 = qnn.QuantLinear(in_features=10*1*9, out_features= 5, \n",
    "                                   bias=True,   \n",
    "                                   #weight_bit_width=weight_bit_width,\n",
    "                                   #output_quant=Int8ActPerTensorFloat,\n",
    "                                   bias_quant=Int8Bias,\n",
    "                                   return_quant_tensor=True)\n",
    "        #print(self.fc1)\n",
    "        self.relu5 = QuantReLU(return_quant_tensor=True)\n",
    "        \n",
    "        #Layer6\n",
    "        self.fc2 = qnn.QuantLinear(in_features=5, out_features=5, \n",
    "                                   bias=True,  \n",
    "                                   #weight_bit_width=weight_bit_width,\n",
    "                                   #output_quant=Int8ActPerTensorFloat,\n",
    "                                   bias_quant=Int8Bias,\n",
    "                                   return_quant_tensor=True)\n",
    "        #print(self.fc2)\n",
    "        self.relu6 = QuantReLU(return_quant_tensor=True)\n",
    "        \n",
    "        #Layer7\n",
    "        self.fc3 = qnn.QuantLinear(in_features=5, \n",
    "                                   #out_features=1, \n",
    "                                   #input_quant=Int8ActPerTensorFloat, \n",
    "                                   out_features=2,\n",
    "                                   bias=True, \n",
    "                                   #weight_bit_width=weight_bit_width,\n",
    "                                   #output_quant=Int8ActPerTensorFloat,\n",
    "                                   bias_quant=Int8Bias,\n",
    "                                   return_quant_tensor=True)\n",
    "        #print(self.fc3)\n",
    "        #self.sigmoid = QuantSigmoid(return_quant_tensor=True)\n",
    "        #self.sigmoid = nn.Sigmoid()\n",
    "        #'''\n",
    "        # Non Quantized\n",
    "        #'''\n",
    "        self.conv1 = nn.Conv1d(in_channels=4, out_channels= 20,kernel_size= 17 )\n",
    "        self.batchnorm1 = nn.BatchNorm1d(20)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool1d(kernel_size=n_channels)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=20, out_channels=15 ,kernel_size= 5)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(15)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool1d(kernel_size=n_channels)\n",
    "        self.conv3 = nn.Conv1d(in_channels=15, out_channels=10 , kernel_size=5)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(10)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool1d(kernel_size=2)\n",
    "        self.conv4 = nn.Conv1d(in_channels=10, out_channels=5 , kernel_size=5)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(5)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(in_features=5*1*9, out_features= 7, bias=True)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(in_features=7, out_features=5, bias=True)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(in_features=5, out_features=1, bias=True)\n",
    "        #self.sigmoid = nn.Sigmoid()#'''\n",
    "\n",
    "    @staticmethod\n",
    "    def _len_last_layer(n_channels, input_size, max_pool_size, n_conv_chs):\n",
    "        return n_channels * (input_size // (max_pool_size ** 2)) * n_conv_chs\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass.\n",
    "        \n",
    "        Parameters\n",
    "        ---------\n",
    "        x: torch.Tensor\n",
    "            Batch of EEG windows of shape (batch_size, n_channels, n_times).\n",
    "        \"\"\"\n",
    "        #print('in', x.shape)\n",
    "        #x = self.quant_identity(x)  # UNCOMMENT FOR QUANTIZATION \n",
    "        #print(f\"Input has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        #print('conv1', x.shape)\n",
    "        x = self.conv1(x)\n",
    "        #print(f\"CONV1:\\n {x} \\n\")\n",
    "        #print(f\"CONV1 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        #print('bn', x.shape)\n",
    "        x = self.batchnorm1(x)\n",
    "        #print(f\"BN1 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        #print('relu', x.shape)\n",
    "        x = self.relu1(x)\n",
    "        #print(f\"R1 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        #print('maxpool', x.shape)\n",
    "        x = self.maxpool1(x)\n",
    "        #print(f\"MP1 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        #print('dropout', x.shape)\n",
    "        x = self.dropout(x)\n",
    "        #print(f\"DR1 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        #print('conv2 shape', x.shape)\n",
    "        x = self.conv2(x)\n",
    "        #print(f\"CONV2:\\n {x} \\n\")\n",
    "        #print(f\"CONV2 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.batchnorm2(x)\n",
    "        #print(f\"BN2 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.relu2(x)\n",
    "        #print(f\"R2 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.maxpool2(x)\n",
    "        #print(f\"MP2 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.dropout(x)\n",
    "        #print(f\"DR2 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.conv3(x)\n",
    "        #print(f\"CONV3:\\n {x} \\n\")\n",
    "        #print(f\"CONV3 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.batchnorm3(x)\n",
    "        #print(f\"BN3 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.relu3(x)\n",
    "        #print(f\"R3 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.maxpool3(x)\n",
    "        #print(f\"MP3 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.dropout(x)\n",
    "        #print(f\"DR3 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.conv4(x)\n",
    "        #print(f\"CONV4:\\n {x} \\n\")\n",
    "        #print(f\"CONV4 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.batchnorm4(x)\n",
    "        #print(f\"BN4 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.relu4(x)\n",
    "        #print(f\"R4 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu5(self.fc1(x.flatten(start_dim=1)))\n",
    "        #print(f\"FC1:\\n {x} \\n\")\n",
    "        #print(f\"FC1 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.relu6(self.fc2(x))\n",
    "        #print(f\"FC2:\\n {x} \\n\")\n",
    "        #print(f\"FC2 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        #x = self.sigmoid(self.fc3(x))\n",
    "        x = self.fc3(x)\n",
    "        #print(f\"FC3:\\n {x} \\n\")\n",
    "        #print(f\"FC3 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv1D HPO Params softmax\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class IEEGSeizureDetection_2sec(nn.Module):\n",
    "   \n",
    "    def __init__(self, n_channels, sfreq, n_conv_chs=15, time_conv_size_s=0.5,\n",
    "                 max_pool_size_s=0.03125, n_classes=2, input_size_s=5, dropout=0.25):\n",
    "        super(IEEGSeizureDetection_2sec, self).__init__()\n",
    "\n",
    "        time_conv_size = int(time_conv_size_s * sfreq) #256\n",
    "        max_pool_size = int(max_pool_size_s * sfreq)   #16\n",
    "        input_size = int(input_size_s * sfreq)         #2560\n",
    "        pad_size = time_conv_size // 2                 #128\n",
    "        self.n_channels = 4                            #2\n",
    "        len_last_layer = self._len_last_layer(n_channels, input_size, max_pool_size, n_conv_chs) #300\n",
    "        beta = 0.89\n",
    "        print('Check parameters',time_conv_size,max_pool_size,input_size,pad_size,self.n_channels, len_last_layer)\n",
    "\n",
    "        #Quantized Aware Training\n",
    "        #8-bit signed integer with a per-tensor floating-point scale factor (ONNX standard)\n",
    "        '''\n",
    "        weight_bit_width = 4\n",
    "        act_bit_width = 4\n",
    "        #Layer1\n",
    "        self.quant_identity = QuantIdentity(return_quant_tensor=True)\n",
    "        self.conv1 = qnn.QuantConv1d(in_channels=4, out_channels= 20,kernel_size= 17,\n",
    "                                     bias=True,\n",
    "                                     #weight_bit_width=weight_bit_width,\n",
    "                                     #input_quant=Int8ActPerTensorFloat, \n",
    "                                     #weight_quant=Int8ActPerTensorFloat,\n",
    "                                     bias_quant=Int8Bias,\n",
    "                                     #output_quant=Int8ActPerTensorFloat,\n",
    "                                     return_quant_tensor=True)\n",
    "        #print(self.conv1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(20)\n",
    "        self.maxpool1 = nn.MaxPool1d(kernel_size=4)\n",
    "        self.dropout = QuantDropout(0.2)\n",
    "        self.relu1 = QuantReLU(return_quant_tensor=True)\n",
    "        \n",
    "        #Layer2\n",
    "        self.conv2 = qnn.QuantConv1d(in_channels=20, out_channels=10 ,kernel_size= 5,\n",
    "                                     bias=True,\n",
    "                                     #weight_bit_width=weight_bit_width,\n",
    "                                     #input_quant=Int8ActPerTensorFloat, \n",
    "                                     bias_quant=Int8Bias,\n",
    "                                     #output_quant=Int8ActPerTensorFloat,\n",
    "                                     return_quant_tensor=True)\n",
    "        #print(self.conv2)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(10)\n",
    "        self.maxpool2 = nn.MaxPool1d(kernel_size=4)\n",
    "        self.relu2 = QuantReLU(return_quant_tensor=True)\n",
    "        \n",
    "        #Layer3\n",
    "        self.conv3 = qnn.QuantConv1d(in_channels=10, out_channels=10 , kernel_size=5,\n",
    "                                     bias=True,\n",
    "                                     #weight_bit_width=weight_bit_width,\n",
    "                                     #input_quant=Int8ActPerTensorFloat, \n",
    "                                     bias_quant=Int8Bias,\n",
    "                                     #output_quant=Int8ActPerTensorFloat,\n",
    "                                     return_quant_tensor=True)\n",
    "        #print(self.conv3)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(10)\n",
    "        self.maxpool3 = nn.MaxPool1d(kernel_size=2)\n",
    "        self.relu3 = QuantReLU(return_quant_tensor=True)\n",
    "        \n",
    "        #Layer4\n",
    "        self.conv4 = qnn.QuantConv1d(in_channels=10, out_channels=10 , kernel_size=5,\n",
    "                                     bias=True,\n",
    "                                     #weight_bit_width=weight_bit_width,\n",
    "                                     #input_quant=Int8ActPerTensorFloat, \n",
    "                                     bias_quant=Int8Bias,\n",
    "                                     #output_quant=Int8ActPerTensorFloat,\n",
    "                                     return_quant_tensor=True)\n",
    "        #print(self.conv4)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(10)\n",
    "        self.relu4 = QuantReLU(return_quant_tensor=True)\n",
    "        \n",
    "        #Layer5\n",
    "        self.fc1 = qnn.QuantLinear(in_features=10*1*9, out_features= 5, \n",
    "                                   bias=True,   \n",
    "                                   #weight_bit_width=weight_bit_width,\n",
    "                                   #output_quant=Int8ActPerTensorFloat,\n",
    "                                   bias_quant=Int8Bias,\n",
    "                                   return_quant_tensor=True)\n",
    "        #print(self.fc1)\n",
    "        self.relu5 = QuantReLU(return_quant_tensor=True)\n",
    "        \n",
    "        #Layer6\n",
    "        self.fc2 = qnn.QuantLinear(in_features=5, out_features=5, \n",
    "                                   bias=True,  \n",
    "                                   #weight_bit_width=weight_bit_width,\n",
    "                                   #output_quant=Int8ActPerTensorFloat,\n",
    "                                   bias_quant=Int8Bias,\n",
    "                                   return_quant_tensor=True)\n",
    "        #print(self.fc2)\n",
    "        self.relu6 = QuantReLU(return_quant_tensor=True)\n",
    "        \n",
    "        #Layer7\n",
    "        self.fc3 = qnn.QuantLinear(in_features=5, \n",
    "                                   #out_features=1, \n",
    "                                   #input_quant=Int8ActPerTensorFloat, \n",
    "                                   out_features=2,\n",
    "                                   bias=True, \n",
    "                                   #weight_bit_width=weight_bit_width,\n",
    "                                   #output_quant=Int8ActPerTensorFloat,\n",
    "                                   bias_quant=Int8Bias,\n",
    "                                   return_quant_tensor=True)\n",
    "        #print(self.fc3)\n",
    "        #self.sigmoid = QuantSigmoid(return_quant_tensor=True)\n",
    "        #self.sigmoid = nn.Sigmoid()\n",
    "        #'''\n",
    "        # Non Quantized\n",
    "        #'''\n",
    "        self.conv1 = nn.Conv1d(in_channels=4, out_channels= 20,kernel_size= 17 )\n",
    "        self.batchnorm1 = nn.BatchNorm1d(20)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool1d(kernel_size=n_channels)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=20, out_channels=10 ,kernel_size= 5)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(10)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool1d(kernel_size=n_channels)\n",
    "        self.conv3 = nn.Conv1d(in_channels=10, out_channels=10 , kernel_size=5)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(10)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool1d(kernel_size=2)\n",
    "        self.conv4 = nn.Conv1d(in_channels=10, out_channels=5 , kernel_size=5)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(5)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(in_features=5*1*9, out_features= 5, bias=True)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(in_features=5, out_features=5, bias=True)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(in_features=5, out_features=2, bias=True)\n",
    "        #self.sigmoid = nn.Sigmoid()#'''\n",
    "\n",
    "    @staticmethod\n",
    "    def _len_last_layer(n_channels, input_size, max_pool_size, n_conv_chs):\n",
    "        return n_channels * (input_size // (max_pool_size ** 2)) * n_conv_chs\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu5(self.fc1(x.flatten(start_dim=1)))\n",
    "        x = self.relu6(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING NEURAL NETWORK with parameterization for freq = 256Hz and t= 2sec : based on Farrokh's # conv2D QAT/nonQAT\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class IEEGSeizureDetection_2sec(nn.Module):\n",
    "   \n",
    "    def __init__(self, n_channels, sfreq, n_conv_chs=15, time_conv_size_s=0.5,\n",
    "                 max_pool_size_s=0.03125, n_classes=2, input_size_s=5, dropout=0.25):\n",
    "        super(IEEGSeizureDetection_2sec, self).__init__()\n",
    "\n",
    "        time_conv_size = int(time_conv_size_s * sfreq) #256\n",
    "        max_pool_size = int(max_pool_size_s * sfreq)   #16\n",
    "        input_size = int(input_size_s * sfreq)         #2560\n",
    "        pad_size = time_conv_size // 2                 #128\n",
    "        self.n_channels = 4                            #2\n",
    "        len_last_layer = self._len_last_layer(n_channels, input_size, max_pool_size, n_conv_chs) #300\n",
    "        beta = 0.89\n",
    "        print('Check parameters',time_conv_size,max_pool_size,input_size,pad_size,self.n_channels, len_last_layer)\n",
    "\n",
    "        #Quantized Aware Training\n",
    "        #8-bit signed integer with a per-tensor floating-point scale factor (ONNX standard)\n",
    "        '''\n",
    "        weight_bit_width = 4\n",
    "        act_bit_width = 4\n",
    "        #Layer1\n",
    "        self.quant_identity = QuantIdentity(return_quant_tensor=True)\n",
    "        self.conv1 = qnn.QuantConv2d(in_channels=1, out_channels= 20,kernel_size= (n_channels,17),\n",
    "                                     bias=True,\n",
    "                                     #weight_bit_width=weight_bit_width,\n",
    "                                     #input_quant=Int8ActPerTensorFloat, \n",
    "                                     #weight_quant=Int8ActPerTensorFloat,\n",
    "                                     bias_quant=Int8Bias,\n",
    "                                     #output_quant=Int8ActPerTensorFloat,\n",
    "                                     return_quant_tensor=True)\n",
    "        #print(self.conv1)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(20)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(1,n_channels))\n",
    "        self.dropout = QuantDropout(0.2)\n",
    "        self.relu1 = QuantReLU(return_quant_tensor=True)\n",
    "        \n",
    "        #Layer2\n",
    "        self.conv2 = qnn.QuantConv2d(in_channels=20, out_channels=10 ,kernel_size= (1,5),\n",
    "                                     bias=True,\n",
    "                                     #weight_bit_width=weight_bit_width,\n",
    "                                     #input_quant=Int8ActPerTensorFloat, \n",
    "                                     bias_quant=Int8Bias,\n",
    "                                     #output_quant=Int8ActPerTensorFloat,\n",
    "                                     return_quant_tensor=True)\n",
    "        #print(self.conv2)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(10)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=(1,n_channels))\n",
    "        self.relu2 = QuantReLU(return_quant_tensor=True)\n",
    "        \n",
    "        #Layer3\n",
    "        self.conv3 = qnn.QuantConv2d(in_channels=10, out_channels=10 , kernel_size=(1,5),\n",
    "                                     bias=True,\n",
    "                                     #weight_bit_width=weight_bit_width,\n",
    "                                     #input_quant=Int8ActPerTensorFloat, \n",
    "                                     bias_quant=Int8Bias,\n",
    "                                     #output_quant=Int8ActPerTensorFloat,\n",
    "                                     return_quant_tensor=True)\n",
    "        #print(self.conv3)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(10)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=(1,2))\n",
    "        self.relu3 = QuantReLU(return_quant_tensor=True)\n",
    "        \n",
    "        #Layer4\n",
    "        self.conv4 = qnn.QuantConv2d(in_channels=10, out_channels=10 , kernel_size=(1,5),\n",
    "                                     bias=True,\n",
    "                                     #weight_bit_width=weight_bit_width,\n",
    "                                     #input_quant=Int8ActPerTensorFloat, \n",
    "                                     bias_quant=Int8Bias,\n",
    "                                     #output_quant=Int8ActPerTensorFloat,\n",
    "                                     return_quant_tensor=True)\n",
    "        #print(self.conv4)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(10)\n",
    "        self.relu4 = QuantReLU(return_quant_tensor=True)\n",
    "        \n",
    "        #Layer5\n",
    "        self.fc1 = qnn.QuantLinear(in_features=10*1*9, out_features= 5, \n",
    "                                   bias=True,   \n",
    "                                   #weight_bit_width=weight_bit_width,\n",
    "                                   #output_quant=Int8ActPerTensorFloat,\n",
    "                                   bias_quant=Int8Bias,\n",
    "                                   return_quant_tensor=True)\n",
    "        #print(self.fc1)\n",
    "        self.relu5 = QuantReLU(return_quant_tensor=True)\n",
    "        \n",
    "        #Layer6\n",
    "        self.fc2 = qnn.QuantLinear(in_features=5, out_features=5, \n",
    "                                   bias=True,  \n",
    "                                   #weight_bit_width=weight_bit_width,\n",
    "                                   #output_quant=Int8ActPerTensorFloat,\n",
    "                                   bias_quant=Int8Bias,\n",
    "                                   return_quant_tensor=True)\n",
    "        #print(self.fc2)\n",
    "        self.relu6 = QuantReLU(return_quant_tensor=True)\n",
    "        \n",
    "        #Layer7\n",
    "        self.fc3 = qnn.QuantLinear(in_features=5, \n",
    "                                   #out_features=1, \n",
    "                                   #input_quant=Int8ActPerTensorFloat, \n",
    "                                   out_features=2,\n",
    "                                   bias=True, \n",
    "                                   #weight_bit_width=weight_bit_width,\n",
    "                                   #output_quant=Int8ActPerTensorFloat,\n",
    "                                   bias_quant=Int8Bias,\n",
    "                                   return_quant_tensor=True)\n",
    "        #print(self.fc3)\n",
    "        #self.sigmoid = QuantSigmoid(return_quant_tensor=True)\n",
    "        #self.sigmoid = nn.Sigmoid()\n",
    "        #'''\n",
    "        # Non Quantized\n",
    "        #'''\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels= 20,kernel_size= (n_channels,17) )\n",
    "        self.batchnorm1 = nn.BatchNorm2d(20)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(1,n_channels))\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=20, out_channels=10 ,kernel_size= (1,5))\n",
    "        self.batchnorm2 = nn.BatchNorm2d(10)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=(1,n_channels))\n",
    "        self.conv3 = nn.Conv2d(in_channels=10, out_channels=10 , kernel_size=(1,5))\n",
    "        self.batchnorm3 = nn.BatchNorm2d(10)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=(1,2))\n",
    "        self.conv4 = nn.Conv2d(in_channels=10, out_channels=10 , kernel_size=(1,5))\n",
    "        self.batchnorm4 = nn.BatchNorm2d(10)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(in_features=10*1*9, out_features= 5, bias=True)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(in_features=5, out_features=5, bias=True)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(in_features=5, out_features=2, bias=True)\n",
    "        #self.sigmoid = nn.Sigmoid()#'''\n",
    "\n",
    "    @staticmethod\n",
    "    def _len_last_layer(n_channels, input_size, max_pool_size, n_conv_chs):\n",
    "        return n_channels * (input_size // (max_pool_size ** 2)) * n_conv_chs\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass.\n",
    "        \n",
    "        Parameters\n",
    "        ---------\n",
    "        x: torch.Tensor\n",
    "            Batch of EEG windows of shape (batch_size, n_channels, n_times).\n",
    "        \"\"\"\n",
    "        \n",
    "        #x = self.quant_identity(x)  # UNCOMMENT FOR QUANTIZATION \n",
    "        #print(f\"Input has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.conv1(x)\n",
    "        #print(f\"CONV1:\\n {x} \\n\")\n",
    "        #print(f\"CONV1 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.batchnorm1(x)\n",
    "        #print(f\"BN1 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.relu1(x)\n",
    "        #print(f\"R1 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.maxpool1(x)\n",
    "        #print(f\"MP1 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.dropout(x)\n",
    "        #print(f\"DR1 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.conv2(x)\n",
    "        #print(f\"CONV2:\\n {x} \\n\")\n",
    "        #print(f\"CONV2 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.batchnorm2(x)\n",
    "        #print(f\"BN2 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.relu2(x)\n",
    "        #print(f\"R2 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.maxpool2(x)\n",
    "        #print(f\"MP2 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.dropout(x)\n",
    "        #print(f\"DR2 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.conv3(x)\n",
    "        #print(f\"CONV3:\\n {x} \\n\")\n",
    "        #print(f\"CONV3 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.batchnorm3(x)\n",
    "        #print(f\"BN3 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.relu3(x)\n",
    "        #print(f\"R3 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.maxpool3(x)\n",
    "        #print(f\"MP3 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.dropout(x)\n",
    "        #print(f\"DR3 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.conv4(x)\n",
    "        #print(f\"CONV4:\\n {x} \\n\")\n",
    "        #print(f\"CONV4 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.batchnorm4(x)\n",
    "        #print(f\"BN4 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.relu4(x)\n",
    "        #print(f\"R4 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu5(self.fc1(x.flatten(start_dim=1)))\n",
    "        #print(f\"FC1:\\n {x} \\n\")\n",
    "        #print(f\"FC1 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        x = self.relu6(self.fc2(x))\n",
    "        #print(f\"FC2:\\n {x} \\n\")\n",
    "        #print(f\"FC2 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "        #x = self.sigmoid(self.fc3(x))\n",
    "        x = self.fc3(x)\n",
    "        #print(f\"FC3:\\n {x} \\n\")\n",
    "        #print(f\"FC3 has QuantTensor:\\n {x.is_valid} \\n\")\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notes on Quantization from :\n",
    "#    https://github.com/Xilinx/brevitas/blob/master/notebooks/01_quant_tensor_quant_conv2d_overview.ipynb\n",
    "#default_quant_conv.quant_weight().is_valid to check if tensor is correctly quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_detection_delay_for_eval(df):\n",
    "    #print(df)\n",
    "    if ((df['True_Label'] == 0).all() and (df['Predicted_Label'] == 0).all()):\n",
    "        print('STATUS : No seizure labeled or detected')\n",
    "        diff = 0\n",
    "        s_d = 0\n",
    "    elif ((df['True_Label'] == 0).all() and not((df['Predicted_Label'] == 0).all())):\n",
    "        print('STATUS : False detection happened')\n",
    "        diff = 0\n",
    "        s_d = 0\n",
    "    elif (not((df['True_Label'] == 0).all()) and (df['Predicted_Label'] == 0).all()):\n",
    "        print('STATUS : Detection Missed')\n",
    "        diff = 0\n",
    "        s_d = 0\n",
    "    elif (not((df['True_Label'] == 0).all()) and not((df['Predicted_Label'] == 0).all())):\n",
    "        #t_pred = df.index[df['Predicted_Label'] == 1].tolist()\n",
    "        #t_true = df.index[df['True_Label'] == 1].tolist()\n",
    "        t_true = np.where(df[ 'True_Label'] == 1)\n",
    "        t_pred = np.where(df[ 'Predicted_Label'] == 1)\n",
    "        print('Indices', t_pred, t_true, len(t_pred[0]))\n",
    "        if t_pred[0][0] <= t_true[0][0]:\n",
    "            #print('inside if loop',t_pred[0][0], t_true[0][0])\n",
    "            for i in range(0,len(t_pred[0])):\n",
    "                #print('length of pred', len(t_pred[0]))\n",
    "                #print('inside for loop',t_pred[0][i], t_true[0][0])\n",
    "                if t_pred[0][i] >= t_true[0][0]:\n",
    "                    #print('for if loop',t_pred[0][i], t_true[0][0])\n",
    "                    t_pred_c = t_pred[0][i]\n",
    "                    #print('IF for loop check',t_pred[0][i], t_true[0][0])\n",
    "                    break\n",
    "                else:\n",
    "                    print('Still searching......')\n",
    "                    t_pred_c = t_pred[0][0]\n",
    "                    #print('IF LSE for loop check',t_pred[0][i], t_true[0][0])       \n",
    "            print('Exiting for loop....')\n",
    "        else:\n",
    "            t_pred_c = t_pred[0][0]\n",
    "            #print('ELSE for loop check',t_pred[0][0], t_true[0][0])\n",
    "        print('pred correct',t_pred_c )\n",
    "        print('Indices', t_pred[0][0], t_true[0][0],t_pred_c)\n",
    "        if t_pred[0][0] <= t_true[0][0]: #False pos\n",
    "            print('STATUS : False detection happened, but there is a seizure also')\n",
    "        print('Prediction time', df.iloc[t_pred_c,6], 'True time',df.iloc[t_true[0][0],6] )\n",
    "        diff = (df.iloc[t_pred_c,6] - df.iloc[t_true[0][0],6])/1000.0 \n",
    "        print('STATUS : Detection delay of',diff,'secs')\n",
    "        s_d = 1\n",
    "    return diff, s_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(conf_mat,pat,fold):\n",
    "    classes_mapping = {0: 'non-ictal', 1: 'ictal'} \n",
    "    ticks = list(classes_mapping.keys())\n",
    "    tick_labels = classes_mapping.values()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    im = ax.imshow(conf_mat, cmap='Reds')\n",
    "    ax.set_yticks(ticks)\n",
    "    ax.set_yticklabels(tick_labels)\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_xticklabels(tick_labels)\n",
    "    ax.set_ylabel('True label')\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    ax.set_title('Confusion matrix')\n",
    "\n",
    "    for i in range(len(ticks)):\n",
    "        for j in range(len(ticks)):\n",
    "            text = ax.text(\n",
    "                j, i, conf_mat[i, j], ha='center', va='center', color='k')\n",
    "\n",
    "    fig.colorbar(im, ax=ax, fraction=0.05, label='# examples')\n",
    "    fig.tight_layout()\n",
    "    #fig.savefig('./save_plot/confusion_matrix_'+i+'.png')\n",
    "    plt.savefig('./results_1D_softmax/best_f1/ConfMat_' + pat + '_' + fold + '.png')\n",
    "    plt.close()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(history_d, pat, fold):\n",
    "    #['epoch'] ['train_loss'] ['valid_loss'] ['train_perf'] ['valid_perf']['valid_ap']['valid_f1']\n",
    "    #Save the dictionary to file and \n",
    "    column_info = ['epoch', 'train_loss', 'valid_loss', 'train_perf','valid_perf', 'valid_ap','valid_f1']\n",
    "    \n",
    "    with open('./results_1D_softmax/best_f1/history'+ pat + '_' + fold + '.csv', 'w') as csvfile:\n",
    "        for key in history_d.keys():\n",
    "            csvfile.write(\"%s,%s\\n\"%(key,history_d[key]))\n",
    "\n",
    "    pd.read_csv('./results_1D_softmax/best_f1/history'+ pat + '_' + fold + '.csv', header=None).T.to_csv('./saved_model/conv1D_1output/history_c_'+ pat + '_' + fold + '.csv', header=False, index=False)\n",
    "    os.remove('./results_1D_softmax/best_f1/history'+ pat + '_' + fold + '.csv')\n",
    "    \n",
    "    #Save the plot as image!\n",
    "    fig = plt.figure()\n",
    "\n",
    "    ax1 = plt.subplot2grid((2,1), (0,0))\n",
    "    ax2 = plt.subplot2grid((2,1), (1,0), sharex=ax1)\n",
    "\n",
    "    ax1.plot(history_d['epoch'], history_d['train_perf'], label=\"Train Accuracy\")\n",
    "    ax1.plot(history_d['epoch'], history_d['valid_perf'], label=\"Test Accuracy\")\n",
    "    ax1.plot(history_d['epoch'],history_d['valid_f1'], label=\"Test F1\")\n",
    "    ax1.legend(loc=2)\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Performance')\n",
    "    ax2.plot(history_d['epoch'],history_d['train_loss'], label=\"Train Loss\")\n",
    "    ax2.plot(history_d['epoch'],history_d['valid_loss'], label=\"Test Loss\")\n",
    "    ax2.legend(loc=2)\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    #ax2.axis(ymin=0.0,ymax=0.02)\n",
    "    plt.show()\n",
    "    plt.savefig('./results_1D_softmax/best_f1/LearningCurve' + pat + '_' + fold + '.png')\n",
    "    plt.close()\n",
    "#plot_learning_curve(history,str([patient_id[p_id]][0]),'1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_detection_delay( pat, fold):\n",
    "    plt.savefig('./save_plot_1D/detection_delay' + pat + '_' + fold + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv1D\n",
    "from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score\n",
    "from sklearn.metrics import average_precision_score, f1_score,  auc\n",
    "from sklearn.metrics import precision_recall_curve, confusion_matrix\n",
    "\n",
    "def analog_to_spike(batch_x, batch_y):\n",
    "    #print('shape for analog to spike',np.shape(batch_x), np.shape(batch_x)[0])\n",
    "    b_s = np.shape(batch_x)[0]\n",
    "    c_s = np.shape(batch_x)[2]\n",
    "    t_s = np.shape(batch_x)[3]\n",
    "\n",
    "    batch_x = spikegen.delta(batch_x, threshold=0.5, off_spike=False)\n",
    "    #print('shape for loop',np.shape(batch_x), len(batch_x),b_s,c_s,t_s, 'shape of y',np.shape(batch_y))\n",
    "    #print('Check the value to be plotted', batch_x[0,0,0,:], len(batch_x[0,0,0,:])\n",
    "    '''\n",
    "    for b in range(0,5):\n",
    "        for c in range(0,c_s):    \n",
    "            # Create fig, ax\n",
    "            fig = plt.figure(facecolor=\"w\", figsize=(8, 4))\n",
    "            ax = fig.add_subplot(111)\n",
    "\n",
    "            # Raster plot of delta converted data\n",
    "            splt.raster(batch_x[b,0,c,:], ax)\n",
    "\n",
    "            plt.title(\"Input Neuron\"+ \"for batchsample_\"+ str(b) +\"_for channel_\"+ str(c) + \"_with_label:\" +str(batch_y[b]))\n",
    "            plt.xlabel(\"Time step\")\n",
    "            plt.yticks([])\n",
    "            plt.xlim(0,t_s )\n",
    "            fig.canvas.draw()\n",
    "    '''\n",
    "    return batch_x\n",
    "            \n",
    "\n",
    "def _do_train(model, loader, optimizer, criterion, device, metric):\n",
    "    # training loop\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = np.zeros(len(loader))\n",
    "    y_pred_all, y_true_all = list(), list()\n",
    "    for idx_batch, (batch_x, batch_y, batch_t) in enumerate(loader):\n",
    "        \n",
    "        batch_x = batch_x.to(device=device, dtype=torch.float32)   #([180, 1, 2, 2560])\n",
    "        batch_x = torch.squeeze(batch_x,1)\n",
    "        batch_y = batch_y.to(device=device, dtype=torch.int64)\n",
    "        #print('Dataset dimensions',batch_x.shape, batch_y.shape)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_x)\n",
    "        #output = torch.squeeze(output,1)(\n",
    "        #batch_y = batch_y.unsqueeze(1).float()\n",
    "        #print('predicted class', torch.argmax(output, axis=1).cpu().numpy())\n",
    "        loss = criterion(output, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n",
    "        y_true_all.append(batch_y.cpu().numpy())\n",
    "\n",
    "        train_loss[idx_batch] = loss.item()\n",
    "        \n",
    "    y_pred = np.concatenate(y_pred_all)\n",
    "    y_true = np.concatenate(y_true_all)\n",
    "    perf = metric(y_true, y_pred)\n",
    "    acc = np.mean(y_true == y_pred)\n",
    "    #print('TRAIN: y_pred',y_pred,'y_true',y_true )\n",
    "    return np.mean(train_loss), perf   \n",
    "        \n",
    "'''\n",
    "def _validate(model, loader, criterion, device, metric):\n",
    "    # validation loop\n",
    "    model.eval()\n",
    "    \n",
    "    val_loss = np.zeros(len(loader))\n",
    "    y_pred_all, y_true_all = list(), list()\n",
    "    with torch.no_grad():\n",
    "        for idx_batch, (batch_x, batch_y, batch_t) in enumerate(loader):\n",
    "            batch_x = batch_x.to(device=device, dtype=torch.float32)\n",
    "            batch_y = batch_y.to(device=device, dtype=torch.int64)\n",
    "            output = model.forward(batch_x)\n",
    "            #output = torch.squeeze(output,1)\n",
    "            #print('predicted class', torch.argmax(output, axis=1).cpu().numpy())\n",
    "            #print('actual class', batch_y)\n",
    "            loss = criterion(output, batch_y)\n",
    "            val_loss[idx_batch] = loss.item()\n",
    "            \n",
    "            y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n",
    "            y_true_all.append(batch_y.cpu().numpy())\n",
    "            \n",
    "    y_pred = np.concatenate(y_pred_all)\n",
    "    y_true = np.concatenate(y_true_all)\n",
    "    perf = metric(y_true, y_pred)\n",
    "    #print('VALID: y_pred',y_pred,'y_true',y_true)    \n",
    "    return np.mean(val_loss), perf'''\n",
    "\n",
    "def _validate(model, loader, criterion, device, metric):\n",
    "    # validation loop\n",
    "    model.eval()\n",
    "    \n",
    "    average_precision = 0\n",
    "    f1_score_eval = 0\n",
    "    val_loss = np.zeros(len(loader))\n",
    "    y_pred_all, y_true_all, y_score_all = list(), list(), list()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx_batch, (batch_x, batch_y, batch_t) in enumerate(loader):\n",
    "            batch_x = batch_x.to(device=device, dtype=torch.float32)\n",
    "            batch_x = torch.squeeze(batch_x,1)\n",
    "            batch_y = batch_y.to(device=device, dtype=torch.int64)\n",
    "            batch_t = batch_t.to(device=device, dtype=torch.float32)\n",
    "            output = model.forward(batch_x)\n",
    "            #output = torch.squeeze(output,1)\n",
    "            #print('predicted class', torch.argmax(output, axis=1).cpu().numpy())\n",
    "            #print('actual class', batch_y)\n",
    "            loss = criterion(output, batch_y)\n",
    "            val_loss[idx_batch] = loss.item()\n",
    "            \n",
    "            pred_probab = nn.Softmax(dim=1)(output)  # Move this TODO\n",
    "            probs = pred_probab[:, 1]\n",
    "\n",
    "            y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n",
    "            y_true_all.append(batch_y.cpu().numpy())\n",
    "            y_score_all.append(probs.detach().cpu().numpy())\n",
    "            #print('Debug Average Precsion','pred_probab',pred_probab,'probs',probs, 'y_score_all' ,y_score_all)\n",
    "            \n",
    "    y_pred = np.concatenate(y_pred_all)\n",
    "    y_true = np.concatenate(y_true_all)\n",
    "    y_score = np.concatenate(y_score_all)\n",
    "    \n",
    "    perf = metric(y_true, y_pred)\n",
    "    f1_score_eval = f1_score(y_true, y_pred, average='binary')\n",
    "    average_precision = average_precision_score(y_true, y_score)\n",
    "    #print('VALIDATE: y_true', y_true, 'y_score', y_score)\n",
    "    \n",
    "    #print('VALID: No Mean',val_loss ,  np.mean(val_loss), perf, average_precision, f1_score_eval )  \n",
    "    # return loss, accuracy, AP, F1 score, delay\n",
    "    return np.mean(val_loss), perf, average_precision , f1_score_eval\n",
    "\n",
    "def _validate_1epoch(model, loader, criterion, fold, device, metric):\n",
    "    # validation loop\n",
    "    model.eval()\n",
    "    \n",
    "    average_precision = 0\n",
    "    f1_score_eval = 0\n",
    "    false_positives = 0\n",
    "    detection_delay = 0\n",
    "    val_loss = np.zeros(len(loader))\n",
    "    y_pred_all, y_true_all, y_score_all = list(), list(), list()\n",
    "    #m = nn.Sigmoid()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx_batch, (batch_x, batch_y, batch_t) in enumerate(loader):\n",
    "            batch_x = batch_x.to(device=device, dtype=torch.float32)\n",
    "            batch_x = torch.squeeze(batch_x,1)\n",
    "            batch_y = batch_y.to(device=device, dtype=torch.int64)\n",
    "            batch_t = batch_t.to(device=device, dtype=torch.float32)\n",
    "            output = model.forward(batch_x)\n",
    "            #output = torch.squeeze(output,1)\n",
    "            #print('predicted class', torch.argmax(output, axis=1).cpu().numpy())\n",
    "            #print('actual class', batch_y)\n",
    "            loss = criterion(output, batch_y)\n",
    "            val_loss[idx_batch] = loss.item()\n",
    "            \n",
    "            pred_probab = nn.Softmax(dim=1)(output)  # Move this TODO\n",
    "            probs = pred_probab[:, 1]\n",
    "            #print('Probs', probs, probs.shape, 'Pred probs', pred_probab, pred_probab.shape)\n",
    "            #print('Output', torch.argmax(output, axis=1).cpu().numpy())\n",
    "            #print('Output Max', torch.argmax(output, axis=1).cpu().numpy())\n",
    "            #print('Sigmoid to check', m(output).cpu())\n",
    "            y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n",
    "            y_true_all.append(batch_y.cpu().numpy())\n",
    "            y_score_all.append(probs.detach().cpu().numpy())\n",
    "            #print('Debug Average Precsion','pred_probab',pred_probab,'probs',probs, 'y_score_all' ,y_score_all)\n",
    "            \n",
    "            #''' # Create dataframe and plot true and predicted labels\n",
    "            num_bs =  len(batch_x)      #256\n",
    "            num_in = len(batch_x[0,0,:])   # 2560\n",
    "            #print('older t1', num_bs, num_in)\n",
    "            t1 = np.arange(0,num_in*num_bs,1)\n",
    "    \n",
    "            #create a dataframe to visualize randomized data,target and outputs\n",
    "            df_reconstruct_all = pd.DataFrame(columns=['Channel1', 'Channel2','Channel3','Channel4', 'True_Label', 'Predicted_Label'])\n",
    "            for i in range(0, len(batch_x)):\n",
    "                data_re = {'Channel1':  batch_x[i,0,:].cpu().numpy(),\n",
    "                    'Channel2': batch_x[i,1,:].cpu().numpy(),\n",
    "                    'Channel3': batch_x[i,2,:].cpu().numpy(),\n",
    "                    'Channel4': batch_x[i,3,:].cpu().numpy(),\n",
    "                    'True_Label' : np.full((num_in, ), batch_y[i].cpu().numpy()), # 2560 labels\n",
    "                    'Predicted_Label' : np.full((num_in, ),torch.argmax(output, axis=1)[i].cpu().numpy() ) ,\n",
    "                    'Time_Label': batch_t[i,:].cpu().numpy()\n",
    "                    }\n",
    "                df_reconstruct = pd.DataFrame(data_re)\n",
    "                df_reconstruct_all = df_reconstruct_all.append(df_reconstruct)\n",
    "    \n",
    "            #Calculate detection delay\n",
    "            dd, s_d = calculate_detection_delay_for_eval(df_reconstruct_all)\n",
    "            if s_d !=0:\n",
    "                detection_delay = dd\n",
    "    \n",
    "            #Plot all batches\n",
    "            #''' \n",
    "            figure, axs = plt.subplots(nrows=4, ncols=1,figsize=(10,5), constrained_layout=True)\n",
    "            axs[0].plot( df_reconstruct_all.Time_Label, df_reconstruct_all.Channel1)\n",
    "            axs[0].set_title('Channel1')\n",
    "            \n",
    "            axs[1].plot( df_reconstruct_all.Time_Label, df_reconstruct_all.Channel2)\n",
    "            axs[1].set_title('Channel2')\n",
    "    \n",
    "            axs[2].plot( df_reconstruct_all.Time_Label, df_reconstruct_all.True_Label)\n",
    "            axs[2].set_title('True Label')\n",
    "    \n",
    "            axs[3].plot( df_reconstruct_all.Time_Label, df_reconstruct_all.Predicted_Label )\n",
    "            axs[3].set_title('Predicted Label')\n",
    "            plt.show()#'''\n",
    "            #plt.savefig('./save_plot_1D/detection_delay' + str([patient_id[p_id]][0]) + '_' + str(fold) + '.png')\n",
    "            #print(df_reconstruct_all)  # Print the dataframe for each batch\n",
    "            \n",
    "    y_pred = np.concatenate(y_pred_all)\n",
    "    y_true = np.concatenate(y_true_all)\n",
    "    y_score = np.concatenate(y_score_all)\n",
    "    print('Check dimensions', y_pred.shape, y_true.shape, y_score.shape)\n",
    "    \n",
    "    test_bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    test_kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    print(f'Test balanced accuracy: {test_bal_acc:0.3f}')\n",
    "    print(f'Test Cohen\\'s kappa: {test_kappa:0.3f}')\n",
    "    \n",
    "    perf = metric(y_true, y_pred)\n",
    "    f1_score_eval = f1_score(y_true, y_pred, average='binary')\n",
    "    average_precision = average_precision_score(y_true, y_score)\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_score)\n",
    "    auc_precision_recall = auc(recall, precision)\n",
    "    \n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "    tn, false_positives, fn, tp = conf_mat.ravel()\n",
    "    print('conf_mat', conf_mat)\n",
    "    \n",
    "    plot_confusion_matrix(conf_mat)\n",
    "    \n",
    "    print(f'f1_score_eval: {f1_score_eval:0.3f} \\t  average_precision: {average_precision:0.3f} \\t'\n",
    "         f'auc_precision_recall: {auc_precision_recall:0.3f} \\t  detection_delay: {detection_delay:0.3f}  \\t'\n",
    "         f'false_positive: {false_positives:0.3f} \\t false_negativ: {fn:0.3f}' )\n",
    "    \n",
    "    #print('VALID:', np.mean(val_loss), perf, average_precision, f1_score_eval )  \n",
    "    \n",
    "    # return loss, accuracy, AP, F1 score,false_+s, delay\n",
    "    return np.mean(val_loss), perf, average_precision , f1_score_eval, detection_delay,conf_mat\n",
    "\n",
    "\n",
    "def train(model, loader_train, loader_test, optimizer, criterion, n_epochs, fold,\n",
    "          patience, device, metric=None):\n",
    "    \"\"\"Training function.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : instance of nn.Module\n",
    "        The model.\n",
    "    loader_train : instance of Sampler\n",
    "        The generator of EEG samples the model has to train on.\n",
    "        It contains n_train samples\n",
    "    loader_test : instance of Sampler\n",
    "        The generator of EEG samples the model has to validate on.\n",
    "        It contains n_val samples. The validation samples are used to\n",
    "        monitor the training process and to perform early stopping\n",
    "    optimizer : instance of optimizer\n",
    "        The optimizer to use for training.\n",
    "    n_epochs : int\n",
    "        The maximum of epochs to run.\n",
    "    patience : int\n",
    "        The patience parameter, i.e. how long to wait for the\n",
    "        validation error to go down.\n",
    "    metric : None | callable\n",
    "        Metric to use to evaluate performance on the training and\n",
    "        validation sets. Defaults to balanced accuracy.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    best_model : instance of nn.Module\n",
    "        The model that led to the best prediction on the validation\n",
    "        dataset.\n",
    "    history : list of dicts\n",
    "        Training history (loss, accuracy, etc.)\n",
    "    \"\"\"\n",
    "    best_valid_loss = np.inf\n",
    "    best_model = copy.deepcopy(model)\n",
    "    waiting = 0\n",
    "    history = list()\n",
    "    history_dict = {'epoch': [], 'train_loss': [], 'valid_loss': [],'train_perf':[],'valid_perf':[],'valid_ap':[],\n",
    "                    'valid_f1':[], 'false_positive':[],'detection_delay':[]}\n",
    "    \n",
    "    if metric is None:\n",
    "        metric = balanced_accuracy_score\n",
    "        \n",
    "    print('epoch \\t train_loss \\t valid_loss \\t train_perf \\t valid_perf \\t valid_ap \\t valid_f1')\n",
    "    print('-------------------------------------------------------------------')\n",
    "    print('Check number of epochs to run for LOOCV folds after selecting best hyperparam', n_epochs)\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_loss, train_perf = _do_train(\n",
    "            model, loader_train, optimizer, criterion, device, metric=metric)\n",
    "        \n",
    "        valid_loss, valid_perf, valid_ap, valid_f1 = _validate(\n",
    "            model, loader_test, criterion, device, metric=metric)\n",
    "        \n",
    "        #Save checkpoint\n",
    "        checkpoint = {\n",
    "            'epoch': epoch +1,\n",
    "            'state_dict' : model.state_dict(),\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }\n",
    "        #torch.save(checkpoint, './saved_model/QAT_ ' + '1' + '.pth')\n",
    "        #torch.save(model.state_dict(), './saved_model/QAT_ ' + '1' + '.pth')\n",
    "        #torch.save(best_model.state_dict(), './saved_model/conv1D/best-model-' + str([patient_id[p_id]][0]) +'_' +str(fold) +'.pth')\n",
    "           \n",
    "        history.append(\n",
    "            {'epoch': epoch, \n",
    "             'train_loss': train_loss, 'valid_loss': valid_loss,\n",
    "             'train_perf': train_perf, 'valid_perf': valid_perf, 'valid_ap': valid_ap,'valid_f1': valid_f1})\n",
    "        \n",
    "        print(f'{epoch} \\t {train_loss:0.4f} \\t {valid_loss:0.4f} '\n",
    "              f'\\t {train_perf:0.4f} \\t {valid_perf:0.4f}\\t {valid_ap:0.4f}\\t {valid_f1:0.4f}')\n",
    "                                                \n",
    "        history_dict['epoch'].append(epoch)\n",
    "        history_dict['train_loss'].append(train_loss)\n",
    "        history_dict['valid_loss'].append(valid_loss)\n",
    "        history_dict['train_perf'].append(train_perf)\n",
    "        history_dict['valid_perf'].append(valid_perf)\n",
    "        history_dict['valid_ap'].append(valid_ap)\n",
    "        history_dict['valid_f1'].append(valid_f1)\n",
    "        #'''\n",
    "        # model saving\n",
    "        if valid_loss < best_valid_loss:\n",
    "            print(f'best val loss {best_valid_loss:.4f} -> {valid_loss:.4f}')\n",
    "            best_valid_loss = valid_loss\n",
    "            print('Saving the best model')\n",
    "            best_model = copy.deepcopy(model)\n",
    "            waiting = 0\n",
    "        else:\n",
    "            waiting += 1\n",
    "\n",
    "        # model early stopping\n",
    "        if waiting >= patience or epoch==n_epochs:\n",
    "            print(f'Stop training at epoch {epoch}')\n",
    "            torch.save(best_model.state_dict(), './saved_model/conv1D/best-model-' + str([patient_id[p_id]][0]) +'_' +str(fold) +'.pth')\n",
    "            print(f'Best val loss : {best_valid_loss:.4f}')\n",
    "            break#'''\n",
    "        \n",
    "    '''   \n",
    "    valid_loss, valid_perf, valid_ap, valid_f1, fp, dd, fn = _validate_1epoch(\n",
    "            model, loader_test_1epoch, criterion, device, metric=metric)\n",
    "    \n",
    "    print('FINAL EVAL')\n",
    "    eval_metric = {\n",
    "        'valid_loss' : valid_loss, 'valid_perf' : valid_perf,'valid_ap' : valid_ap,\n",
    "        'valid_f1' : valid_f1, 'false_positive' : fp, 'detection_delay' : dd, 'false_negative' : fn\n",
    "    }'''\n",
    "    \n",
    "    return history_dict#, eval_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conv1D modified to make correct softmax with limit with 2 output neurons\n",
    "from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score\n",
    "from sklearn.metrics import average_precision_score, f1_score,  auc , roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, confusion_matrix, roc_curve\n",
    "from matplotlib import pyplot\n",
    "\n",
    "def _do_train(model, loader, optimizer, criterion, device, metric):\n",
    "    # training loop\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = np.zeros(len(loader))\n",
    "    y_pred_all, y_true_all = list(), list()\n",
    "    for idx_batch, (batch_x, batch_y, batch_t) in enumerate(loader):\n",
    "        \n",
    "        batch_x = batch_x.to(device=device, dtype=torch.float32)   #([180, 1, 2, 2560])\n",
    "        batch_x = torch.squeeze(batch_x,1)\n",
    "        batch_y = batch_y.to(device=device, dtype=torch.int64)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_x)\n",
    "        #output = torch.squeeze(output,1)(\n",
    "        #batch_y = batch_y.unsqueeze(1).float()\n",
    "        #print('predicted class', torch.argmax(output, axis=1).cpu().numpy())\n",
    "        loss = criterion(output, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n",
    "        # softmax limit instead of argmax\n",
    "        pred_probab = nn.Softmax(dim=1)(output).cpu()  \n",
    "        probs = pred_probab[:, 1]\n",
    "        \n",
    "        m = nn.Softmax(dim=1)\n",
    "        y_pred_all.append((probs.cpu() > 0.5))\n",
    "        y_true_all.append(batch_y.cpu().numpy())\n",
    "\n",
    "        train_loss[idx_batch] = loss.item()\n",
    "        \n",
    "    y_pred = np.concatenate(y_pred_all)\n",
    "    y_true = np.concatenate(y_true_all)\n",
    "    perf = metric(y_true, y_pred)\n",
    "    acc = np.mean(y_true == y_pred)\n",
    "    return np.mean(train_loss), perf   \n",
    "\n",
    "\n",
    "def _validate(model, loader, criterion, device, metric):\n",
    "    # validation loop\n",
    "    model.eval()\n",
    "    \n",
    "    average_precision = 0\n",
    "    f1_score_eval = 0\n",
    "    val_loss = np.zeros(len(loader))\n",
    "    y_pred_all, y_true_all, y_score_all = list(), list(), list()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx_batch, (batch_x, batch_y, batch_t) in enumerate(loader):\n",
    "            batch_x = batch_x.to(device=device, dtype=torch.float32)\n",
    "            batch_x = torch.squeeze(batch_x,1)\n",
    "            batch_y = batch_y.to(device=device, dtype=torch.int64)\n",
    "            batch_t = batch_t.to(device=device, dtype=torch.float32)\n",
    "            output = model.forward(batch_x)\n",
    "            #output = torch.squeeze(output,1)\n",
    "            #print('predicted class', torch.argmax(output, axis=1).cpu().numpy())\n",
    "            loss = criterion(output, batch_y)\n",
    "            val_loss[idx_batch] = loss.item()\n",
    "            \n",
    "            pred_probab = nn.Softmax(dim=1)(output)  \n",
    "            probs = pred_probab[:, 1]  \n",
    "            \n",
    "            y_pred_all.append((probs.cpu() > 0.5))\n",
    "            #y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n",
    "            y_true_all.append(batch_y.cpu().numpy())\n",
    "            y_score_all.append(probs.detach().cpu().numpy()) \n",
    "            \n",
    "    y_pred = np.concatenate(y_pred_all)\n",
    "    y_true = np.concatenate(y_true_all)\n",
    "    y_score = np.concatenate(y_score_all)\n",
    "    \n",
    "    perf = metric(y_true, y_pred)\n",
    "    f1_score_eval = f1_score(y_true, y_pred, average='binary')\n",
    "    average_precision = average_precision_score(y_true, y_score)\n",
    "    \n",
    "    return np.mean(val_loss), perf, average_precision , f1_score_eval\n",
    "\n",
    "def _validate_1epoch(model, loader, criterion, fold, device, metric):\n",
    "    # validation loop\n",
    "    model.eval()\n",
    "    \n",
    "    average_precision = 0\n",
    "    f1_score_eval = 0\n",
    "    false_positives = 0\n",
    "    detection_delay = 0\n",
    "    val_loss = np.zeros(len(loader))\n",
    "    y_pred_all, y_true_all, y_score_all = list(), list(), list()\n",
    "    num_bs_g = 0\n",
    "    num_in_g = 0\n",
    "    with torch.no_grad():\n",
    "        for idx_batch, (batch_x, batch_y, batch_t) in enumerate(loader):\n",
    "            batch_x = batch_x.to(device=device, dtype=torch.float32)\n",
    "            batch_x = torch.squeeze(batch_x,1)\n",
    "            batch_y = batch_y.to(device=device, dtype=torch.int64)\n",
    "            batch_t = batch_t.to(device=device, dtype=torch.float32)\n",
    "            output = model.forward(batch_x)\n",
    "            #output = torch.squeeze(output,1)\n",
    "            #print('predicted class', torch.argmax(output, axis=1).cpu().numpy())\n",
    "            loss = criterion(output, batch_y)\n",
    "            val_loss[idx_batch] = loss.item()\n",
    "            \n",
    "            pred_probab = nn.Softmax(dim=1)(output)  # Move this TODO\n",
    "            probs = pred_probab[:, 1]\n",
    "            \n",
    "            pd.DataFrame(pred_probab.detach().cpu().numpy()).to_csv('./results_1D_softmax/best_f1/PRC' + str([patient_id[p_id]][0]) + '_' + str(fold) + '.csv')\n",
    "            ###y_pred_all.append((probs.cpu() > 0.5))\n",
    "            #y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n",
    "            y_true_all.append(batch_y.cpu().numpy())\n",
    "            y_score_all.append(probs.detach().cpu().numpy())\n",
    "            \n",
    "            #''' # Create dataframe and plot true and predicted labels\n",
    "            num_bs =  len(batch_x)      #256\n",
    "            num_bs_g = num_bs\n",
    "            num_in = len(batch_x[0,0,:])   # 2560\n",
    "            num_in_g = num_in\n",
    "            #print('older t1', num_bs, num_in)\n",
    "            t1 = np.arange(0,num_in*num_bs,1)\n",
    "    \n",
    "            #create a dataframe to visualize randomized data,target and outputs\n",
    "            df_reconstruct_all = pd.DataFrame(columns=['Channel1', 'Channel2','Channel3','Channel4', 'True_Label', 'Predicted_Label'])\n",
    "            for i in range(0, len(batch_x)):\n",
    "                data_re = {'Channel1':  batch_x[i,0,:].cpu().numpy(),\n",
    "                    'Channel2': batch_x[i,1,:].cpu().numpy(),\n",
    "                    'Channel3': batch_x[i,2,:].cpu().numpy(),\n",
    "                    'Channel4': batch_x[i,3,:].cpu().numpy(),\n",
    "                    'True_Label' : np.full((num_in, ), batch_y[i].cpu().numpy()), # 2560 labels\n",
    "                    'Predicted_Label' : np.full((num_in, ),(probs.cpu().numpy() > 0.5)[i] ) ,\n",
    "                    'Time_Label': batch_t[i,:].cpu().numpy()\n",
    "                    }\n",
    "                df_reconstruct = pd.DataFrame(data_re)\n",
    "                df_reconstruct_all = df_reconstruct_all.append(df_reconstruct)\n",
    "            \n",
    "            '''\n",
    "            #Calculate detection delay\n",
    "            dd, s_d = calculate_detection_delay_for_eval(df_reconstruct_all)\n",
    "            if s_d !=0:\n",
    "                detection_delay = dd\n",
    "    \n",
    "            #Plot all batches\n",
    "            figure, axs = plt.subplots(nrows=4, ncols=1,figsize=(10,5), constrained_layout=True)\n",
    "            axs[0].plot( df_reconstruct_all.Time_Label, df_reconstruct_all.Channel1)\n",
    "            axs[0].set_title('Channel1')\n",
    "            \n",
    "            axs[1].plot( df_reconstruct_all.Time_Label, df_reconstruct_all.Channel2)\n",
    "            axs[1].set_title('Channel2')\n",
    "    \n",
    "            axs[2].plot( df_reconstruct_all.Time_Label, df_reconstruct_all.True_Label)\n",
    "            axs[2].set_title('True Label')\n",
    "    \n",
    "            axs[3].plot( df_reconstruct_all.Time_Label, df_reconstruct_all.Predicted_Label )\n",
    "            axs[3].set_title('Predicted Label')\n",
    "            plt.show()\n",
    "            plt.savefig('./results_1D_softmax/best_f1/detection_delay' + str([patient_id[p_id]][0]) + '_' + str(fold) + '.png')\n",
    "            '''\n",
    "    ###y_pred = np.concatenate(y_pred_all)\n",
    "    y_true = np.concatenate(y_true_all)\n",
    "    y_score = np.concatenate(y_score_all)\n",
    "    print('Check dimensions', y_true.shape, y_score.shape)\n",
    "    \n",
    "    # Get all threshold independent metrics - F1_Score, AU-PRC, AU-ROC\n",
    "    \n",
    "    #Plot precision recall characteristics\n",
    "    precision, recall, th = precision_recall_curve(y_true, y_score)\n",
    "    fscore = (2 * precision * recall) / (precision + recall)\n",
    "    ix = np.argmax(fscore)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(recall, precision, color='purple')\n",
    "    ax.scatter(recall[ix], precision[ix], marker='o', color='black', label='Best')\n",
    "    ax.set_title('Precision-Recall Curve')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.set_xlabel('Recall')\n",
    "    plt.show()\n",
    "    plt.savefig('./results_1D_softmax/best_f1/PRC' + str([patient_id[p_id]][0]) + '_' + str(fold) + '.png')\n",
    "    plt.close()\n",
    "    \n",
    "    average_precision =  round(average_precision_score(y_true, y_score), ndigits =4)\n",
    "    auc_precision_recall =  round(auc(recall, precision), ndigits =4)\n",
    "    best_f1 = round(fscore[ix], ndigits =4)\n",
    "    best_threshold = round(th[ix], ndigits =4)\n",
    "    print('Best Threshold=%f, F-Score=%.3f' % (th[ix], fscore[ix]))\n",
    "    print('Best Precision=%.3f, Best Recall=%.3f' % (precision[ix], recall[ix]))\n",
    "    print('bestF1=%f' % (best_f1))\n",
    "    print('Average Precision=%f' % (average_precision))\n",
    "    \n",
    "    #Threshold vs f1 score plot\n",
    "    '''\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.plot(np.append(th,1), fscore, color='black')\n",
    "    ax1.scatter(th[ix], fscore[ix], marker='o', color='red', label='Best')\n",
    "    ax1.set_title('Thresholding Curve')\n",
    "    ax1.set_ylabel('F1-score')\n",
    "    ax1.set_xlabel('Threshold')\n",
    "    plt.show()'''\n",
    "    \n",
    "    print('Plotting ROC')\n",
    "    #ROC characteristics\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "    pyplot.plot(fpr, tpr, marker='.', label='ROC')\n",
    "    pyplot.xlabel('False Positive Rate')\n",
    "    pyplot.ylabel('True Positive Rate')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()\n",
    "    plt.savefig('./results_1D_softmax/best_f1/ROC' + str([patient_id[p_id]][0]) + '_' + str(fold) + '.png')\n",
    "    pyplot.close()\n",
    "    \n",
    "    roc_auc = round(roc_auc_score(y_true, y_score), ndigits =4)\n",
    "    print('AUPRC=%f, AUROC=%f' % (auc_precision_recall, roc_auc))\n",
    "    \n",
    "    #Threshold Dependent Characteristics\n",
    "    y_pred = (y_score >= best_threshold).astype(int)\n",
    "    #y_pred = (y_score >= 0.3).astype(int)\n",
    "    #print('Compare lengths', y_score.shape, y_pred.shape)\n",
    "    #df_dataset = pd.DataFrame({'prob': y_score, 'pred': y_pred}, columns=['prob', 'pred'])\n",
    "    #df_dataset.to_csv('./results_1D_softmax/best_f1/check.csv')\n",
    "    \n",
    "    test_bal_acc = round(balanced_accuracy_score(y_true, y_pred), ndigits =4)\n",
    "    test_kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    perf = metric(y_true, y_pred)\n",
    "    f1_score_eval = round(f1_score(y_true, y_pred, average='binary'), ndigits =4)\n",
    "    \n",
    "    print(f'Test balanced accuracy: {test_bal_acc:0.3f}')\n",
    "    print(f'Test Cohen\\'s kappa: {test_kappa:0.3f}') \n",
    "\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "    tn, false_positives, fn, tp = conf_mat.ravel()\n",
    "    print('conf_mat', conf_mat)\n",
    "    \n",
    "    plot_confusion_matrix(conf_mat,str([patient_id[p_id]][0]),str(fold) )\n",
    "    \n",
    "    #Detection Delay\n",
    "    #Calculate detection delay\n",
    "    #Update predicted labels\n",
    "    #print('CHECK', num_bs_g, num_in_g) #1800,512\n",
    "    df_pred_reconstruct_all = pd.DataFrame(columns=['Predicted_Label'])\n",
    "    for i in range(0, num_bs_g):\n",
    "        pred_re = {'Predicted_Label': np.full((num_in_g, ),(y_pred)[i] )}\n",
    "        pred_re_reconstruct = pd.DataFrame(pred_re)\n",
    "        df_pred_reconstruct_all = df_pred_reconstruct_all.append(pred_re_reconstruct) \n",
    "    df_reconstruct_all.update(df_pred_reconstruct_all)\n",
    "\n",
    "    dd, s_d = calculate_detection_delay_for_eval(df_reconstruct_all)\n",
    "    if s_d !=0:\n",
    "        detection_delay = dd\n",
    "    \n",
    "    #Plot all batches\n",
    "    figure, axs = plt.subplots(nrows=4, ncols=1,figsize=(10,5), constrained_layout=True)\n",
    "    axs[0].plot( df_reconstruct_all.Time_Label, df_reconstruct_all.Channel1)\n",
    "    axs[0].set_title('Channel1')\n",
    "            \n",
    "    axs[1].plot( df_reconstruct_all.Time_Label, df_reconstruct_all.Channel2)\n",
    "    axs[1].set_title('Channel2')\n",
    "    \n",
    "    axs[2].plot( df_reconstruct_all.Time_Label, df_reconstruct_all.True_Label)\n",
    "    axs[2].set_title('True Label')\n",
    "    \n",
    "    axs[3].plot( df_reconstruct_all.Time_Label, df_reconstruct_all.Predicted_Label )\n",
    "    axs[3].set_title('Predicted Label')\n",
    "    plt.show()\n",
    "    plt.savefig('./results_1D_softmax/best_f1/detection_delay' + str([patient_id[p_id]][0]) + '_' + str(fold) + '.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print('Best f1 score',best_f1,'Calculated f1 score',f1_score_eval)\n",
    "            \n",
    "    print(f'f1_score_eval: {f1_score_eval:0.3f} \\t  average_precision: {average_precision:0.3f} \\t'\n",
    "         f'auc_precision_recall: {auc_precision_recall:0.3f} \\t  detection_delay: {detection_delay:0.3f}  \\t'\n",
    "         f'false_positive: {false_positives:0.3f} \\t false_negativ: {fn:0.3f}' )\n",
    "    \n",
    "    return np.mean(val_loss), test_bal_acc, average_precision , f1_score_eval, detection_delay,conf_mat, auc_precision_recall,roc_auc\n",
    "\n",
    "\n",
    "def train(model, loader_train, loader_test, optimizer, criterion, n_epochs, fold,\n",
    "          patience, device, metric=None):\n",
    "    \"\"\"Training function.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : instance of nn.Module\n",
    "        The model.\n",
    "    loader_train : instance of Sampler\n",
    "        The generator of EEG samples the model has to train on.\n",
    "        It contains n_train samples\n",
    "    loader_test : instance of Sampler\n",
    "        The generator of EEG samples the model has to validate on.\n",
    "        It contains n_val samples. The validation samples are used to\n",
    "        monitor the training process and to perform early stopping\n",
    "    optimizer : instance of optimizer\n",
    "        The optimizer to use for training.\n",
    "    n_epochs : int\n",
    "        The maximum of epochs to run.\n",
    "    patience : int\n",
    "        The patience parameter, i.e. how long to wait for the\n",
    "        validation error to go down.\n",
    "    metric : None | callable\n",
    "        Metric to use to evaluate performance on the training and\n",
    "        validation sets. Defaults to balanced accuracy.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    best_model : instance of nn.Module\n",
    "        The model that led to the best prediction on the validation\n",
    "        dataset.\n",
    "    history : list of dicts\n",
    "        Training history (loss, accuracy, etc.)\n",
    "    \"\"\"\n",
    "    best_valid_loss = np.inf\n",
    "    best_model = copy.deepcopy(model)\n",
    "    waiting = 0\n",
    "    history = list()\n",
    "    history_dict = {'epoch': [], 'train_loss': [], 'valid_loss': [],'train_perf':[],'valid_perf':[],'valid_ap':[],\n",
    "                    'valid_f1':[], 'false_positive':[],'detection_delay':[]}\n",
    "    \n",
    "    if metric is None:\n",
    "        metric = balanced_accuracy_score\n",
    "        \n",
    "    print('epoch \\t train_loss \\t valid_loss \\t train_perf \\t valid_perf \\t valid_ap \\t valid_f1')\n",
    "    print('-------------------------------------------------------------------')\n",
    "    print('Check number of epochs to run for LOOCV folds after selecting best hyperparam', n_epochs)\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_loss, train_perf = _do_train(\n",
    "            model, loader_train, optimizer, criterion, device, metric=metric)\n",
    "        \n",
    "        valid_loss, valid_perf, valid_ap, valid_f1 = _validate(\n",
    "            model, loader_test, criterion, device, metric=metric)\n",
    "        \n",
    "        #Save checkpoint\n",
    "        checkpoint = {\n",
    "            'epoch': epoch +1,\n",
    "            'state_dict' : model.state_dict(),\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }\n",
    "        #torch.save(checkpoint, './saved_model/QAT_ ' + '1' + '.pth')\n",
    "        #torch.save(model.state_dict(), './saved_model/QAT_ ' + '1' + '.pth')\n",
    "        #torch.save(best_model.state_dict(), './saved_model/conv1D/best-model-' + str([patient_id[p_id]][0]) +'_' +str(fold) +'.pth')\n",
    "           \n",
    "        history.append(\n",
    "            {'epoch': epoch, \n",
    "             'train_loss': train_loss, 'valid_loss': valid_loss,\n",
    "             'train_perf': train_perf, 'valid_perf': valid_perf, 'valid_ap': valid_ap,'valid_f1': valid_f1})\n",
    "        \n",
    "        print(f'{epoch} \\t {train_loss:0.4f} \\t {valid_loss:0.4f} '\n",
    "              f'\\t {train_perf:0.4f} \\t {valid_perf:0.4f}\\t {valid_ap:0.4f}\\t {valid_f1:0.4f}')\n",
    "                                                \n",
    "        history_dict['epoch'].append(epoch)\n",
    "        history_dict['train_loss'].append(train_loss)\n",
    "        history_dict['valid_loss'].append(valid_loss)\n",
    "        history_dict['train_perf'].append(train_perf)\n",
    "        history_dict['valid_perf'].append(valid_perf)\n",
    "        history_dict['valid_ap'].append(valid_ap)\n",
    "        history_dict['valid_f1'].append(valid_f1)\n",
    "        \n",
    "        torch.save(model.state_dict(), './results_1D_softmax/best_f1/best-model-' + str([patient_id[p_id]][0]) +'_' +str(fold) +'.pth')\n",
    "        '''\n",
    "        # model saving\n",
    "        if valid_loss < best_valid_loss:\n",
    "            print(f'best val loss {best_valid_loss:.4f} -> {valid_loss:.4f}')\n",
    "            best_valid_loss = valid_loss\n",
    "            print('Saving the best model')\n",
    "            best_model = copy.deepcopy(model)\n",
    "            waiting = 0\n",
    "        else:\n",
    "            waiting += 1\n",
    "\n",
    "        # model early stopping\n",
    "        if waiting >= patience or epoch==n_epochs:\n",
    "            print(f'Stop training at epoch {epoch}')\n",
    "            torch.save(best_model.state_dict(), './results_1D_softmax/best_f1/best-model-' + str([patient_id[p_id]][0]) +'_' +str(fold) +'.pth')\n",
    "            print(f'Best val loss : {best_valid_loss:.4f}')\n",
    "            break#'''\n",
    "        \n",
    "    '''   \n",
    "    valid_loss, valid_perf, valid_ap, valid_f1, fp, dd, fn = _validate_1epoch(\n",
    "            model, loader_test_1epoch, criterion, device, metric=metric)\n",
    "    \n",
    "    print('FINAL EVAL')\n",
    "    eval_metric = {\n",
    "        'valid_loss' : valid_loss, 'valid_perf' : valid_perf,'valid_ap' : valid_ap,\n",
    "        'valid_f1' : valid_f1, 'false_positive' : fp, 'detection_delay' : dd, 'false_negative' : fn\n",
    "    }'''\n",
    "    \n",
    "    return history_dict#, eval_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New loss function: BCELoss sigmoid with 1 output neuron-  working use this\n",
    "from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score\n",
    "from sklearn.metrics import average_precision_score, f1_score,  auc\n",
    "from sklearn.metrics import precision_recall_curve, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from matplotlib import pyplot\n",
    "\n",
    "def _do_train(model, loader, optimizer, criterion, device, metric):\n",
    "    # training loop\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = np.zeros(len(loader))\n",
    "    y_pred_all, y_true_all = list(), list()\n",
    "    for idx_batch, (batch_x, batch_y, batch_t) in enumerate(loader):\n",
    "        \n",
    "        batch_x = batch_x.to(device=device, dtype=torch.float32)   #([180, 1, 2, 2560])\n",
    "        batch_x = torch.squeeze(batch_x,1)\n",
    "        batch_y = batch_y.to(device=device, dtype=torch.float32)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_x)\n",
    "        #output = torch.squeeze(output,1)(\n",
    "        #batch_y = batch_y.unsqueeze(1).float()\n",
    "        loss = criterion(torch.squeeze(output,1), batch_y)\n",
    "        #loss = criterion(output, batch_y)\n",
    "        #print('loss', loss, loss.shape)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        m = nn.Sigmoid()\n",
    "        out_sigmoid = m(torch.squeeze(output,1))\n",
    "        \n",
    "        y_pred_all.append((out_sigmoid.detach().cpu().numpy() > 0.5))\n",
    "        y_true_all.append(batch_y.cpu().numpy())\n",
    "\n",
    "        train_loss[idx_batch] = loss.item()\n",
    "        \n",
    "    y_pred = np.concatenate(y_pred_all)\n",
    "    y_true = np.concatenate(y_true_all)\n",
    "    perf = metric(y_true, y_pred)\n",
    "    acc = np.mean(y_true == y_pred)\n",
    "    return np.mean(train_loss), perf   \n",
    "\n",
    "\n",
    "def _validate(model, loader, criterion, device, metric):\n",
    "    # validation loop\n",
    "    model.eval()\n",
    "    \n",
    "    average_precision = 0\n",
    "    f1_score_eval = 0\n",
    "    val_loss = np.zeros(len(loader))\n",
    "    y_pred_all, y_true_all, y_score_all = list(), list(), list()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx_batch, (batch_x, batch_y, batch_t) in enumerate(loader):\n",
    "            batch_x = batch_x.to(device=device, dtype=torch.float32)\n",
    "            batch_x = torch.squeeze(batch_x,1)\n",
    "            batch_y = batch_y.to(device=device, dtype=torch.float32)\n",
    "            batch_t = batch_t.to(device=device, dtype=torch.float32)\n",
    "            output = model.forward(batch_x)\n",
    "            #output = torch.squeeze(output,1)\n",
    "            #print('predicted class', torch.argmax(output, axis=1).cpu().numpy())\n",
    "            #print('actual class', batch_y)\n",
    "            #print('output of NN eval',torch.squeeze(output,1).shape,  torch.squeeze(output,1))\n",
    "            loss = criterion(torch.squeeze(output), batch_y)\n",
    "            val_loss[idx_batch] = loss.item()\n",
    "            \n",
    "            m = nn.Sigmoid()\n",
    "            out_sigmoid = m(torch.squeeze(output,1))\n",
    "            #pred_probab = nn.Softmax(dim=1)(output)  # Move this TODO\n",
    "            #probs = pred_probab[:, 1]\n",
    "            #print('Eval, appended values', torch.argmax(output, axis=1).cpu().numpy())\n",
    "            #y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n",
    "            y_pred_all.append((out_sigmoid.cpu().numpy() > 0.5))\n",
    "            y_true_all.append(batch_y.cpu().numpy())\n",
    "            #print('TRUE',(output.cpu().numpy() > 0.5),'PRED',batch_y.cpu().numpy())\n",
    "            y_score_all.append(m(torch.squeeze(output)).detach().cpu().numpy())\n",
    "            #print('Debug Average Precsion','pred_probab',pred_probab,'probs',probs, 'y_score_all' ,y_score_all)\n",
    "            \n",
    "    y_pred = np.concatenate(y_pred_all)\n",
    "    y_true = np.concatenate(y_true_all)\n",
    "    y_score = np.concatenate(y_score_all)\n",
    "    \n",
    "    perf = metric(y_true, y_pred)\n",
    "    f1_score_eval = f1_score(y_true, y_pred, average='binary')\n",
    "    average_precision = average_precision_score(y_true, y_score)\n",
    "    \n",
    "    #print('VALID: No Mean',val_loss ,  np.mean(val_loss), perf, average_precision, f1_score_eval )  \n",
    "    # return loss, accuracy, AP, F1 score, delay\n",
    "    return np.mean(val_loss), perf, average_precision , f1_score_eval\n",
    "\n",
    "def _validate_1epoch(model, loader, criterion, fold , device, metric):\n",
    "    # validation loop\n",
    "    model.eval()\n",
    "    \n",
    "    average_precision = 0\n",
    "    f1_score_eval = 0\n",
    "    false_positives = 0\n",
    "    detection_delay = 0\n",
    "    val_loss = np.zeros(len(loader))\n",
    "    y_pred_all, y_true_all, y_score_all = list(), list(), list()\n",
    "    num_bs_g = 0\n",
    "    num_in_g = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx_batch, (batch_x, batch_y, batch_t) in enumerate(loader):\n",
    "            batch_x = batch_x.to(device=device, dtype=torch.float32)\n",
    "            batch_x = torch.squeeze(batch_x,1)\n",
    "            batch_y = batch_y.to(device=device, dtype=torch.float32)\n",
    "            batch_t = batch_t.to(device=device, dtype=torch.float32)\n",
    "            output = model.forward(batch_x)\n",
    "            #output = torch.squeeze(output,1)\n",
    "            #print('predicted class', torch.argmax(output, axis=1).cpu().numpy())\n",
    "            #print('actual class', batch_y)\n",
    "            loss = criterion(torch.squeeze(output), batch_y)\n",
    "            val_loss[idx_batch] = loss.item()\n",
    "            \n",
    "            m = nn.Sigmoid()\n",
    "            out_sigmoid = m(torch.squeeze(output,1))\n",
    "            #pred_probab = nn.Softmax(dim=1)(output)  # Move this TODO\n",
    "            #probs = pred_probab[:, 1]\n",
    "            #print('Probs', probs)\n",
    "            #y_pred_all.append((out_sigmoid.cpu().numpy() > 0.5))\n",
    "            y_true_all.append(batch_y.cpu().numpy())\n",
    "            y_score_all.append(m(torch.squeeze(output)).detach().cpu().numpy())\n",
    "            #print('Debug Average Precsion','pred_probab',pred_probab,'probs',probs, 'y_score_all' ,y_score_all)\n",
    "            \n",
    "            #''' # Create dataframe and plot true and predicted labels\n",
    "            num_bs =  len(batch_x)      #256\n",
    "            num_bs_g = num_bs\n",
    "            num_in = len(batch_x[0,0,:])   # 2560\n",
    "            num_in_g = num_in\n",
    "            #print('older t1', num_bs, num_in)\n",
    "            t1 = np.arange(0,num_in*num_bs,1)\n",
    "    \n",
    "            #create a dataframe to visualize randomized data,target and outputs\n",
    "            df_reconstruct_all = pd.DataFrame(columns=['Channel1', 'Channel2','Channel3','Channel4', 'True_Label', 'Predicted_Label'])\n",
    "            for i in range(0, len(batch_x)):\n",
    "                #print('New computation loop',np.full((num_in, ),(output[i].cpu().numpy() > 0.5) ), (output[i].cpu().numpy() > 0.5))\n",
    "                data_re = {'Channel1':  batch_x[i,0,:].cpu().numpy(),\n",
    "                    'Channel2': batch_x[i,1,:].cpu().numpy(),\n",
    "                    'Channel3': batch_x[i,2,:].cpu().numpy(),\n",
    "                    'Channel4': batch_x[i,3,:].cpu().numpy(),\n",
    "                    'True_Label' : np.full((num_in, ), batch_y[i].cpu().numpy()), # 2560 labels\n",
    "                    'Predicted_Label' : np.full((num_in, ),(out_sigmoid[i].cpu().numpy() > 0.5) ) ,\n",
    "                    'Time_Label': batch_t[i,:].cpu().numpy()\n",
    "                    }\n",
    "                df_reconstruct = pd.DataFrame(data_re)\n",
    "                df_reconstruct_all = df_reconstruct_all.append(df_reconstruct)\n",
    "    \n",
    "            #Calculate detection delay\n",
    "            '''\n",
    "            dd, s_d = calculate_detection_delay_for_eval(df_reconstruct_all)\n",
    "            if s_d !=0:\n",
    "                detection_delay = dd\n",
    "    \n",
    "            #Plot all batches\n",
    "            figure, axs = plt.subplots(nrows=4, ncols=1,figsize=(10,5), constrained_layout=True)\n",
    "            axs[0].plot( df_reconstruct_all.Time_Label, df_reconstruct_all.Channel1)\n",
    "            axs[0].set_title('Channel1')\n",
    "            \n",
    "            axs[1].plot( df_reconstruct_all.Time_Label, df_reconstruct_all.Channel2)\n",
    "            axs[1].set_title('Channel2')\n",
    "    \n",
    "            axs[2].plot( df_reconstruct_all.Time_Label, df_reconstruct_all.True_Label)\n",
    "            axs[2].set_title('True Label')\n",
    "    \n",
    "            axs[3].plot( df_reconstruct_all.Time_Label, df_reconstruct_all.Predicted_Label )\n",
    "            axs[3].set_title('Predicted Label')\n",
    "            plt.show()\n",
    "            plt.savefig('./saved_model/conv1D_1output/detection_delay' + str([patient_id[p_id]][0]) + '_' + str(fold) + '.png')\n",
    "            '''\n",
    "            \n",
    "    #y_pred = np.concatenate(y_pred_all)\n",
    "    y_true = np.concatenate(y_true_all)\n",
    "    y_score = np.concatenate(y_score_all)\n",
    "    print('Check dimensions', y_score.shape, y_true.shape)#, y_score.shape)\n",
    "    \n",
    "    # Get all threshold independent metrics - F1_Score, AU-PRC, AU-ROC\n",
    "    \n",
    "    #Plot precision recall characteristics\n",
    "    precision, recall, th = precision_recall_curve(y_true, y_score)\n",
    "    fscore = (2 * precision * recall) / (precision + recall)\n",
    "    ix = np.argmax(fscore)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(recall, precision, color='purple')\n",
    "    ax.scatter(recall[ix], precision[ix], marker='o', color='black', label='Best')\n",
    "    ax.set_title('Precision-Recall Curve')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.set_xlabel('Recall')\n",
    "    plt.show()\n",
    "    plt.savefig('./results_1D_softmax/best_f1/PRC' + str([patient_id[p_id]][0]) + '_' + str(fold) + '.png')\n",
    "    plt.close()\n",
    "    \n",
    "    average_precision =  round(average_precision_score(y_true, y_score), ndigits =4)\n",
    "    auc_precision_recall =  round(auc(recall, precision), ndigits =4)\n",
    "    best_f1 = round(fscore[ix], ndigits =4)\n",
    "    best_threshold = round(th[ix], ndigits =4)\n",
    "    print('Best Threshold=%f, F-Score=%.3f' % (th[ix], fscore[ix]))\n",
    "    print('Best Precision=%.3f, Best Recall=%.3f' % (precision[ix], recall[ix]))\n",
    "    \n",
    "    #Threshold vs f1 score plot\n",
    "    '''\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.plot(np.append(th,1), fscore, color='black')\n",
    "    ax1.scatter(th[ix], fscore[ix], marker='o', color='red', label='Best')\n",
    "    ax1.set_title('Thresholding Curve')\n",
    "    ax1.set_ylabel('F1-score')\n",
    "    ax1.set_xlabel('Threshold')\n",
    "    plt.show()'''\n",
    "    \n",
    "    print('Plotting ROC')\n",
    "    #ROC characteristics\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "    pyplot.plot(fpr, tpr, marker='.', label='ROC')\n",
    "    pyplot.xlabel('False Positive Rate')\n",
    "    pyplot.ylabel('True Positive Rate')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()\n",
    "    plt.savefig('./results_1D_softmax/best_f1/ROC' + str([patient_id[p_id]][0]) + '_' + str(fold) + '.png')\n",
    "    pyplot.close()\n",
    "    \n",
    "    roc_auc = round(roc_auc_score(y_true, y_score), ndigits =4)\n",
    "    print('AUPRC=%f, AUROC=%f' % (auc_precision_recall, roc_auc))\n",
    "    \n",
    "    #Threshold Dependent Characteristics\n",
    "    y_pred = (y_score >= best_threshold).astype(int)\n",
    "    print('Compare lengths', y_score.shape, y_pred.shape)\n",
    "    #df_dataset = pd.DataFrame({'prob': y_score, 'pred': y_pred}, columns=['prob', 'pred'])\n",
    "    #df_dataset.to_csv('./check.csv')\n",
    "    \n",
    "    test_bal_acc = round(balanced_accuracy_score(y_true, y_pred), ndigits =4)\n",
    "    test_kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    perf = metric(y_true, y_pred)\n",
    "    f1_score_eval = round(f1_score(y_true, y_pred, average='binary'), ndigits =4)\n",
    "    \n",
    "    print(f'Test balanced accuracy: {test_bal_acc:0.3f}')\n",
    "    print(f'Test Cohen\\'s kappa: {test_kappa:0.3f}') \n",
    "\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "    tn, false_positives, fn, tp = conf_mat.ravel()\n",
    "    print('conf_mat', conf_mat)\n",
    "    \n",
    "    plot_confusion_matrix(conf_mat,str([patient_id[p_id]][0]),str(fold) )\n",
    "    \n",
    "    #Detection Delay\n",
    "    #Calculate detection delay\n",
    "    #Update predicted labels\n",
    "    #print('CHECK', num_bs_g, num_in_g) #1800,512\n",
    "    df_pred_reconstruct_all = pd.DataFrame(columns=['Predicted_Label'])\n",
    "    for i in range(0, num_bs_g):\n",
    "        pred_re = {'Predicted_Label': np.full((num_in_g, ),(y_pred)[i] )}\n",
    "        pred_re_reconstruct = pd.DataFrame(pred_re)\n",
    "        df_pred_reconstruct_all = df_pred_reconstruct_all.append(pred_re_reconstruct) \n",
    "    df_reconstruct_all.update(df_pred_reconstruct_all)\n",
    "\n",
    "    dd, s_d = calculate_detection_delay_for_eval(df_reconstruct_all)\n",
    "    if s_d !=0:\n",
    "        detection_delay = dd\n",
    "    \n",
    "    #Plot all batches\n",
    "    figure, axs = plt.subplots(nrows=4, ncols=1,figsize=(10,5), constrained_layout=True)\n",
    "    axs[0].plot( df_reconstruct_all.Time_Label, df_reconstruct_all.Channel1)\n",
    "    axs[0].set_title('Channel1')\n",
    "            \n",
    "    axs[1].plot( df_reconstruct_all.Time_Label, df_reconstruct_all.Channel2)\n",
    "    axs[1].set_title('Channel2')\n",
    "    \n",
    "    axs[2].plot( df_reconstruct_all.Time_Label, df_reconstruct_all.True_Label)\n",
    "    axs[2].set_title('True Label')\n",
    "    \n",
    "    axs[3].plot( df_reconstruct_all.Time_Label, df_reconstruct_all.Predicted_Label )\n",
    "    axs[3].set_title('Predicted Label')\n",
    "    plt.show()\n",
    "    plt.savefig('./results_1D_softmax/best_f1/detection_delay' + str([patient_id[p_id]][0]) + '_' + str(fold) + '.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print('Best f1 score',best_f1,'Calculated f1 score',f1_score_eval)\n",
    "    \n",
    "    print(f'f1_score_eval: {f1_score_eval:0.3f} \\t  average_precision: {average_precision:0.3f} \\t'\n",
    "         f'auc_precision_recall: {auc_precision_recall:0.3f} \\t  detection_delay: {detection_delay:0.3f}  \\t'\n",
    "         f'false_positive: {false_positives:0.3f} \\t false_negativ: {fn:0.3f}' )\n",
    "    \n",
    "    return np.mean(val_loss), perf, average_precision , f1_score_eval, detection_delay, conf_mat,auc_precision_recall,roc_auc\n",
    "\n",
    "def train(model, loader_train, loader_test, optimizer, criterion, n_epochs, fold,\n",
    "          patience, device, metric=None):\n",
    "    \"\"\"Training function. \n",
    "    Returns\n",
    "    -------\n",
    "    best_model : instance of nn.Module\n",
    "        The model that led to the best prediction on the validation\n",
    "        dataset.\n",
    "    history : list of dicts\n",
    "        Training history (loss, accuracy, etc.)\n",
    "    \"\"\"\n",
    "    best_valid_loss = np.inf\n",
    "    best_model = copy.deepcopy(model)\n",
    "    waiting = 0\n",
    "    history = list()\n",
    "    history_dict = {'epoch': [], 'train_loss': [], 'valid_loss': [],'train_perf':[],'valid_perf':[],'valid_ap':[],\n",
    "                    'valid_f1':[], 'false_positive':[],'detection_delay':[]}\n",
    "    \n",
    "    if metric is None:\n",
    "        metric = balanced_accuracy_score\n",
    "        \n",
    "    print('epoch \\t train_loss \\t valid_loss \\t train_perf \\t valid_perf \\t valid_ap \\t valid_f1')\n",
    "    print('-------------------------------------------------------------------')\n",
    "    print('Check number of epochs to run for LOOCV folds after selecting best hyperparam', n_epochs)\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_loss, train_perf = _do_train(\n",
    "            model, loader_train, optimizer, criterion, device, metric=metric)\n",
    "        \n",
    "        valid_loss, valid_perf, valid_ap, valid_f1 = _validate(\n",
    "            model, loader_test, criterion, device, metric=metric)\n",
    "        \n",
    "        #Save checkpoint\n",
    "        checkpoint = {\n",
    "            'epoch': epoch +1,\n",
    "            'state_dict' : model.state_dict(),\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }\n",
    "\n",
    "        #torch.save(model.state_dict(), './saved_model/QAT_ ' + '1' + '.pth')\n",
    "        \n",
    "        history.append(\n",
    "            {'epoch': epoch, \n",
    "             'train_loss': train_loss, 'valid_loss': valid_loss,\n",
    "             'train_perf': train_perf, 'valid_perf': valid_perf, 'valid_ap': valid_ap,'valid_f1': valid_f1})\n",
    "        \n",
    "        print(f'{epoch} \\t {train_loss:0.4f} \\t {valid_loss:0.4f} '\n",
    "              f'\\t {train_perf:0.4f} \\t {valid_perf:0.4f}\\t {valid_ap:0.4f}\\t {valid_f1:0.4f}')\n",
    "                                                \n",
    "        history_dict['epoch'].append(epoch)\n",
    "        history_dict['train_loss'].append(train_loss)\n",
    "        history_dict['valid_loss'].append(valid_loss)\n",
    "        history_dict['train_perf'].append(train_perf)\n",
    "        history_dict['valid_perf'].append(valid_perf)\n",
    "        history_dict['valid_ap'].append(valid_ap)\n",
    "        history_dict['valid_f1'].append(valid_f1)\n",
    "        \n",
    "        #'''\n",
    "        #model saving\n",
    "        if valid_loss < best_valid_loss:\n",
    "            print(f'best val loss {best_valid_loss:.4f} -> {valid_loss:.4f}')\n",
    "            best_valid_loss = valid_loss\n",
    "            print('Saving the best model')\n",
    "            best_model = copy.deepcopy(model)\n",
    "            waiting = 0\n",
    "        else:\n",
    "            waiting += 1\n",
    "\n",
    "        # model early stopping\n",
    "        if waiting >= patience or epoch==n_epochs:\n",
    "            print(f'Stop training at epoch {epoch}')\n",
    "            torch.save(best_model.state_dict(), './results_1D_softmax/best_f1/best-model-' + str([patient_id[p_id]][0]) +'_' +str(fold) +'.pth')\n",
    "            print(f'Best val loss : {best_valid_loss:.4f}')\n",
    "            break #'''\n",
    "        \n",
    "    '''    \n",
    "    valid_loss, valid_perf, valid_ap, valid_f1, fp, dd, fn = _validate_1epoch(\n",
    "            model, loader_test_1epoch, criterion, device, metric=metric)\n",
    "    \n",
    "    print('FINAL EVAL')\n",
    "    eval_metric = {\n",
    "        'valid_loss' : valid_loss, 'valid_perf' : valid_perf,'valid_ap' : valid_ap,\n",
    "        'valid_f1' : valid_f1, 'false_positive' : fp, 'detection_delay' : dd, 'false_negative' : fn\n",
    "    }'''\n",
    "    \n",
    "    return history_dict#, eval_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv2D\n",
    "from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score\n",
    "from sklearn.metrics import average_precision_score, f1_score,  auc\n",
    "from sklearn.metrics import precision_recall_curve, confusion_matrix\n",
    "\n",
    "def analog_to_spike(batch_x, batch_y):\n",
    "    #print('shape for analog to spike',np.shape(batch_x), np.shape(batch_x)[0])\n",
    "    b_s = np.shape(batch_x)[0]\n",
    "    c_s = np.shape(batch_x)[2]\n",
    "    t_s = np.shape(batch_x)[3]\n",
    "\n",
    "    batch_x = spikegen.delta(batch_x, threshold=0.5, off_spike=False)\n",
    "    #print('shape for loop',np.shape(batch_x), len(batch_x),b_s,c_s,t_s, 'shape of y',np.shape(batch_y))\n",
    "    #print('Check the value to be plotted', batch_x[0,0,0,:], len(batch_x[0,0,0,:])\n",
    "    '''\n",
    "    for b in range(0,5):\n",
    "        for c in range(0,c_s):    \n",
    "            # Create fig, ax\n",
    "            fig = plt.figure(facecolor=\"w\", figsize=(8, 4))\n",
    "            ax = fig.add_subplot(111)\n",
    "\n",
    "            # Raster plot of delta converted data\n",
    "            splt.raster(batch_x[b,0,c,:], ax)\n",
    "\n",
    "            plt.title(\"Input Neuron\"+ \"for batchsample_\"+ str(b) +\"_for channel_\"+ str(c) + \"_with_label:\" +str(batch_y[b]))\n",
    "            plt.xlabel(\"Time step\")\n",
    "            plt.yticks([])\n",
    "            plt.xlim(0,t_s )\n",
    "            fig.canvas.draw()\n",
    "    '''\n",
    "    return batch_x\n",
    "            \n",
    "\n",
    "def _do_train(model, loader, optimizer, criterion, device, metric):\n",
    "    # training loop\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = np.zeros(len(loader))\n",
    "    y_pred_all, y_true_all = list(), list()\n",
    "    for idx_batch, (batch_x, batch_y, batch_t) in enumerate(loader):\n",
    "        \n",
    "        batch_x = batch_x.to(device=device, dtype=torch.float32)   #([180, 1, 2, 2560])\n",
    "        batch_y = batch_y.to(device=device, dtype=torch.int64)\n",
    "        #print('Dataset dimensions',batch_x.shape, batch_y.shape)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_x)\n",
    "        #output = torch.squeeze(output,1)(\n",
    "        #batch_y = batch_y.unsqueeze(1).float()\n",
    "        #print('predicted class', torch.argmax(output, axis=1).cpu().numpy())\n",
    "        loss = criterion(output, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n",
    "        y_true_all.append(batch_y.cpu().numpy())\n",
    "\n",
    "        train_loss[idx_batch] = loss.item()\n",
    "        \n",
    "    y_pred = np.concatenate(y_pred_all)\n",
    "    y_true = np.concatenate(y_true_all)\n",
    "    perf = metric(y_true, y_pred)\n",
    "    acc = np.mean(y_true == y_pred)\n",
    "    #print('TRAIN: y_pred',y_pred,'y_true',y_true )\n",
    "    return np.mean(train_loss), perf   \n",
    "        \n",
    "'''\n",
    "def _validate(model, loader, criterion, device, metric):\n",
    "    # validation loop\n",
    "    model.eval()\n",
    "    \n",
    "    val_loss = np.zeros(len(loader))\n",
    "    y_pred_all, y_true_all = list(), list()\n",
    "    with torch.no_grad():\n",
    "        for idx_batch, (batch_x, batch_y, batch_t) in enumerate(loader):\n",
    "            batch_x = batch_x.to(device=device, dtype=torch.float32)\n",
    "            batch_y = batch_y.to(device=device, dtype=torch.int64)\n",
    "            output = model.forward(batch_x)\n",
    "            #output = torch.squeeze(output,1)\n",
    "            #print('predicted class', torch.argmax(output, axis=1).cpu().numpy())\n",
    "            #print('actual class', batch_y)\n",
    "            loss = criterion(output, batch_y)\n",
    "            val_loss[idx_batch] = loss.item()\n",
    "            \n",
    "            y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n",
    "            y_true_all.append(batch_y.cpu().numpy())\n",
    "            \n",
    "    y_pred = np.concatenate(y_pred_all)\n",
    "    y_true = np.concatenate(y_true_all)\n",
    "    perf = metric(y_true, y_pred)\n",
    "    #print('VALID: y_pred',y_pred,'y_true',y_true)    \n",
    "    return np.mean(val_loss), perf'''\n",
    "\n",
    "def _validate(model, loader, criterion, device, metric):\n",
    "    # validation loop\n",
    "    model.eval()\n",
    "    \n",
    "    average_precision = 0\n",
    "    f1_score_eval = 0\n",
    "    val_loss = np.zeros(len(loader))\n",
    "    y_pred_all, y_true_all, y_score_all = list(), list(), list()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx_batch, (batch_x, batch_y, batch_t) in enumerate(loader):\n",
    "            batch_x = batch_x.to(device=device, dtype=torch.float32)\n",
    "            batch_y = batch_y.to(device=device, dtype=torch.int64)\n",
    "            batch_t = batch_t.to(device=device, dtype=torch.float32)\n",
    "            output = model.forward(batch_x)\n",
    "            #output = torch.squeeze(output,1)\n",
    "            #print('predicted class', torch.argmax(output, axis=1).cpu().numpy())\n",
    "            #print('actual class', batch_y)\n",
    "            loss = criterion(output, batch_y)\n",
    "            val_loss[idx_batch] = loss.item()\n",
    "            \n",
    "            pred_probab = nn.Softmax(dim=1)(output)  # Move this TODO\n",
    "            probs = pred_probab[:, 1]\n",
    "            \n",
    "            y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n",
    "            y_true_all.append(batch_y.cpu().numpy())\n",
    "            y_score_all.append(probs.detach().cpu().numpy())\n",
    "            #print('Debug Average Precsion','pred_probab',pred_probab,'probs',probs, 'y_score_all' ,y_score_all)\n",
    "            \n",
    "    y_pred = np.concatenate(y_pred_all)\n",
    "    y_true = np.concatenate(y_true_all)\n",
    "    y_score = np.concatenate(y_score_all)\n",
    "    \n",
    "    perf = metric(y_true, y_pred)\n",
    "    f1_score_eval = f1_score(y_true, y_pred, average='binary')\n",
    "    average_precision = average_precision_score(y_true, y_score)\n",
    "    #print('VALIDATE: y_true', y_true, 'y_score', y_score)\n",
    "    \n",
    "    #print('VALID: No Mean',val_loss ,  np.mean(val_loss), perf, average_precision, f1_score_eval )  \n",
    "    # return loss, accuracy, AP, F1 score, delay\n",
    "    return np.mean(val_loss), perf, average_precision , f1_score_eval\n",
    "\n",
    "def _validate_1epoch(model, loader, criterion, fold ,device, metric):\n",
    "    # validation loop\n",
    "    model.eval()\n",
    "    \n",
    "    average_precision = 0\n",
    "    f1_score_eval = 0\n",
    "    false_positives = 0\n",
    "    detection_delay = 0\n",
    "    val_loss = np.zeros(len(loader))\n",
    "    y_pred_all, y_true_all, y_score_all = list(), list(), list()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx_batch, (batch_x, batch_y, batch_t) in enumerate(loader):\n",
    "            batch_x = batch_x.to(device=device, dtype=torch.float32)\n",
    "            batch_y = batch_y.to(device=device, dtype=torch.int64)\n",
    "            batch_t = batch_t.to(device=device, dtype=torch.float32)\n",
    "            output = model.forward(batch_x)\n",
    "            #output = torch.squeeze(output,1)\n",
    "            #print('predicted class', torch.argmax(output, axis=1).cpu().numpy())\n",
    "            #print('actual class', batch_y)\n",
    "            loss = criterion(output, batch_y)\n",
    "            val_loss[idx_batch] = loss.item()\n",
    "            \n",
    "            pred_probab = nn.Softmax(dim=1)(output)  # Move this TODO\n",
    "            probs = pred_probab[:, 1]\n",
    "            print('Probs', probs)\n",
    "            y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n",
    "            y_true_all.append(batch_y.cpu().numpy())\n",
    "            y_score_all.append(probs.detach().cpu().numpy())\n",
    "            #print('Debug Average Precsion','pred_probab',pred_probab,'probs',probs, 'y_score_all' ,y_score_all)\n",
    "            \n",
    "            #''' # Create dataframe and plot true and predicted labels\n",
    "            num_bs =  len(batch_x)      #256\n",
    "            num_in = len(batch_x[0,0,0,:])   # 2560\n",
    "            #print('older t1', num_bs, num_in)\n",
    "            t1 = np.arange(0,num_in*num_bs,1)\n",
    "    \n",
    "            #create a dataframe to visualize randomized data,target and outputs\n",
    "            df_reconstruct_all = pd.DataFrame(columns=['Channel1', 'Channel2','Channel3','Channel4', 'True_Label', 'Predicted_Label'])\n",
    "            for i in range(0, len(batch_x)):\n",
    "                data_re = {'Channel1':  batch_x[i,0,0,:].cpu().numpy(),\n",
    "                    'Channel2': batch_x[i,0,1,:].cpu().numpy(),\n",
    "                    'Channel3': batch_x[i,0,2,:].cpu().numpy(),\n",
    "                    'Channel4': batch_x[i,0,3,:].cpu().numpy(),\n",
    "                    'True_Label' : np.full((num_in, ), batch_y[i].cpu().numpy()), # 2560 labels\n",
    "                    'Predicted_Label' : np.full((num_in, ),torch.argmax(output, axis=1)[i].cpu().numpy() ) ,\n",
    "                    'Time_Label': batch_t[i,:].cpu().numpy()\n",
    "                    }\n",
    "                df_reconstruct = pd.DataFrame(data_re)\n",
    "                df_reconstruct_all = df_reconstruct_all.append(df_reconstruct)\n",
    "    \n",
    "            #Calculate detection delay\n",
    "            dd, s_d = calculate_detection_delay_for_eval(df_reconstruct_all)\n",
    "            if s_d !=0:\n",
    "                detection_delay = dd\n",
    "    \n",
    "            #Plot all batches\n",
    "            #''' \n",
    "            figure, axs = plt.subplots(nrows=4, ncols=1,figsize=(10,5), constrained_layout=True)\n",
    "            axs[0].plot( df_reconstruct_all.Time_Label, df_reconstruct_all.Channel1)\n",
    "            axs[0].set_title('Channel1')\n",
    "            \n",
    "            axs[1].plot( df_reconstruct_all.Time_Label, df_reconstruct_all.Channel2)\n",
    "            axs[1].set_title('Channel2')\n",
    "    \n",
    "            axs[2].plot( df_reconstruct_all.Time_Label, df_reconstruct_all.True_Label)\n",
    "            axs[2].set_title('True Label')\n",
    "    \n",
    "            axs[3].plot( df_reconstruct_all.Time_Label, df_reconstruct_all.Predicted_Label )\n",
    "            axs[3].set_title('Predicted Label')\n",
    "            plt.show()#'''\n",
    "            plt.savefig('./save_plot/detection_delay' + str([patient_id[p_id]][0]) + '_' + str(fold) + '.png')\n",
    "            #print(df_reconstruct_all)  # Print the dataframe for each batch\n",
    "            \n",
    "    y_pred = np.concatenate(y_pred_all)\n",
    "    y_true = np.concatenate(y_true_all)\n",
    "    y_score = np.concatenate(y_score_all)\n",
    "    print('Check dimensions', y_pred.shape, y_true.shape, y_score.shape)\n",
    "    \n",
    "    test_bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    test_kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    print(f'Test balanced accuracy: {test_bal_acc:0.3f}')\n",
    "    print(f'Test Cohen\\'s kappa: {test_kappa:0.3f}')\n",
    "    \n",
    "    perf = metric(y_true, y_pred)\n",
    "    f1_score_eval = f1_score(y_true, y_pred, average='binary')\n",
    "    average_precision = average_precision_score(y_true, y_score)\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_score)\n",
    "    auc_precision_recall = auc(recall, precision)\n",
    "    \n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "    tn, false_positives, fn, tp = conf_mat.ravel()\n",
    "    print('conf_mat', conf_mat)\n",
    "    \n",
    "    plot_confusion_matrix(conf_mat)\n",
    "    \n",
    "    print(f'f1_score_eval: {f1_score_eval:0.3f} \\t  average_precision: {average_precision:0.3f} \\t'\n",
    "         f'auc_precision_recall: {auc_precision_recall:0.3f} \\t  detection_delay: {detection_delay:0.3f}  \\t'\n",
    "         f'false_positive: {false_positives:0.3f} \\t false_negativ: {fn:0.3f}' )\n",
    "    \n",
    "    #print('VALID:', np.mean(val_loss), perf, average_precision, f1_score_eval )  \n",
    "    \n",
    "    # return loss, accuracy, AP, F1 score,false_+s, delay\n",
    "    return np.mean(val_loss), perf, average_precision , f1_score_eval, detection_delay,conf_mat\n",
    "\n",
    "def train(model, loader_train, loader_test, optimizer, criterion, n_epochs, fold,\n",
    "          patience, device, metric=None):\n",
    "    \"\"\"Training function.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : instance of nn.Module\n",
    "        The model.\n",
    "    loader_train : instance of Sampler\n",
    "        The generator of EEG samples the model has to train on.\n",
    "        It contains n_train samples\n",
    "    loader_test : instance of Sampler\n",
    "        The generator of EEG samples the model has to validate on.\n",
    "        It contains n_val samples. The validation samples are used to\n",
    "        monitor the training process and to perform early stopping\n",
    "    optimizer : instance of optimizer\n",
    "        The optimizer to use for training.\n",
    "    n_epochs : int\n",
    "        The maximum of epochs to run.\n",
    "    patience : int\n",
    "        The patience parameter, i.e. how long to wait for the\n",
    "        validation error to go down.\n",
    "    metric : None | callable\n",
    "        Metric to use to evaluate performance on the training and\n",
    "        validation sets. Defaults to balanced accuracy.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    best_model : instance of nn.Module\n",
    "        The model that led to the best prediction on the validation\n",
    "        dataset.\n",
    "    history : list of dicts\n",
    "        Training history (loss, accuracy, etc.)\n",
    "    \"\"\"\n",
    "    best_valid_loss = np.inf\n",
    "    best_model = copy.deepcopy(model)\n",
    "    waiting = 0\n",
    "    history = list()\n",
    "    history_dict = {'epoch': [], 'train_loss': [], 'valid_loss': [],'train_perf':[],'valid_perf':[],'valid_ap':[],\n",
    "                    'valid_f1':[], 'false_positive':[],'detection_delay':[]}\n",
    "    \n",
    "    if metric is None:\n",
    "        metric = balanced_accuracy_score\n",
    "        \n",
    "    print('epoch \\t train_loss \\t valid_loss \\t train_perf \\t valid_perf \\t valid_ap \\t valid_f1')\n",
    "    print('-------------------------------------------------------------------')\n",
    "    print('Check number of epochs to run for LOOCV folds after selecting best hyperparam', n_epochs)\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_loss, train_perf = _do_train(\n",
    "            model, loader_train, optimizer, criterion, device, metric=metric)\n",
    "        \n",
    "        valid_loss, valid_perf, valid_ap, valid_f1 = _validate(\n",
    "            model, loader_test, criterion, device, metric=metric)\n",
    "        \n",
    "        #Save checkpoint\n",
    "        checkpoint = {\n",
    "            'epoch': epoch +1,\n",
    "            'state_dict' : model.state_dict(),\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }\n",
    "        #torch.save(checkpoint, './saved_model/QAT_ ' + '1' + '.pth')\n",
    "        \n",
    "        history.append(\n",
    "            {'epoch': epoch, \n",
    "             'train_loss': train_loss, 'valid_loss': valid_loss,\n",
    "             'train_perf': train_perf, 'valid_perf': valid_perf, 'valid_ap': valid_ap,'valid_f1': valid_f1})\n",
    "        \n",
    "        print(f'{epoch} \\t {train_loss:0.4f} \\t {valid_loss:0.4f} '\n",
    "              f'\\t {train_perf:0.4f} \\t {valid_perf:0.4f}\\t {valid_ap:0.4f}\\t {valid_f1:0.4f}')\n",
    "                                                \n",
    "        history_dict['epoch'].append(epoch)\n",
    "        history_dict['train_loss'].append(train_loss)\n",
    "        history_dict['valid_loss'].append(valid_loss)\n",
    "        history_dict['train_perf'].append(train_perf)\n",
    "        history_dict['valid_perf'].append(valid_perf)\n",
    "        history_dict['valid_ap'].append(valid_ap)\n",
    "        history_dict['valid_f1'].append(valid_f1)\n",
    "        #'''\n",
    "        #model saving conv2D\n",
    "        if valid_loss < best_valid_loss:\n",
    "            print(f'best val loss {best_valid_loss:.4f} -> {valid_loss:.4f}')\n",
    "            best_valid_loss = valid_loss\n",
    "            print('Saving the best model')\n",
    "            best_model = copy.deepcopy(model)\n",
    "            waiting = 0\n",
    "        else:\n",
    "            waiting += 1\n",
    "\n",
    "        # model early stopping\n",
    "        if waiting >= patience or epoch==n_epochs:\n",
    "            print(f'Stop training at epoch {epoch}')\n",
    "            torch.save(best_model.state_dict(), './saved_model/conv2D/best-model-' + str([patient_id[p_id]][0]) +'_' +str(fold) +'.pth')\n",
    "            print(f'Best val loss : {best_valid_loss:.4f}')\n",
    "            break\n",
    "        \n",
    "    '''\n",
    "    valid_loss, valid_perf, valid_ap, valid_f1, fp, dd, fn = _validate_1epoch(\n",
    "            model, loader_test_1epoch, criterion, device, metric=metric)\n",
    "    \n",
    "    print('FINAL EVAL')\n",
    "    eval_metric = {\n",
    "        'valid_loss' : valid_loss, 'valid_perf' : valid_perf,'valid_ap' : valid_ap,\n",
    "        'valid_f1' : valid_f1, 'false_positive' : fp, 'detection_delay' : dd, 'false_negative' : fn\n",
    "    }'''\n",
    "    \n",
    "    return history_dict#, eval_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN AND MONITOR NETWORK\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "sfreq = 256.0  # Sampling frequency\n",
    "n_channels = 4\n",
    "print(sfreq, n_channels)\n",
    "# Create dataloaders\n",
    "train_batch_size = 180 #180  #45\n",
    "valid_batch_size = 180 #180  #45\n",
    "num_workers = 0\n",
    "torch.manual_seed(87)\n",
    "np.random.seed(87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.nn import CrossEntropyLoss, BCELoss, BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "n_epochs = 200 #200\n",
    "patience = 50   #40    #25\n",
    "\n",
    "loss_list = []\n",
    "perf_list = []\n",
    "ap_list = []\n",
    "f1_list = []\n",
    "fp_list = []\n",
    "dd_list = []\n",
    "fn_list = []\n",
    "tp_list = []\n",
    "tn_list = []\n",
    "auprc_list = []\n",
    "auroc_list = []\n",
    "\n",
    "for fold, (train_idx,valid_idx) in enumerate(LeaveOneOut().split(np.arange(len(dataset.datasets)))):\n",
    "    print('LeaveOneOut Cross Validation {}'.format(fold + 1))\n",
    "    print('Check values for train and test', train_idx, valid_idx)\n",
    "    \n",
    "    train_ds = ConcatDataset([dataset.datasets[i] for i in train_idx])\n",
    "    test_ds = ConcatDataset([dataset.datasets[i] for i in valid_idx])\n",
    "    print(f'Training: {len(train_ds)}  Validation: {len(test_ds)}')\n",
    "    \n",
    "    loader_train = DataLoader(\n",
    "        train_ds, batch_size=train_batch_size, shuffle=True, num_workers=num_workers)\n",
    "    loader_test = DataLoader(\n",
    "        test_ds, batch_size=valid_batch_size, shuffle=False, num_workers=num_workers)\n",
    "    loader_test_1epoch = DataLoader(\n",
    "        test_ds, batch_size=test_ds.__len__(), shuffle=False, num_workers=num_workers)\n",
    "    \n",
    "    classes_mapping = {0: 'non-ictal', 1: 'ictal'}\n",
    "    train_y = pd.Series([y for _, y,_ in train_ds]).map(classes_mapping)\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(train_y), y=train_y)\n",
    "    \n",
    "    model = IEEGSeizureDetection_2sec(n_channels, sfreq, n_classes=2)\n",
    "    print(f'Using device \\'{device}\\'.')\n",
    "    model = model.to(device)\n",
    "    model.apply(reset_weights)\n",
    "    \n",
    "    optimizer = Adam(model.parameters(), lr=3e-3, weight_decay=0)   #use 3,3 for 2D CNN, 1,4 for 1D CNN0.01795\n",
    "    #optimizer = Adam(model.parameters(), lr=0.01795, weight_decay=0)\n",
    "    optimizer = Adam(model.parameters(), lr=0.0215, weight_decay=0)\n",
    "    #criterion = CrossEntropyLoss(weight=torch.Tensor(class_weights).to(device)) \n",
    "    criterion = CrossEntropyLoss() \n",
    "    #criterion = BCEWithLogitsLoss()\n",
    "    \n",
    "    history = train(\n",
    "    model, loader_train, loader_test , optimizer, criterion, n_epochs, fold,patience, \n",
    "    device, metric=balanced_accuracy_score)\n",
    "    \n",
    "    #Plot learning curve\n",
    "    plot_learning_curve(history,str([patient_id[p_id]][0]),str(fold))\n",
    "    \n",
    "    #Load the best model saved in train()\n",
    "    model_validate_1epoch = IEEGSeizureDetection_2sec(n_channels, sfreq, n_classes=2).to(device)\n",
    "    model_validate_1epoch.load_state_dict(torch.load('./results_1D_softmax/best_f1/best-model-' + str([patient_id[p_id]][0]) +'_' +str(fold) +'.pth', map_location=device))\n",
    "    \n",
    "    valid_loss, valid_perf, valid_ap, valid_f1, dd, valid_cm, auprc,auroc = _validate_1epoch(\n",
    "            model_validate_1epoch, loader_test_1epoch, criterion, fold,device, metric=balanced_accuracy_score)\n",
    "    \n",
    "    loss_list.append(valid_loss)\n",
    "    perf_list.append(valid_perf)\n",
    "    ap_list.append(valid_ap)\n",
    "    f1_list.append(valid_f1)           \n",
    "    dd_list.append(dd)\n",
    "    tn_list.append(valid_cm[0][0])\n",
    "    fp_list.append(valid_cm[0][1])\n",
    "    fn_list.append(valid_cm[1][0])\n",
    "    tp_list.append(valid_cm[1][1])\n",
    "    auprc_list.append(auprc)\n",
    "    auroc_list.append(auroc)\n",
    "    #break\n",
    "print('Lists:',loss_list, perf_list, ap_list, f1_list, dd_list,tn_list,fp_list,fn_list,tp_list,auprc_list,auroc_list)\n",
    "\n",
    "#Add other stuff AUPRC, AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(3.45678, ndigits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write final values to csv\n",
    "from itertools import zip_longest\n",
    "all_metric = [loss_list, perf_list, ap_list, f1_list, dd_list,tn_list,fp_list,fn_list,tp_list,auprc_list,auroc_list]\n",
    "export_data = zip_longest(*all_metric, fillvalue = '')\n",
    "#with open('./save_plot_1D/eval-results-HPO' + str([patient_id[p_id]][0]) +'.csv', 'w', newline='') as myfile:\n",
    "with open('./results_1D_softmax/best_f1/eval-results-re-rand-' + str([patient_id[p_id]][0]) +'.csv', 'w', newline='') as myfile:\n",
    "    wr = csv.writer(myfile)\n",
    "    wr.writerow((\"Loss\", \"Accuracy\",\"AP\", \"F1\",\"Detection Delay\", \"TN\",\"FP\", \"FN\",\"TP\",\"AUPRC\",\"AUROC\"))\n",
    "    wr.writerows(export_data)\n",
    "myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 changes for QAT + CPU used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computing class weight\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "classes_mapping = {0: 'non-ictal', 1: 'ictal'}\n",
    "train_y = pd.Series([y for _, y,_ in train_ds]).map(classes_mapping)\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_y), y=train_y)\n",
    "print(class_weights)\n",
    "pos_weight = class_weights[0]/class_weights[1]\n",
    "print(pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss, BCELoss, BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "n_epochs = 150\n",
    "patience = 5\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=3e-3, weight_decay=0)\n",
    "criterion = CrossEntropyLoss(weight=torch.Tensor(class_weights).to(device)) \n",
    "#criterion = BCELoss() \n",
    "#criterion = BCEWithLogitsLoss(pos_weight=torch.tensor([20]).to(device) )\n",
    "\n",
    "history = train(\n",
    "    model, loader_train, loader_test , optimizer, criterion, n_epochs, patience, \n",
    "    device, metric=balanced_accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "valid_loss, valid_perf, valid_ap, valid_f1, fp, dd, fn = _validate_1epoch(\n",
    "            model, loader_test_1epoch, criterion, device, metric=balanced_accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './saved_model/QAT/' + 'CE-442-21' + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckp(checkpoint_fpath):\n",
    "    \"\"\"\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    model: model that we want to load checkpoint parameters into       \n",
    "    optimizer: optimizer we defined in previous training\n",
    "    \"\"\"\n",
    "    # load check point on CPU\n",
    "    device = torch.device('cpu')\n",
    "    model = IEEGSeizureDetection_2sec(n_channels, sfreq, n_classes=2)\n",
    "    #checkpoint = torch.load(checkpoint_fpath,  map_location=device)\n",
    "    #model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.load_state_dict(torch.load(checkpoint_fpath, map_location=device))\n",
    "    print(device)\n",
    "    '''\n",
    "    checkpoint = torch.load(checkpoint_fpath,  map_location=device)\n",
    "    print(checkpoint)\n",
    "    # initialize state_dict from checkpoint to model\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    # initialize optimizer from checkpoint to optimizer\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
    "    #valid_loss_min = checkpoint['valid_loss_min']\n",
    "    # return model, optimizer, epoch value, min validation loss '''\n",
    "    return model #, checkpoint['epoch'], valid_loss_min.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ckp_path = './saved_model/QAT-' + 'CE-253-8' + '.pth'\n",
    "ckp_path = './saved_model/1Dconv/' + 'QAT-253-2D-TS0.pth'\n",
    "#print(model)\n",
    "fc = load_ckp(ckp_path)\n",
    "fc = fc\n",
    "fc.eval()\n",
    "print(next(fc.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Export to ONNX : GPU-trained model to be loaded using the CPU.\n",
    "from brevitas.export import FINNManager\n",
    "from brevitas.export.onnx.generic.manager import BrevitasONNXManager\n",
    "\n",
    "FINNManager.export(fc, input_shape=(1,1, 4, 512), export_path='./saved_model/ONNX/QAT-conv2D-TS-253-0.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(fc.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netron\n",
    "netron.start('./saved_model/ONNX/QAT-CE-442-21.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        #print(name, param.data)\n",
    "        if name =='conv1.weight':\n",
    "            conv1_weight = param.data\n",
    "            print('conv1_weight', conv1_weight.shape, conv1_weight[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_weight_torch = torch.flatten(conv1_weight)\n",
    "print(conv1_weight_torch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'figure.figsize':(7,5), 'figure.dpi':100})\n",
    "\n",
    "# Plot Histogram on x\n",
    "#x = np.random.normal(size = 1000)\n",
    "plt.hist(conv1_weight_torch.cpu(), bins=1000)\n",
    "plt.gca().set(title='Frequency Histogram', ylabel='Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare FINN and BREVITAS execution\n",
    "def inference_with_brevitas(current_inp):\n",
    "    brevitas_output = brevitas_model.forward(current_inp)\n",
    "    # apply sigmoid + threshold\n",
    "    brevitas_output = torch.sigmoid(brevitas_output)\n",
    "    brevitas_output = (brevitas_output.detach().numpy() > 0.5) * 1\n",
    "    # convert output to bipolar\n",
    "    brevitas_output = 2*brevitas_output - 1\n",
    "    return brevitas_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_onnx",
   "language": "python",
   "name": "gpu_onnx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
